# **An√°lise de sentimentos de conte√∫do compartilhado em** **comunidades brasileiras do Reddit:** **Avalia√ß√£o de um conjunto de dados rotulados por humanos**

## Giovana Piorino
#### Universidade Federal de Minas Gerais giovana.piorino@dcc.ufmg.br

## Vitor Moreira
#### Universidade Federal de Minas Gerais vitormoreira@dcc.ufmg.br

## Luiz Henrique Quevedo Lima
#### Universidade Federal de Minas Gerais luiz.quevedo@dcc.ufmg.br

## Adriana Silvina Pagano
#### Universidade Federal de Minas Gerais apagano@ufmg.br
### **ABSTRACT**

The soaring use of social media and its impact on society have
been raising ethical issues about the content disseminated by these
platforms, particularly from the perspective of responsible AI given
the need to mitigate the propagation of bias and the spread of toxic
language. Sentiment Analysis of the language of these communities poses big challenges, since it requires quality datasets that
can be used in supervised training of models. The social network
Reddit comprises smaller, sub-communities centered on specific
topics, called Subreddits. Through manual annotation of posts in
Subreddits related to Brazilian content and communities, we have
developed a dataset for Sentiment Analysis in Brazilian Portuguese.
We report the results of our annotation process and characterize the
language of the posts. Our dataset is meant to support Sentiment
Analysis tasks for social media language in Brazilian Portuguese.
### **KEYWORDS**

An√°lise de Sentimentos, Comunidades do Reddit, Tarefa de Anota√ß√£o, Portugu√™s Brasileiro
### **1 INTRODU√á√ÉO**

As redes sociais t√™m rompido barreiras de comunica√ß√£o, proporcionando √†s pessoas a oportunidade de interagir com amigos e
familiares ao redor do mundo, participar de discuss√µes e tomar
conhecimento dos mais variados assuntos [ 2 ]. Al√©m disso, t√™m permitido a r√°pida divulga√ß√£o de quest√µes atuais [ 33 ]. A cada ano,
aumenta o n√∫mero de usu√°rios, com taxas de crescimento maiores
que 5% ao ano, alcan√ßando 5,07 bilh√µes de usu√°rios no in√≠cio de abril
de 2024 [ 18 ]. Contudo, essa expans√£o tamb√©m trouxe um n√∫mero
crescente de pessoas vulner√°veis que veem suas emo√ß√µes serem
afetadas negativamente devido √†s intera√ß√µes nessas plataformas

[ 19 ]. Nessa perspectiva, uma pesquisa da Universidade de Torino,
com o objetivo de compreender o efeito da agress√£o cibern√©tica em
adultos na It√°lia, aponta que, dos 341 participantes, 43% disseram
ter sido v√≠timas de cyber agress√£o. Segundo 95,1% dos participantes,
esses epis√≥dios ocorreram em redes sociais e foram considerados
potencialmente danosos √† sa√∫de mental [22].

In: Proceedings of the Brazilian Symposium on Multimedia and the Web (WebMe
dia‚Äô2024). Juiz de Fora, Brazil. Porto Alegre: Brazilian Computer Society, 2024.
¬© 2024 SBC ‚Äì Brazilian Computing Society.
ISSN 2966-2753

## Ana Paula Couto da Silva
#### Universidade Federal de Minas Gerais ana.coutosilva@dcc.ufmg.br

Dado o crescimento do conte√∫do gerado nas redes sociais diariamente (mais de 4,4 bilh√µes de postagens no segundo semestre
de 2023 no caso da rede Reddit [ 32 ]), sua modera√ß√£o tem se tornado um problema desafiador e dispendioso. Para lidar com isso,
grandes empresas como X, antigo Twitter, adotaram modelos de
aprendizado de m√°quina e revis√£o humana [ 39 ]. Esses modelos
ajudam as plataformas a tomar medidas que julgarem adequadas
em rela√ß√£o a conte√∫dos identificados como violadores de suas diretrizes. Contudo, ainda que existam modelos aptos para realizar
essas tarefas, h√° limita√ß√µes no seu desempenho em idiomas com
menor disponibilidade de dados, como o portugu√™s brasileiro.
Algumas iniciativas t√™m desenvolvido pesquisas e conjuntos de
dados em portugu√™s brasileiro com anota√ß√£o manual de sentimentos em textos de redes sociais. A maior parte dos trabalhos t√™m
privilegiado a rede social Twitter, cujos textos possuem padr√µes
espec√≠ficos de linguagem, raz√£o pela qual modelos treinados com
eles mostram limita√ß√µes quando aplicados a textos de outras redes
sociais. No caso do Reddit, n√£o encontramos nenhum conjunto de
dados de textos originalmente redigidos em portugu√™s brasileiro,
extra√≠dos do Reddit e anotados com r√≥tulos de sentimentos.

Buscando expandir os recursos de PLN para o portugu√™s brasileiro, este artigo apresenta um novo conjunto de dados anotados
para an√°lise de sentimentos. Os textos anotados foram retirados
do Reddit. [1] Reddit √© uma comunidade que permite aos usu√°rios
interagirem por meio de postagens (submiss√µes) e coment√°rios an√¥nimos. Os usu√°rios s√£o organizados em comunidades (subreddits)
e se inscrevem nas comunidades mais alinhadas com seus t√≥picos
de interesse. Os dados anotados com um dos sentimentos ( *positivo*,
*negativo* ou *neutro* ) e a caracteriza√ß√£o lingu√≠stica dos textos categorizados em cada uma das classes de sentimento pode auxiliar na
proposta de novos modelos de classifica√ß√£o de sentimentos e na
melhora de modelos existentes de tal modo que estes sejam mais
adequados para as caracter√≠sticas espec√≠ficas da l√≠ngua portuguesa.
Adicionalmente, nosso trabalho explora formas de an√°lise que
lidam com a complexidade da tarefa de classifica√ß√£o de sentimentos,
a partir do tratamento e caracteriza√ß√£o dos casos em que os anotadores n√£o conseguem atribuir nenhum dos tr√™s sentimentos ao coment√°rio em an√°lise. Por fim, para permitir a reprodutibilidade e incentivar estudos subsequentes, o conjunto de dados anotados ser√° disponibilizado em endere√ßo a ser divulgado na vers√£o para publica√ß√£o.

1 http://reddit.com/


54


-----

WebMedia‚Äô2024, Juiz de Fora, Brazil Giovana Piorino, Vitor Moreira, Luiz Henrique Quevedo Lima, Adriana Silvina Pagano, and Ana Paula Couto da Silva

### **2 TRABALHOS RELACIONADOS**

Estudos exploraram a an√°lise de sentimentos em textos de redes
sociais em portugu√™s brasileiro, tendo alguns deles disponibilizados
publicamente os conjuntos de dados utilizados nos trabalhos.
Dentre eles, os autores [ 36 ] realizaram an√°lises textuais e de
sentimento com base em textos em portugu√™s brasileiro da rede
social Twitter. O trabalho mostra diferentes metodologias para
auxiliar an√°lises textuais com enfoque nessa rede social, como o
Twitt√≥metro e o *Amazon Mechanical Turk* [2] .

Outras an√°lises, como em [ 14 ], tamb√©m exploraram a detec√ß√£o de
t√≥picos e a an√°lise de sentimentos em textos do Twitter no contexto
brasileiro, com √™nfase em temas relacionados √† COVID-19. A abordagem de extra√ß√£o de t√≥picos utilizada foi a LDA ( *Latent Dirichlet*
*Allocation* ), e a an√°lise de sentimentos para os textos em portugu√™s
obteve aux√≠lio do mUSE( *Multilingual Universal Sentence Encoder for*
*Semantic Retrieval* ), e do SemEval 2018. Ainda relativo ao Twitter,
os autores em [ 40 ] coletaram tweets em portugu√™s brasileiro de
forma a compor um conjunto de dados [3] de 15.000 tweets, extra√≠dos
entre janeiro e julho de 2017. Para esse estudo, os tweets tamb√©m
foram classificados com os r√≥tulos *positivo, negativo e neutro*, por
anotadores cuja anota√ß√£o obteve m√©tricas de alfa de krippendorf
de 0,529, considerada uma concord√¢ncia moderada.
Dentre os modelos direcionados √† l√≠ngua portuguesa e √† an√°lise
de sentimentos, tem-se o VADER[ 16 ]( *Valence Aware Dictionary for*
*Sentiment Reasoning* ), que apresenta uma extens√£o para a l√≠ngua
portuguesa chamada LeIA [ 1 ] ( *L√©xico para Infer√™ncia Adaptada* ),
a qual rotula textos entre categorias *positivo, negativo e neutro*,
podendo se adaptar a diferentes contextos, sem se restringir ao
escopo de textos de uma rede social espec√≠fica.
No que diz respeito a trabalhos relacionados √† rede social Reddit, os autores [ 6 ] utilizaram o modelo *GoEmotions* baseado em
um conjunto de dados com aproximadamente 58.000 coment√°rios
rotulados manualmente com categorias de emo√ß√µes, redigidos em
ingl√™s e traduzidos para o portugu√™s. O estudo tamb√©m realizou
correla√ß√µes lingu√≠sticas entre as emo√ß√µes identificadas e os coment√°rios rotulados, e obteve m√©tricas de avalia√ß√£o das anota√ß√µes e do
modelo. No entanto, devido √† grande quantidade de categorias de
emo√ß√µes presentes na rotula√ß√£o, as m√©tricas geraram valores, em
geral, moderados ou fracos para a tarefa de anota√ß√£o.
Em [ 17 ], os autores utilizaram conjunto de dados de textos extra√≠dos do Twitter e do Reddit para avaliar distintas configura√ß√µes de
pipelines de pr√©-processamento dos textos em portugu√™s brasileiro,
pass√≠veis de serem implementadas antes da aplica√ß√£o de m√©todos
de modelagem de t√≥picos. As adapta√ß√µes avaliadas evidenciaram
melhoras em todas as m√©tricas.

Apesar do recente crescimento da rede social Reddit, ainda h√°
poucas refer√™ncias na literatura sobre an√°lises textuais e de tarefas
de anota√ß√£o de sentimentos em textos dessa rede, principalmente
em portugu√™s brasileiro. Assim, nosso estudo busca expandir os
recursos de PLN em portugu√™s brasileiro, fornecendo um conjunto
de dados anotado com sentimentos, juntamente com os resultados das m√©tricas centrais de avalia√ß√£o da anota√ß√£o humana e a
caracteriza√ß√£o da linguagem dos textos no conjunto de dados.

2 https://www.mturk.com/
3 https://bitbucket.org/HBrum/tweetsentbr/src/master/


**Tabela 1: Subreddits selecionados e total de postagens e co-**
**ment√°rios (2022).**

**Subreddit** **Postagens** **Coment√°rios**

r/brasil 115,876 2,382,928

r/desabafos 115,876 1,487,076

r/futebol 35,826 1,272,009
r/saopaulo 7,308 88,894
r/eu_nvr 12,631 221,348
r/botecodoreddit 7,059 62,999

r/conversas 21,967 355,761

r/investimentos 9,756 156,695
r/tiodopave 2,371 12,106
r/brasilivre 67,301 1,308,441

Total 390,924 7,348,257
### **3 METODOLOGIA**

Nesta se√ß√£o primeiramente apresentamos a metodologia utilizada
para coletar o conjunto original de dados. A seguir, descrevemos
a processo de anota√ß√£o manual de um conjunto selecionado dos
dados. Por fim, apresentamos os m√©todos usados para a an√°lise
lingu√≠stica dos coment√°rios anotados.
### **3.1 Conjunto de Dados**

Reddit √© uma m√≠dia social online organizada em subcomunidades por √°reas de interesse ou subreddits, nas quais usu√°rios discutem diferentes assuntos, atrav√©s de intera√ß√µes do tipo postagemcoment√°rios, chamadas de *threads* . Nossa base original de dados
consiste em atividades de usu√°rios (postagens e coment√°rios) [4] entre
os meses de janeiro e dezembro de 2022 realizadas nas 10 comunidades brasileiras com maior n√∫mero de usu√°rios ativos. A Tabela

1 apresenta as principais estat√≠sticas das 10 comunidades selecionadas. Os dados foram coletados a partir da plataforma Pushshift,
que coleta, analisa e arquiva conte√∫dos do Reddit desde 2015 [ 4 ].
Estes dados foram previamente apresentados em [ 21 ] e utilizados
para a tarefa de classifica√ß√£o de toxicidade dos coment√°rios compartilhados nestes subreddits.
### **3.2 Anota√ß√£o dos dados**

Para a classifica√ß√£o manual do sentimento associado a cada coment√°rio, foram selecionados 2,000 coment√°rios da base original
coletada, seguindo uma amostra estratificada do total de coment√°rios em cada comunidade analisada. Estes coment√°rios foram

divididos em 4 grupos, com 500 coment√°rios cada, denominados
*Grupo1, Grupo2, Grupo3, Grupo4* . Cada grupo foi anotado por 3
anotadores distintos.

Os anotadores s√£o estudantes universit√°rios convidados a participar de forma an√¥nima e instru√≠dos a ler e classificar cada coment√°rio
como *Positivo, Negativo, Neutro ou N√£o sei dizer*, levando em considera√ß√£o o sentimento predominante em cada texto. Caso n√£o fosse
poss√≠vel determinar um sentimento, a op√ß√£o a ser escolhida deveria ser *N√£o sei dizer* . Para auxiliar a identifica√ß√£o do sentimento
predominante, foi sugerido aos anotadores ter aten√ß√£o especial a
dois pontos: (i) os coment√°rios *negativos* geralmente manifestam

4 O termo ‚Äôcoment√°rios‚Äô ser√° utilizado abrangendo coment√°rios e postagens.


55


-----

An√°lise de sentimentos de conte√∫do compartilhado em comunidades brasileiras do Reddit:
Avalia√ß√£o de um conjunto de dados rotulados por humanos WebMedia‚Äô2024, Juiz de Fora, Brazil


emo√ß√µes de medo, culpa, m√°goa, tristeza, raiva, ang√∫stia, ansiedade
e depress√£o; e (ii) os coment√°rios *neutros* n√£o apresentam nenhuma
caracter√≠stica que possa levar a sua classifica√ß√£o como negativos
ou positivos.
Ao final do processo de anota√ß√£o, cada coment√°rio recebeu o
r√≥tulo com o sentimento atribu√≠do pela maioria dos anotadores e
a concord√¢ncia entre os avaliadores foi medida por tr√™s m√©tricas
comumente usadas: *Kappa de Fleiss* [ 7 ], *Alpha de Krippendorf* [ 20 ]
e *Concord√¢ncia Observada* [8].
### **3.3** **Classifica√ß√£o Autom√°tica de Sentimentos**

Para medir a correla√ß√£o entre a classifica√ß√£o autom√°tica e manual
de sentimentos nos coment√°rios amostrados do Reddit, escolhemos
o modelo XLM-RoBERTa ( *Cross Lingual Language Model - Robustly*
*Optimized BERT-Pretraining Approach* ) [5] como nosso *baseline*, que
est√° dispon√≠vel na biblioteca *Hugging Face* .
O modelo utilizado j√° havia passado por um ajuste fino baseado
em textos da rede social *Twitter* em portugu√™s. A escolha desse
modelo se deve √† sua grande base treinada em aproximadamente
10 milh√µes de *tweets* na l√≠ngua portuguesa [ 3 ] e a o modelo ser
direcionado √† tarefa de an√°lise de sentimentos.
### **3.4 An√°lise Textual**

Antes de iniciar a an√°lise textual, os 2.000 coment√°rios anotados
foram submetidos a filtros, utilizando-se express√µes regulares [ 13 ],
com o objetivo de detectar o conte√∫do dos coment√°rios a serem
exclu√≠dos da an√°lise: endere√ßos de sites, men√ß√µes a outros usu√°rios,
hashtags, textos citados, datas ou emojis. Risadas expressas em
texto foram removidas, assim como coment√°rios contendo palavras
gramaticais que ocorriam isoladamente e sem valor de informa√ß√£o
para nossa an√°lise, com base na lista de ( *stopwords* ) da biblioteca
NLTK[ 26 ] e em um modelo do spaCy[ 37 ]. Assim, 19 coment√°rios
foram removidos das an√°lises ap√≥s os filtros.

*3.4.1* *Raz√£o Type-Token Type-Token Ratio (TTR).* Com a tokeniza√ß√£o dos coment√°rios feita pela biblioteca [ 25 ], determinamos a diversidade lexical usando a medida TTR. O resultado do TTR adv√©m

do n√∫mero de tokens distintos dividido pelo n√∫mero total de tokens
existentes no coment√°rio. Complementamos a an√°lise avaliando o
tamanho (em n√∫mero de tokens) dos coment√°rios de cada grupo.

*3.4.2* *Etiquetagem de classe de palavra (Pos Tagging).* Para examinar as classes de palavra predominantes nos coment√°rios rotulados,
fizemos o POS tagging [ 28 ] com um modelo pr√©-treinado [ 37 ], baseado em um treebank anotado de acordo com o padr√£o das Universal
Dependencies [ 11 ]. Esse treebank tem como principal base o trabalho de [30].

*3.4.3* *Reconhecimento de Entidades Nomeadas (REN).* Exploramos
as entidades nomeadas atrav√©s do uso de um modelo pr√©-treinado do
spaCy. Empregamos novamente o modelo utilizado no Pos Tagging,
sendo o conjunto de dados utilizado para treinar esse modelo o
WikiNER [ 27 ]. Essa t√©cnica classifica as entidades em 3 categorias:
PESSOA (PER), LOCALIZA√á√ÉO (LOC) e ORGANIZA√á√ÉO (ORG).
Entidades que n√£o se enquadram nessas categorias s√£o classificadas
como DIVERSAS (MISC).

5 https://huggingface.co/docs/transformers/model_doc/xlm-roberta


*3.4.4* *An√°lise de* *ùëõ* *-gramas.* . Para complementar as an√°lises lingu√≠sticas, realizamos a an√°lise de *ùëõ* -gramas. Um n-grama √© uma
sequ√™ncia cont√≠gua de *ùëõ* itens de uma determinada amostra de texto.

*3.4.5* *Classifica√ß√£o de t√≥picos (BERTopic).* Para a extra√ß√£o de t√≥picos dos coment√°rios utilizamos o modelo BERTopic [ 15 ], a fim de
caracterizar os conte√∫dos mais frequentes dos textos, e como eles se
relacionam com os sentimentos rotulados pelos anotadores e pelo
modelo autom√°tico RobERTa. Os coment√°rios foram convertidos

em vetores de representa√ß√£o com aux√≠lio do modelo BERTimbau

[ 35 ], no qual h√° um est√°gio adicional de ajuste fino direcionado √†
similaridade de sem√¢ntica textual [9] [23] [31].
Para garantir uma modelagem mais consistente dos t√≥picos foi
realizada a redu√ß√£o da dimensionalidade dos vetores por meio do
UMAP ( *Uniform Manifold Approximation and Projection for Dimen-*
*sion Reduction* ), t√©cnica que melhora agrupamentos subsequentes.
Tamb√©m foi utilizado o algoritmo HDBSCAN ( *Hierarchical Density-*
*Based Spatial Clustering of Applications with Noise* ), obtendo-se um
agrupamento dos vetores de representa√ß√£o a partir de similaridades
sem√¢nticas. Por fim, c-TF-IDF ( *Class-based Term Frequency-Inverse*
*Document Frequency* ) e MMR ( *Maximal Marginal Relevance* ) foram
aplicados e ajustados para melhorar a defini√ß√£o de palavras-chave
para os t√≥picos e para diversificar seu conte√∫do sem√¢ntico, respectivamente. Foram utilizadas recomenda√ß√µes presentes na documenta√ß√£o do modelo [6] para o ajuste de tais par√¢metros, sendo que para
o UMAP, o n√∫mero de vizinhos foi ajustado para 10, e o n√∫mero
de componentes, para 8. Para o HDBSCAN, o n√∫mero m√≠nimo do
tamanho de agrupamentos √© de 10, e n√∫mero m√≠nimo de amostras,
8. O par√¢metro MMR foi atualizado para uma taxa de 0.8.

*3.4.6* *Rotula√ß√µes sem√¢nticas (PyMUSAS).* Para a an√°lise sem√¢ntica
dos coment√°rios, foi utilizada a ferramenta pyMUSAS, baseada na
estrutura USAS [7] ( *UCREL Semantic Analysis System* ) adaptada √† linguagem Python. Essa classifica√ß√£o apresenta modelos em diferentes
l√≠nguas, incluindo o portugu√™s [ 29 ], um dos motivos para seu uso
neste trabalho.

Resumidamente, ela apresenta uma estrutura organizada em c√≥digos, que representam categorias sem√¢nticas distintas [ 34 ]. Cada
coment√°rio pode ser enquadrado em uma ou mais categorias sem√¢nticas, fornecendo uma vis√£o ampla e abstrata dos conte√∫dos
presentes nos coment√°rios e como eles est√£o relacionados aos sentimentos rotulados.
### **4 RESULTADOS**

Nesta se√ß√£o, apresentamos os principais resultados obtidos na avalia√ß√£o e caracteriza√ß√£o do conjunto de dados anotados.
### **4.1 Concord√¢ncia entre anotadores**

As m√©tricas para analisar os resultados de concord√¢ncia entre os
anotadores foram aplicadas aos subconjuntos *Todas as anota√ß√µes*,
abrangendo todos os coment√°rios rotulados com as quatro categorias dispon√≠veis e *Apenas sentimentos*, abrangendo coment√°rios
rotulados desconsiderando o r√≥tulo *N√£o sei dizer*, de forma a verificar o impacto desse r√≥tulo de incerteza nos resultados. A Tabela 2
apresenta os resultados. O Alfa de Krippendorf e o Kappa de Fleiss

6 https://maartengr.github.io/BERTopic/index.html
7 https://ucrel.lancs.ac.uk/usas/


56


-----

WebMedia‚Äô2024, Juiz de Fora, Brazil Giovana Piorino, Vitor Moreira, Luiz Henrique Quevedo Lima, Adriana Silvina Pagano, and Ana Paula Couto da Silva


apresentaram valores que podem ser interpretados como concord√¢ncia moderada entre os anotadores. J√° a concord√¢ncia observada
apresenta valores consideravelmente maiores que as outras m√©tricas, por√©m n√£o apresenta tanta robustez, por n√£o considerar que
a concord√¢ncia entre anotadores possa ter acontecido ao acaso.
Em geral, observa-se que a qualidade das m√©tricas melhora consideravelmente ao incluir apenas os coment√°rios rotulados com os
sentimentos e desconsiderar a categoria *N√£o sei dizer* .
No que diz respeito √† concord√¢ncia total entre anotadores, isto
√©, todos os anotadores indicando o mesmo r√≥tulo, o percentual
de coment√°rios que obtiveram concord√¢ncia total foi 44.65% no
subconjunto que considera todos os r√≥tulos de anota√ß√£o. J√° no
subconjunto de coment√°rios apenas com r√≥tulos de sentimentos,
a concord√¢ncia total aumenta para 57%. Alguns exemplos desses
coment√°rios se encontram na Tabela 3.
A fim de estabelecer classifica√ß√µes de sentimentos para an√°lises
posteriores de compara√ß√£o com modelos autom√°ticos e caracteriza√ß√£o dos textos, atribu√≠mos √†s ocorr√™ncias de concord√¢ncia parcial o
sentimento anotado predominante, isto √©, a concord√¢ncia de dois
ou mais anotadores sobre um mesmo r√≥tulo. A Tabela 4 mostra

que quase metade do conjunto de coment√°rios foi majoritariamente
rotulado como *negativo*, indicando um desbalanceamento de classes
consider√°vel. J√° os r√≥tulos *positivo* e *neutro* obtiveram propor√ß√µes
semelhantes. 10,55% dos coment√°rios obtiveram discord√¢ncia total,
ou seja, cada anotador apontou um r√≥tulo diferente. Este valor de
discord√¢ncia pode ser o resultado de diferentes perspectivas que
cada anotador pode ter do que √© algo positivo ou negativo [ 24 ], ou
a presen√ßa de conte√∫do com teor de sarcasmo ou falta de contexto
adicional para facilitar a atribui√ß√£o de um sentimento.
A Tabela 5 indica o desempenho de cada trio de anotadores e
suas respectivas m√©tricas, sendo poss√≠vel observar que a anota√ß√£o dos coment√°rios pertencentes ao grupo 4 obteve o melhor e
aqueles do grupo 3 o pior desempenho. No entanto, em geral, as
anota√ß√µes obtiveram m√©tricas de concord√¢ncia razoavelmente pr√≥ximas, apontando para concord√¢ncias m√©dias e moderadas entre
seus respectivos anotadores. De forma complementar, a Tabela 6
apresenta a rotula√ß√£o de sentimentos para cada anotador, dentro
de cada grupo de coment√°rios.
Uma an√°lise interessante a ser realizada est√° relacionada ao

grau de incerteza presente na tarefa de rotula√ß√£o. No total dos
2,000 coment√°rios rotulados, a op√ß√£o *N√£o sei dizer* foi selecionada
por pelo menos um dos tr√™s anotadores em 23,05% do conjunto
total. No entanto, apenas em 4,1% dos coment√°rios, dois ou mais
anotadores rotularam o mesmo coment√°rio com *N√£o sei dizer*, uma
queda significativa que pode indicar que h√° uma dificuldade maior
em 2 ou mais anotadores caracterizarem incerteza de sentimento

para um mesmo texto. Um exemplo de texto em que 2 ou mais
anotadores apresentaram incerteza na rotula√ß√£o √©: *"Curti muito sua*
*dupla personalidade, hehe."*, o que parece ser uma frase de sarcasmo,
dificultando ainda mais a tarefa de rotula√ß√£o, mesmo para humanos.
Observamos tamb√©m grande varia√ß√£o nas categorias escolhidas
pelos anotadores. A Tabela 7 apresenta os resultados das m√©tricas de avalia√ß√£o de concord√¢ncia entre anotadores em cada grupo
de coment√°rios. Vemos que para um mesmo grupo de textos, o
anotador 1 assinalou 13,60% dos coment√°rios com *N√£o sei dizer*,
enquanto que o anotador 3 atribuiu esse r√≥tulo a apenas 0,40% dos
coment√°rios. Tais resultados reafirmam o apontado na literatura


**Tabela 2: Concord√¢ncia entre anotadores.**

**M√©trica** **Todas as anota√ß√µes** **Apenas sentimentos**

Kappa de Fleiss 0,40 0,51
Alfa de Krippendorf 0,47 0,53
Concord√¢ncia observada 0,60 0,70

**Tabela 3: Exemplos de coment√°rios que obtiveram concor-**
**d√¢ncia total entre os anotadores**

**Sentimento** **Exemplo de coment√°rio**

Ahh para, eu curto cidadezinha,
Positivo as vezes eu vou pra uns lugares desse,
fico uns 2 ou 4 dias, acho super legal.


Negativo


Intervencionismo externo visando ganho
pr√≥prio e sem estudar a situa√ß√£o complexa
e possiveis consequencias. Um cl√°ssico
dos estados unidos de m*rda


Subsidio para quem vender preferencialmente
Neutro para o mercado interno ou o contrario,
cobrar mais imposto sobre o produto exportado.

**Tabela 4: Porcentagem de coment√°rios para cada agrupa-**
**mento de rotula√ß√£o e para a discord√¢ncia total.**

**Classifica√ß√£o** **Porcentagem**

Negativo 48,05%
Neutro 20,95%

Positivo 16,30%

Discord√¢ncia total 10,55%

N√£o sei dizer 4,15%

**Tabela 5: M√©tricas de avalia√ß√£o para concord√¢ncia entre ano-**
**tadores para cada grupo desconsiderando o r√≥tulo** ***N√£o sei***
***dizer*** **.**

**M√©trica** **Grupo1** **Grupo2** **Grupo3** **Grupo4**

Kappa de Fleiss 0,41 0,39 0,34 0,44
Alfa de Krippendorf 0,48 0,48 0,40 0,50
Concord√¢ncia observada 0,60 0,58 0,56 0,64

sobre a subjetividade nas avalia√ß√µes de sentimento e a dificuldade
dessa tarefa. Adicionalmente, analisando os dados correspondentes
na Tabela 6, observa-se que o grupo 1 apresentou, em geral, maior
classifica√ß√£o de coment√°rios *positivos*, e o anotador 3 desse grupo
foi o que mais rotulou positivamente, por uma grande margem de
diferen√ßa em rela√ß√£o aos demais. Por outro lado, o anotador 2 do
grupo 4 foi o que mais rotulou negativamente, ainda que, em geral,
obteve um propor√ß√£o de anota√ß√µes consideravelmente constante
em rela√ß√£o aos outros anotadores de seu grupo, que √© o que apresentou as melhores m√©tricas de concord√¢ncia. O grupo 3, grupo com
as mais baixas m√©tricas de concord√¢ncia, apresentou disparidades
consider√°veis entre as propor√ß√µes de rotula√ß√µes, tendo o anotador
1 desse grupo demonstrado discrep√¢ncia razo√°vel de propor√ß√µes de
rotula√ß√µes em rela√ß√£o aos anotadores 2 e 3.


57


-----

An√°lise de sentimentos de conte√∫do compartilhado em comunidades brasileiras do Reddit:
Avalia√ß√£o de um conjunto de dados rotulados por humanos WebMedia‚Äô2024, Juiz de Fora, Brazil

**Tabela 6: Distribui√ß√£o de rotula√ß√£o de sentimentos para cada anotador.**

**Grupo1** **Grupo2** **Grupo3** **Grupo4**

**Anotador 1** **Anotador 2** **Anotador 3** **Anotador 1** **Anotador 2** **Anotador 3** **Anotador 1** **Anotador 2** **Anotador 3** **Anotador 1** **Anotador 2** **Anotador 3**

**Positivo** 22,8% 16,6% 35,4% 19,6% 18,8% 19,8% 17,6% 24,0% 10,0% 15,2% 15,4% 14,8%
**Negativo** 47,6% 46,8% 38,4% 45,4% 50,2% 44,0% 55,6% 43,6% 48,0% 42,0% 57,2% 46,6%
**Neutro** 16,0% 28,0% 25,8% 24,4% 21,4% 14,0% 19,4% 27,2% 25,2% 25,8% 27,2% 38,4%
**N√£o sei dizer** 13,6% 0,86% 0,4% 10,6% 9,6% 22,2% 7,4% 5,2% 16,8% 17,0% 0,2% 0,2%


**Tabela 7: Porcentagem de coment√°rios categorizados como**
***N√£o sei dizer*** **por anotador e grupo.**

**Anotadores** **Grupo1** **Grupo2** **Grupo3** **Grupo4**

Anotador 1 13,60% 10,60% 7,40% 17,00%

Anotador 2 8,60% 9,60% 5,20% 0,20%

Anotador 3 0,40% 22,20% 16,80% 0,20%
### **4.2 Compara√ß√£o com XLM-RoBERTa**

O r√≥tulo final de cada coment√°rio foi atribu√≠do com base na concord√¢ncia de 2 ou mais anotadores. Feita essa atribui√ß√£o, a fim de
ajustar os r√≥tulos aos que est√£o presentes no modelo XLM-RoBERTa
( *Positivo*, *Negativo* e *Neutro* ), foram removidos coment√°rios em que
houve discord√¢ncia total entre anotadores e coment√°rios em que a
maioria dos anotadores selecionou *N√£o sei dizer*, resultando num total de 1.706 coment√°rios utilizados para compara√ß√£o com o modelo
treinado.

Ap√≥s essa etapa, realizamos a compara√ß√£o entre os anotadores
e o modelo, que obteve acur√°cia de 62,37% (porcentagem de coment√°rios em que o r√≥tulo indicado pelo modelo coincidiu com a
anota√ß√£o humana) e Kappa de Cohen de 0,34, considerado razoavelmente fraco [ 5 ]. O modelo apresentou as seguintes porcentagens
de sentimentos: 12,49% de coment√°rios *positivos*, 60,90% de coment√°rios *negativos* e 26,61% de coment√°rios *neutros* . A taxa de r√≥tulos
*negativos* foi consideravelmente superior √† da anota√ß√£o humana,
que √© de 48,05%.
A distribui√ß√£o da concord√¢ncia entre os grupos foi bem similar, com varia√ß√µes entre 60% - 65% de concord√¢ncia do modelo em
rela√ß√£o aos anotadores. O grupo 3 apresentou a menor taxa de
concord√¢ncia com modelo, com 60,66%, e o grupo 4 apresentou a
melhor taxa, com 65,27%. Tais resultados s√£o an√°logos aos obtidos
com as m√©tricas de concord√¢ncia entre anotadores apresentadas
anteriormente, em que os grupos 3 e 4 apresentaram o pior e o
melhor desempenho, respectivamente.
O modelo apresentou uma taxa de concord√¢ncia para r√≥tulos
negativos razoavelmente alta entre os grupos, variando de 75,10%83,33%, enquanto que as taxas de concord√¢ncia para r√≥tulos positivos foram as mais baixas entre os grupos, abrangendo uma porcentagem de r√≥tulos indicados corretamente entre 33,01% e 38,24%.
Isso contrasta com o fato de que sua taxa de rotula√ß√µes positivas √©
similar √† taxa dos anotadores, ind√≠cio de que o modelo exibe grande
dificuldade para identificar corretamente um coment√°rio *positivo* .
Tal observa√ß√£o se relaciona com os resultados das principais m√©tricas apresentadas na Tabela 8, em que a classe *negativo* apresentou
valores maiores e mais consistentes que as demais, al√©m do desbalanceio da amostra citado anteriormente, havendo ocorr√™ncias
significantemente maiores de r√≥tulos negativos. Para rotula√ß√µes


**Tabela 8: M√©tricas de compara√ß√£o entre anotadores e modelo**

**XLM-RoBERTa.**

**Classe** **Precis√£o** **Recall** **F1-Score**

Positivo 0,54 0,35 0,42

Negativo 0,72 0,78 0,75
Neutro 0,44 0,48 0,46

M√©dia Macro 0,57 0,54 0,54

M√©dia Ponderada 0,62 0,62 0,62

**Tabela 9: Quantidade de coment√°rios para cada agrupamento**
**de rotula√ß√£o e para a discord√¢ncia total.**

**Classifica√ß√£o** **Quantidade de Coment√°rios**

Negativo 960

Neutro 413

Positivo 319

Discord√¢ncia total 210

N√£o sei dizer 79

para *negativo*, o grupo 1 apresentou maior taxa de concord√¢ncia em
rela√ß√£o ao modelo, com 83,33%. Para os r√≥tulos *positivo* e *neutro*, o
grupo 4 obteve a maior taxa, com 38,24% e 56,64% respectivamente.
Tamb√©m buscamos identificar caracter√≠sticas dos textos em que
o modelo fez uma predi√ß√£o do r√≥tulo errado. Um exemplo de coment√°rio que obteve concord√¢ncia total entre anotadores, mas que
o modelo errou em sua predi√ß√£o de r√≥tulo, √©: *"Dai querem vir opinar*
*no nosso jogo. Americano √© f*da... bom que n√£o entendem nada"*, que
os anotadores indicaram como *negativo*, mas o modelo considerou
como *positivo* . Em geral, para as ocorr√™ncias de concord√¢ncia total
dos anotadores, o modelo obteve uma taxa de erros de 38%.
### **4.3 Caracteriza√ß√£o da Linguagem**

A compara√ß√£o dos padr√µes de linguagem foi realizada por meio do
agrupamento de coment√°rios baseado no r√≥tulo predominante das
3 rotula√ß√µes feitas pelos anotadores a cada coment√°rio. Utilizou-se
um p-valor < 0,5 em todas as an√°lises para garantir a signific√¢ncia
estat√≠stica. A Tabela 9 exibe os dados ap√≥s a filtragem de textos e,
consequentemente, de coment√°rios que n√£o continham informa√ß√µes
√∫teis. Esses dados foram utilizados nas an√°lises realizadas.

***Raz√£o Type-Token Type-Token Ratio (TTR)*** : Quanto √† an√°lise
do TTR, existem diferen√ßas entre as m√©dias de caracteres por coment√°rio nos agrupamentos, em especial, entre o agrupamento
*N√£o sei dizer* e os demais. O agrupamento *N√£o sei dizer* apresentou a menor m√©dia, com 43,13 [29,08, 60,15]. O agrupamento de
coment√°rios *neutros* teve uma m√©dia de 81,41 [69,65, 94,45], j√° os
agrupamentos de coment√°rios *negativos* e *positivos* apresentaram


58


-----

WebMedia‚Äô2024, Juiz de Fora, Brazil Giovana Piorino, Vitor Moreira, Luiz Henrique Quevedo Lima, Adriana Silvina Pagano, and Ana Paula Couto da Silva


**Tabela 10: Porcentagem de etiquetas pos para cada classe**
**rotulada.**

**Classifica√ß√£o** **NOUN** **VERB** **ADJ** **PROPN** **ADV**

Negativo 35,51% 30,54% 18,28% 6,28% 4,17%
Neutro 34,97% 27,83% 18,08% 10,07% 3,92%

Positivo 34,49% 32,19% 17,82% 6,31% 3,66%

N√£o sei dizer 29,84% 26,16% 14,15% 18,41% 2,71%

m√©dias de 98,46 [90,57, 106,66] e 99,13 [80,11, 122,28]. Esses resultados podem indicar que coment√°rios com sentimentos negativos e
positivos tendem a ser mais longos do que coment√°rios neutros e
aqueles que necessitam de mais contexto para serem interpretados,
categorizados como *N√£o sei dizer* . No entanto, ao aplicar o teste estat√≠stico de Mann-Whitney [8] [ 38 ], n√£o foi encontrada uma diferen√ßa
entre o agrupamento *neutro* e o agrupamento *positivo* . Por outro
lado, ao realizarmos o teste estat√≠stico tanto para compararmos
o agrupamento *negativo* com o *neutro* quanto para compararmos
o agrupamento *negativo* com o *positivo*, foi demonstrado que h√°
diferen√ßas significativas entre eles.
Em rela√ß√£o √† m√©dia e ao intervalo de confian√ßa TTR, os agrupamentos apresentaram os seguintes valores: o agrupamento *N√£o sei*
*dizer* apresenta 0,98 [0,96, 0,99], o agrupamento *neutro*, 0,97 [0,96,
0,98], o agrupamento *negativo*, 0,97 [0,96, 0,97] e o agrupamento
*positivo*, 0,97 [0,97, 0,98]. A an√°lise com o teste de Mann-Whitney
indicou que o √∫nico agrupamento com diferen√ßa significativa em
rela√ß√£o aos outros foi o agrupamento *N√£o sei dizer* . Nos demais resultados, o mesmo teste estat√≠stico ser√° utilizado e, portanto, iremos

omitir o seu nome.

***Etiquetagem de classe de palavra (Pos Tagging)*** : A m√©dia e o
intervalo de confian√ßa da diversidade de etiquetas POS para cada
agrupamento s√£o os seguintes: o agrupamento *N√£o sei dizer* apresenta 0,73 [0,66, 0,79], o agrupamento *neutro*, 0,57 [0,55, 0,60], o
agrupamento *negativo*, 0,50 [0,48, 0,51] e o agrupamento *positivo*,
0,56 [0,52, 0,59]. Esses resultados corroboram os obtidos no TTR,
especialmente na diferen√ßa entre o agrupamento *N√£o sei dizer* e os
demais em termos de diversidade. Vale ressaltar que o agrupamento
*negativo* possui a menor m√©dia.
A Tabela 10 apresenta a representatividade das principais etiquetas pos em rela√ß√£o ao total de palavras etiquetadas de cada
agrupamento de coment√°rios. Para um maior aprofundamento, analisamos a m√©dia de palavras classificadas com etiquetas espec√≠ficas
por coment√°rio, come√ßando pelos adjetivos (ADJ). A m√©dia e o
intervalo de confian√ßa para cada agrupamento s√£o os seguintes: o
agrupamento *N√£o sei dizer* apresenta 0,93 [0,62, 1,29], o agrupamento *neutro*, 1,94 [1,58, 2,36], o agrupamento *negativo*, 2,41 [2,21,
2,62] e o agrupamento *positivo*, 2,38 [1,90, 2,98]. O agrupamento *N√£o*
*sei dizer* possui a menor m√©dia. Ao aplicar o teste estat√≠stico nos
demais agrupamentos, observamos que h√° diferen√ßas significativas
entre todos eles, a partir de compara√ß√µes entre *negativos* e *neutros*,
*negativos* e *positivos*, e *positivos* e *neutros* .
Para os substantivos (NOUN), a m√©dia e o intervalo de confian√ßa
para cada agrupamento s√£o os seguintes: o agrupamento *N√£o sei*
*dizer* apresenta 1,96 [1,38, 2,65], o agrupamento *neutro*, 3,76 [3,24,

8 O teste Mann-Whitney √© um teste n√£o param√©trico utilizado para verificar se dois
grupos de amostras independentes pertencem ou n√£o √† mesma popula√ß√£o.


4,33], o agrupamento *negativo*, 4,681 [4,31, 5,06] e o agrupamento
*positivo*, 4,61 [3,74, 5,66]. Como no caso dos adjetivos, o agrupamento *N√£o sei dizer* apresenta a menor m√©dia. O teste estat√≠stico
revela diferen√ßas significativas ao confrontarmos o agrupamento
*negativo* com o *positivo* e o agrupamento *negativo* com o *neutro*,
por√©m, isso n√£o se prova verdade ao confrontarmos o agrupamento
*neutro* com o *positivo* .
A m√©dia e intervalo de confian√ßa dos agrupamento para os verbos
(VERB) s√£o os seguintes: o agrupamento *N√£o sei dizer* apresenta 1,71

[1,09, 2,52], o agrupamento *neutro*, 2,99 [2,58, 3,43], o agrupamento
*negativo*, 4,03 [3,68, 4,38] e o agrupamento *positivo*, 4,30 [3,45, 5,33].
Observa-se o mesmo padr√£o para o agrupamento *N√£o sei dizer* nas 3
etiquetas. O teste estat√≠stico indica diferen√ßas significativas ao compararmos o agrupamento *negativo* com o *positivo* e o agrupamento
*negativo* com o *neutro*, mas n√£o mostrou diferen√ßas significativas
ao compararmos o agrupamento *neutro* com o *positivo* .
Por fim, o agrupamento de coment√°rios classificados como *N√£o*
*sei dizer* √© o √∫nico que apresenta mais etiquetas POS de nome
pr√≥prio (PROPN) do que de adjetivos (ADJ), como pode ser visto
na Tabela 10. Isso tamb√©m mostra que esse agrupamento √© o que
cont√©m mais nomes pr√≥prios.
***Reconhecimento de Entidades Nomeadas (REN)*** : Os coment√°rios
classificados como *N√£o sei dizer* apresentam uma predomin√¢ncia de
entidades do tipo PER, representando 51% das entidades identificadas, seguido por 19% de entidades do tipo LOC, 16% de ORG e 14%
de MISC. Os coment√°rios *neutros* exibem uma distribui√ß√£o de 43%
de entidades PER, 25% de LOC, 16% de ORG e 16% de MISC. J√° os
coment√°rios *positivos* mostram 40% de entidades PER, 24% de LOC,
11% de ORG e 24% de MISC. Por fim, nos coment√°rios *negativos*, 44%
de entidades PER, 35% de LOC, 12% de ORG e 10% de MISC. Esses
dados destacam a predomin√¢ncia de entidades PER no grupo *N√£o sei*
*dizer*, a quantidade de entidades LOC nos coment√°rios *negativos* e a
presen√ßa significativa de entidades MISC nos coment√°rios *positivos* .
Adicionalmente, considerando os 2000 coment√°rios, nossas an√°
lises mostraram um crescimento no n√∫mero de entidades menciona
das de janeiro para fevereiro e de fevereiro para mar√ßo, em especial,
possivelmente em decorr√™ncia da guerra entre R√∫ssia e Ucr√¢nia.
Al√©m disso, existem picos pr√≥ximos de outubro, coincidindo com
o per√≠odo eleitoral no Brasil, com exce√ß√£o do grupo *N√£o sei dizer*,
provavelmente por ter poucos coment√°rios, como demonstrado na
Tabela 9.

***An√°lise de*** *ùëõ* ***-gramas*** : Na an√°lise dos n-gramas, podemos destacar os resultados de bigramas dos coment√°rios classificados como
*positivo*, que frequentemente abordam temas relacionados √† vida.
J√° para os coment√°rios *negativos*, evidencia-se *lula, bolsonaro* . Nos
trigramas de sentimento positivo, temos palavras relacionadas √†
conselhos sobre relacionamento (por exemplo *sociedade, v√™, casais* ).
os trigramas dos coment√°rios *negativos*, h√° a ocorr√™ncia da combina√ß√£o *bandido, bandido, morto*, possivelmente relacionada a debates
pol√≠ticos e posicionamentos ideol√≥gicos.
***Extra√ß√£o de T√≥picos (BERTopic)*** : Realizamos a extra√ß√£o de t√≥picos,
obtendo 15 t√≥picos correspondentes, ordenados por sua frequ√™ncia
de ocorr√™ncia entre os coment√°rios, apresentados na Tabela 11.
Analisando coment√°rios em que se obteve discord√¢ncia total entre
os anotadores, os t√≥picos proporcionalmente mais relacionados
s√£o, em ordem decrescente: 14, 3, 1, 9 e 13. Enquanto os t√≥picos 3
e 1 s√£o mais gen√©ricos, relacionados a rotina, fam√≠lia e situa√ß√µes


59


-----

An√°lise de sentimentos de conte√∫do compartilhado em comunidades brasileiras do Reddit:
Avalia√ß√£o de um conjunto de dados rotulados por humanos WebMedia‚Äô2024, Juiz de Fora, Brazil


0 1 2 3 4 5 6 7 8 9 10 11 12 13 14

TÔøΩpico

(b) Sentimentos rotulados pelo modelo


Negativo

Neutro

Positivo


Negativo

Neutro

Positivo


0 1 2 3 4 5 6 7 8 9 10 11 12 13 14

TÔøΩpico

(a) Sentimentos rotulados por anotadores


80

60

40

20

0


80

60

40

20

0


**Figura 1: Compara√ß√£o de frequ√™ncia de sentimentos para cada t√≥pico entre anotadores e modelo.**


do cotidiano, os t√≥picos 14, 9 e 13 s√£o relacionados a pol√≠tica em
diferentes escopos: o t√≥pico 14 √© mais direcionado a ideologias
pol√≠ticas, sobretudo o nazismo; o t√≥pico 9 relaciona-se a ideia de
*fake news*, resultado de elei√ß√µes e partidos pol√≠ticos, e o t√≥pico 13
relata temas acerca de problem√°ticas e temas do governo durante a
presid√™ncia de Jair Bolsonaro.
J√° em rela√ß√£o aos coment√°rios em que houve concord√¢ncia total
entre anotadores, destacam-se os t√≥picos 11, 12, 7 e 2. Pelo conjunto
de palavras, em geral, trata-se de t√≥picos polarizados e que transmitem ideias positivas (t√≥pico 11) ou negativas (t√≥picos 7,2), al√©m
do t√≥pico 12, que apresenta cr√≠ticas a governos brasileiros.
Em rela√ß√£o √† an√°lise de t√≥picos, realizamos uma compara√ß√£o entre os dados anotados por humanos e pelo modelo XLM-RoBERTA,
como pode ser visualizado na Figura 1. Identificamos que os t√≥picos
5, 12 e 14, relacionados a quest√µes pol√≠ticas, foram rotulados como
*negativos* mais pelo modelo do que pela anota√ß√£o humana. J√° o t√≥pico 7, composto por palavr√µes e palavras que expressam conceitos
negativos no geral, como *odeio*, *pena*, *horr√≠vel*, apresentou maior
propor√ß√£o desse r√≥tulo entre anotadores, comparado ao modelo. Os
t√≥picos 3 (relacionados a conversas gerais sobre fam√≠lia e rotina)
e 4 (sobre quest√µes financeiras e mercado de trabalho), s√£o razoavelmente polarizados entre os anotadores, mas o modelo rotulou
mais como *negativos* .
Em rela√ß√£o aos coment√°rios em que ao menos um anotador rotulou como *N√£o sei dizer*, destacam-se os t√≥picos 10, 14 e 2. O t√≥pico 10
apresenta 32,6% de seus coment√°rios em que ao menos um anotador
rotulou como *N√£o sei dizer*, e apresenta conte√∫dos relacionados √†
crimes, xingamentos e conte√∫dos sexuais. J√° o t√≥pico 14, em que
30,4% de seus coment√°rios apresenta ao menos um r√≥tulo para *N√£o*
*sei dizer*, relaciona-se √† quest√µes ideol√≥gicas e pol√≠ticas. Por fim,
o t√≥pico 2, que apresenta 28% de seus coment√°rios com ao menos
um anotador indicando o r√≥tulo, apresenta conte√∫dos gen√©ricos
relacionados a g√≠rias e relatos do cotidiano. Em rela√ß√£o √† coment√°rios em que todos os anotadores assinalaram como *N√£o sei dizer*,
destacam-se 3 coment√°rios nos t√≥picos 2 e 3, geralmente relacionados a relatos e fatos do cotidiano e g√≠rias. Possivelmente por
apresentarem contextos muito espec√≠ficos dentro de uma postagem,
s√£o considerados mais dif√≠ceis de rotular.

***Rotula√ß√µes sem√¢nticas (PyMUSAS)*** : Para os resultados obtidos a
partir da categoriza√ß√£o sem√¢ntica dos coment√°rios, obteve-se, no
total, 163.704 rotula√ß√µes para n√≠veis sem√¢nticos gerais(principais
categorias sem√¢nticas, que excluem pontua√ß√µes, por exemplo), lembrando que cada palavra de cada coment√°rio apresenta uma ou mais
rotula√ß√µes poss√≠veis dentro do dom√≠nio das categorias do USAS [9] .

9 https://ucrel.lancs.ac.uk/usas/Lancaster_visual/Frames_Lancaster.htm


**Tabela 11: T√≥picos e termos mais frequentes.**

**T√≥pico** **Termos mais Frequentes**

0 pessoa, pessoas, ficar, nada, fazer, a√≠, coisa, ainda, vida, porque
**1** carro, acho, nunca, vou, uso, desse, lembro, sei, ver, achei
**2** burro, bozo, ai, and, of, p*ca, vem, comida, pode, coment√°rio
**3** nome, filho, crian√ßa, banho, banheiro, tomar, p*ta, durante, lembro, deve
**4** dinheiro, pagar, sal√°rio, fazer, trabalho, mercado, todos, ganhar, hist√≥ria, sobre
**5** brasil, pa√≠s, estado, eua, direita, pa√≠ses, r√∫ssia, china, nuclear, esquerda
**6** time, goleiro, jogo, gol, futebol, palmeiras, jogador, vasco, paulo, passado
**7** f*da, odeio, mano, t√¥, p*rra, pqp, tomara, gosto, pena, horr√≠vel
**8** palavras, entender, dia, 11, pois, pessoas, falando, palavra, pa√≠ses, comecei
**9** falou, entendi, falei, resultado, fake, hoje, disse, pt, pesquisa, dia
**10** bandido, quer, bunda, p*u, pq, m√£os, matar, passou, cima, bola
**11** obrigado, sorte, entendi, coment√°rios, man, respeito, espero, deus, feliz, boa
**12** lula, bolsonaro, bolsonarista, governo, aux√≠lio, gastos, mal, √©poca, presidente, contra
**13** popula√ß√£o, pol√≠tica, direito, popular, governo, pol√≠tico, sa√∫de, economia, bolsonaro, passar
**14** socialismo, amp, x200b, hitler, nacional, comunismo, alem√£es, contr√°rio, dizem, igreja

Considerando todos os coment√°rios, as categorias de maior ocorr√™ncia s√£o *nomes pr√≥prios, g√≠rias e palavr√µes*, que comp√µe 29,64%
das ocorr√™ncias totais, *termos abstratos, que abrangem a√ß√µes gerais,*
*afeto, classifica√ß√£o, avalia√ß√£o, compara√ß√£o, posse, import√¢ncia, faci-*
*lidade/dificuldade, grau, exclusividade e seguran√ßa*, que apresenta
17,6%, e *termos sociais, que abrangem a√ß√µes, estados e processos, reci-*
*procidade, participa√ß√£o, merecimento, tra√ßos de personalidade, pessoas,*
*relacionamentos, fam√≠lia, grupos, obriga√ß√£o, poder*, que apresenta
9,17% do total das ocorr√™ncias categorizadas.
Considerando apenas as anota√ß√µes de sentimentos, observa-se
grande relev√¢ncia das categorias *termos num√©ricos* e *julgamentos*
*de apar√™ncia e atributos f√≠sicos, como apar√™ncia, cor, forma, textura e*
*temperatura* na composi√ß√£o de coment√°rios rotulados como *positi-*
*vos* pelos anotadores. Nesse caso, a segunda categoria comp√µe 6,7%
de todas as rotula√ß√µes de classes para coment√°rios *positivos*, contra
1,9% em *negativos*, e 2,8% em *neutros* .
Em contrapartida, para os coment√°rios rotulados como *negativos*,
destacam-se as categorias *conceitos de movimento, localiza√ß√£o, via-*
*gem e transporte*, bem como *conceitos de clima e quest√µes ambientais* .
A primeira categoria constitui 9,5% de todas as ocorr√™ncias categorizadas em coment√°rios *negativos*, contra 3,3% para *positivos* e 5,0%
para *neutros* . Para coment√°rios rotulados como *neutros*, destacam-se,
em rela√ß√£o √†s propor√ß√µes de coment√°rios *negativos* e *positivos*, as
categorias *conceitos de ci√™ncia e tecnologia*, *conceitos de dinheiro, ne-*
*g√≥cios, trabalho e ind√∫stria*, assim como *termos abstratos, que abran-*
*gem a√ß√µes gerais, afeto, classifica√ß√£o, avalia√ß√£o, compara√ß√£o, posse,*
*import√¢ncia, facilidade/dificuldade, grau, exclusividade e seguran√ßa* .


60


-----

WebMedia‚Äô2024, Juiz de Fora, Brazil Giovana Piorino, Vitor Moreira, Luiz Henrique Quevedo Lima, Adriana Silvina Pagano, and Ana Paula Couto da Silva


Al√©m disso, a categoria composta por *nomes pr√≥prios, g√≠rias e*
*palavr√µes* constitui parte consider√°vel tanto de coment√°rios *po-*
*sitivos* (28,65% do total de coment√°rios positivos) quanto para *ne-*
*gativos* (29,9%). Assim, conceitos como g√≠rias, palavr√µes e nomes
pr√≥prios podem n√£o ser considerados caracter√≠sticas predominantes
para determinar o sentimento de um coment√°rio, visto que para ambos sentimentos, tais conceitos apresentam presen√ßa similar. Essa
quest√£o √© abordada ao comparar a anota√ß√£o humana com o modelo,
que classifica mais t√≥picos negativamente se forem constitu√≠dos
por alguns palavr√µes, acima da m√©dia da rotula√ß√£o humana para
negativos. Logo, tais padr√µes sem√¢nticos podem levar o modelo
a rotular coment√°rios como *negativos* excessivamente, devido √†
dificuldade de tratar tais padr√µes no texto.
Para coment√°rios em que houve discord√¢ncia total entre anotadores, temos as categorias *arquitetura, tipos de edif√≠cios e casas,*
*constru√ß√µes, resid√™ncia, m√≥veis e acess√≥rios dom√©sticos*, *conceitos de*
*dinheiro, neg√≥cios, trabalho e ind√∫stria* e *entretenimento em geral,*
*m√∫sica, teatro, esportes e jogos* . Considerando o total de ocorr√™ncias
da categoria *arquitetura, tipos de edif√≠cios e casas,constru√ß√µes, resi-*
*d√™ncia, m√≥veis e acess√≥rios dom√©sticos* para todos os coment√°rios,
12,38% deles participam da discord√¢ncia total. Para as categorias
*conceitos de dinheiro, neg√≥cios, trabalho e ind√∫stria* e *entretenimento*
*em geral, m√∫sica, teatro, esportes e jogos*, as porcentagens s√£o 10,37%
e 10,10%, respectivamente. Tais categorias comp√µem as propor√ß√µes
mais altas de discord√¢ncia total entre todas as categorias. Esses
resultados indicam certa dificuldade de concord√¢ncia de anota√ß√µes
em rela√ß√£o a assuntos espec√≠ficos que envolvem conhecimento de
mundo do anotador, como arquitetura, entretenimento e mercado
financeiro, por exemplo.
Por fim, a an√°lise de categorias predominantes nos coment√°rios
que os anotadores rotularam com *N√£o sei dizer* mostra predomin√¢ncia das categorias *conceitos art√≠sticos, artes, artesanato*, *alimentos, be-*
*bidas, tabaco e drogas, agricultura e horticultura* e *educa√ß√£o e estudos* .
### **5 CONCLUS√ïES E TRABALHOS FUTUROS**

Os achados da nossa pesquisa corroboram apontamentos na literatura sobre desenvolvimento de conjunto de dados por meio de anota√ß√£o humana em tarefas que envolvem grande subjetividade, como √©
a an√°lise de sentimentos. Um deles diz respeito √† concord√¢ncia entre
anotadores, que, em nosso estudo, se mostrou moderada de acordo
com os resultados do Alfa de Krippendorf e do Kappa de Fleiss.
Tamb√©m em rela√ß√£o √† composi√ß√£o do conjunto de dados, nossos
resultados mostram que quase metade do conjunto de coment√°rios
foi majoritariamente rotulado como *negativo*, indicando desbalanceamento de classes consider√°vel, podendo evidenciar um ambiente
mais nocivo de intera√ß√µes.
Ainda em rela√ß√£o aos resultados das m√©tricas de concord√¢ncia,
as anota√ß√µes obtiveram valores pr√≥ximos, apontando para concord√¢ncias m√©dias e moderadas entre seus respectivos anotadores. Em
rela√ß√£o √† incerteza, apenas em 4,1% dos coment√°rios, dois ou mais
anotadores rotularam o mesmo coment√°rio com *N√£o sei dizer*, o que
revelou dificuldade maior em 2 ou mais anotadores caracterizarem
incerteza de sentimento para um mesmo texto.
Na compara√ß√£o com os anotadores humanos, o modelo obteve
acur√°cia de 62,37% e Kappa de Cohen de 0,34, valores considerados
fracos. O modelo rotulou 60,90% dos coment√°rios como *negativos*,


taxa consideravelmente superior √† da anota√ß√£o humana, que foi
de 48,05%. De fato, determinados t√≥picos relacionados a quest√µes
pol√≠ticas foram rotulados como *negativos* mais pelo modelo do que
pela anota√ß√£o humana. O modelo tamb√©m mostrou dificuldade para
identificar corretamente coment√°rios *positivos* .
A caracteriza√ß√£o da linguagem dos coment√°rios revelou que o
tamanho dos coment√°rios categorizados como *negativos* e *positivos*
tendeu a ser maior do que o tamanho dos coment√°rios categorizados
como *neutros* e aqueles categorizados como *N√£o sei dizer* . O tamanho
do texto pode impactar a rotula√ß√£o, uma vez que quanto maior o
contexto, maior a chance de os rotuladores conseguirem fazer uma
interpreta√ß√£o e atribuir um sentimento.
No que diz respeito √†s classes de palavra mais frequentes em
cada tipo de sentimento, destacam-se os coment√°rios classificados
como *N√£o sei dizer*, que apresentaram, tanto predomin√¢ncia de entidades do tipo PER, bem como maior n√∫mero de etiquetas da classe
nome pr√≥prio (PROPN), o que pode sugerir que esses coment√°rios
demandam reconhecimento dessas entidades e, por consequ√™ncia,
conhecimento de mundo, para poder atribuir um sentimento, problema que parece ter sido enfrentado pelos anotadores.
A an√°lise de t√≥picos revelou que para os coment√°rios em que se
obteve discord√¢ncia total entre os anotadores, figura, em primeiro
lugar, o t√≥pico 14, que √© mais direcionado a ideologias pol√≠ticas.
Este resultado pode ser interpretado em rela√ß√£o aos achados sobre
o desempenho do modelo, que rotulou coment√°rios de quest√µes
pol√≠ticas como *negativos* em maior n√∫mero do que os anotadores
humanos. No que diz respeito aos coment√°rios em que ao menos
um anotador rotulou como *N√£o sei dizer*, sobressa√≠ram t√≥picos relacionados a crimes, xingamentos e conte√∫dos sexuais e a quest√µes
ideol√≥gicas e pol√≠ticas.
Em termos metodol√≥gicos, nosso estudo evidenciou que a qualidade das m√©tricas melhorou consideravelmente ao se separar o
conjunto de dados em dois subconjuntos e incluir apenas os coment√°rios rotulados com sentimentos, desconsiderando a categoria
*N√£o sei dizer* . O mesmo aconteceu com o c√°lculo do percentual de
concord√¢ncia total dos anotadores sobre um mesmo r√≥tulo, que foi
superior quando desconsiderada a categoria *N√£o sei dizer* .
Em conson√¢ncia com a literatura, nosso estudo corrobora a complexidade da tarefa de cria√ß√£o de conjunto de dados, dado o desafio
de se lidar com n√≠veis de concord√¢ncia moderados entre anotadores.

Para a consolida√ß√£o do conjunto de dados, o voto da maioria, ou a
agrega√ß√£o das distintas respostas, √© decis√≥rio para o r√≥tulo √∫nico de
refer√™ncia que ser√° adjudicado. Em tarefas que envolvem alto grau
de subjetividade, como √© o caso da an√°lise de sentimentos, a decis√£o pela maioria reduz a representatividade das diversas opini√µes
pass√≠veis de existir em uma popula√ß√£o ainda maior. Nesse sentido,
estudos recentes[ 10, 12 ] prop√µem uma mudan√ßa em dire√ß√£o a uma
abordagem mais inclusiva de todas as perspectivas dos anotadores
como alternativa √† maioria enquanto refer√™ncia ou *ground truth* .
Em trabalhos futuros, pretendemos explorar a perspectiviza√ß√£o de
forma a mitigar o problema do n√≠vel de concord√¢ncia entre anotadores.

**Agradecimentos:** Este trabalho foi parcialmente financiado pela
FAPEMIG, CAPES e CNPq.


61


-----

An√°lise de sentimentos de conte√∫do compartilhado em comunidades brasileiras do Reddit:
Avalia√ß√£o de um conjunto de dados rotulados por humanos WebMedia‚Äô2024, Juiz de Fora, Brazil

### **REFER√äNCIAS**

[1] Rafael J. A. Almeida. 2018. LeIA - L√©xico para Infer√™ncia Adaptada. https:
//github.com/rafjaa/LeIA.

[2] Jacob Amedie. 2015. The Impact of Social Media on Society. *Advanced Writing:*
*Pop Culture Intersections* (2015). https://scholarcommons.scu.edu/engl_176/2/

[3] Francesco Barbieri, Luis Espinosa Anke, and Jose Camacho-Collados. 2022. XLMT: Multilingual Language Models in Twitter for Sentiment Analysis and Beyond.
In *Proceedings of the Thirteenth Language Resources and Evaluation Conference* .
European Language Resources Association, Marseille, France, 258‚Äì266.

[4] Jason Baumgartner, Savvas Zannettou, Brian Keegan, Megan Squire, and Jeremy
Blackburn. 2020. The pushshift reddit dataset. In *Proceedings of the international*
*AAAI conference on web and social media*, Vol. 14. 830‚Äì839.

[5] Victoria Bobicev and Marina Sokolova. 2017. Inter-Annotator Agreement in
Sentiment Analysis: Machine Learning Perspective. In *Recent Advances in Natural*
*Language Processing* . 97‚Äì102. https://doi.org/10.26615/978-954-452-049-6_015

[6] Dorottya Demszky, Dana Movshovitz-Attias, Jeongwoo Ko, Alan Cowen, Gaurav
Nemade, and Sujith Ravi. 2020. GoEmotions: A Dataset of Fine-Grained Emotions.
arXiv:2005.00547

[7] Joseph L Fleiss. 1971. Measuring nominal scale agreement among many raters.
*Psychological bulletin* 76, 5 (1971), 378.

[8] Joseph L. Fleiss. 1975. Measuring Agreement between Two Judges on the Presence
or Absence of a Trait. *Biometrics* 31, 3 (1975), 651‚Äì659. http://www.jstor.org/
stable/2529549

[9] E Fonseca, L Santos, Marcelo Criscuolo, and S Aluisio. 2016. ASSIN: Avaliacao
de similaridade semantica e inferencia textual. In *Computational Processing of the*
*Portuguese Language-12th International Conference, Tomar, Portugal* . 13‚Äì15.

[10] Tommaso Fornaciari, Alexandra Uma, Silviu Paun, Barbara Plank, Dirk Hovy, and
Massimo Poesio. 2021. Beyond Black & White: Leveraging Annotator Disagreement via Soft-Label Multi-Task Learning. In *Proceedings of the 2021 Conference*
*of the North American Chapter of the Association for Computational Linguistics:*
*Human Language Technologies*, Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-Tur, Iz Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy
Chakraborty, and Yichao Zhou (Eds.). Association for Computational Linguistics,
Online, 2591‚Äì2597. https://doi.org/10.18653/v1/2021.naacl-main.204

[11] Claudia Freitas, Paulo Rocha, and Eckhard Bick. 2008. A new world in Floresta
Sint√°(c)tica ‚Äì the Portuguese treebank. *Calidosc√≥pio* 6, 3 (2008), 142‚Äì148. https:
//doi.org/10.4013/cld.20083.03

[12] Simona Frenda, Alessandro Pedrani, Valerio Basile, Soda Marem Lo, Alessandra Teresa Cignarella, Raffaella Panizzon, Cristina Marco, Bianca Scarlini, Viviana
Patti, Cristina Bosco, and Davide Bernardi. 2023. EPIC: Multi-Perspective Annotation of a Corpus of Irony. In *Proceedings of the 61st Annual Meeting of the*
*Association for Computational Linguistics (Volume 1: Long Papers)*, Anna Rogers,
Jordan Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational
Linguistics, Toronto, Canada, 13844‚Äì13857. https://doi.org/10.18653/v1/2023.acllong.774

[13] Jeffrey E. F. Friedl. 2006. *Mastering regular expressions* (3 ed.). O‚ÄôReilly Media.

[14] Klaifer Garcia and Lilian Berton. 2021. Topic detection and sentiment analysis
in Twitter content related to COVID-19 from Brazil and the USA. *Applied Soft*
*Computing* 101 (2021), 107057. https://doi.org/10.1016/j.asoc.2020.107057

[15] Maarten Grootendorst. 2022. BERTopic: Neural topic modeling with a class-based
TF-IDF procedure. *arXiv preprint arXiv:2203.05794* (2022).

[16] Clayton Hutto and Eric Gilbert. 2014. Vader: A parsimonious rule-based model
for sentiment analysis of social media text. In *Proceedings of the international*
*AAAI conference on web and social media*, Vol. 8. 216‚Äì225.

[17] Ant√¥nio Pereira De Souza J√∫nior, Pablo Cecilio, Felipe Viegas, Washington Cunha,
Elisa Tuler De Albergaria, and Leonardo Chaves Dutra Da Rocha. 2022. Evaluating
Topic Modeling Pre-processing Pipelines for Portuguese Texts. In *Proceedings of*
*the Brazilian Symposium on Multimedia and the Web* (Curitiba, Brazil) *(WebMedia*
*‚Äô22)* . Association for Computing Machinery, New York, NY, USA, 191‚Äì201. https:
//doi.org/10.1145/3539637.3557052

[18] Simon Kemp. 2024. Digital 2024 April Global Statshot Report. https://datareportal.
com/reports/digital-2024-april-global-statshot Acessado em: 13/06/2024.

[19] Adam D. I. Kramer, Jamie E. Guillory, and Jeffrey T. Hancock. 2014. Experimental
evidence of massive-scale emotional contagion through social networks. *Procee-*
*dings of the National Academy of Sciences* 111, 24 (2014). https://doi.org/10.1073/
pnas.1320040111

[20] Klaus Krippendorff. 2004. *Content Analysis: An Introduction to Its Methodology*
*(second edition)* . Sage Publications.

[21] Luiz Henrique Quevedo Lima, Adriana Silvina Pagano, and Ana Paula Couto da
Silva. 2024. Toxic Content Detection in online social networks: a new dataset from
Brazilian Reddit Communities. In *Proceedings of the 16th International Conference*
*on Computational Processing of Portuguese* . 472‚Äì482.

[22] M Martella, F Bert, G Colli, G Lo Moro, A Pagani, R Tatti, G Scaioli, and R
Siliquini. 2021. Consequences of cyberaggression on Social Network on mental
health of Italian adults. *European Journal of Public Health* 31 (2021). https:
//doi.org/10.1093/eurpub/ckab165.589



[23] Philip May. 2021. Machine translated multilingual STS benchmark dataset. https:
//github.com/PhilipMay/stsb-multi-mt

[24] Negar Mokhberian, Myrl G Marmarelis, Frederic R Hopp, Valerio Basile, Fred
Morstatter, and Kristina Lerman. 2023. Capturing perspectives of crowdsourced
annotators in subjective learning tasks. *arXiv preprint arXiv:2311.09743* (2023).

[25] NLTK. 2023. NLTK - Sample usage for tokenize. https://www.nltk.org/howto/
tokenize.html Acessado em: 22/06/2024.

[26] NLTK. 2023. NLTK - stopwords. https://www.nltk.org/search.html?q=stopwords
Acessado em: 24/06/2024.

[27] Joel Nothman, Nicky Ringland, Will Radford, Tara Murphy, and James R Curran.
2013. Learning multilingual named entity recognition from Wikipedia. *Artificial*
*Intelligence* 194 (2013), 151‚Äì175.

[28] Slav Petrov, Dipanjan Das, and Ryan McDonald. 2011. A universal part-of-speech
tagset. *arXiv preprint arXiv:1104.2086* (2011).

[29] Scott Piao, Francesca Bianchi, Carmen Dayrell, Angela D‚ÄôEgidio, and Paul Rayson.
2015. Development of the Multilingual Semantic Annotation System. In *Proce-*
*edings of the 2015 Conference of the North American Chapter of the Association*
*for Computational Linguistics: Human Language Technologies*, Rada Mihalcea,
Joyce Chai, and Anoop Sarkar (Eds.). Association for Computational Linguistics,
Denver, Colorado, 1268‚Äì1274. https://doi.org/10.3115/v1/N15-1137

[30] Alexandre Rademaker, Fabricio Chalub, Livy Real, Cl√°udia Freitas, Eckhard Bick,
and Valeria De Paiva. 2017. Universal Dependencies for Portuguese. In *Proceedings*
*of the Fourth International Conference on Dependency Linguistics (Depling)* . Pisa,
Italy, 197‚Äì206. http://aclweb.org/anthology/W17-6523

[31] Livy Real, Erick Fonseca, and Hugo Goncalo Oliveira. 2020. The assin 2 shared
task: a quick overview. In *International Conference on Computational Processing*
*of the Portuguese Language* . Springer, 406‚Äì412.

[32] Reddit. 2023. Transparency Report: July to December 2023. https://www.
redditinc.com/policies/transparency-report-july-to-december-2023 Acessado
em: 13/06/2024.

[33] Shabnoor Siddiqui and Tajinder Singh. 2016. Social Media its Impact with Positive
and Negative Aspects. *International Journal of Computer Applications Techno-*
*logy and Research* 5 (2016), 71‚Äì75. https://jogamayadevicollege.ac.in/uploads/
1586197536.pdf

[34] Scott Songlin Piao, Paul Edward Rayson, Dawn Archer, Francesca Bianchi, Carmen Dayrell, Mahmoud El-Haj, Ricardo-Mar√≠a Jim√©nez-Y√°√±ez, Dawn Knight,
Michal K≈ôen, Laura Lofberg, et al . 2016. Lexical Coverage Evaluation of Largescale Multilingual Semantic Lexicons for Twelve Languages. In *Proceedings of the*
*Tenth International Conference on Language Resources and Evaluation (LREC 2016)*
(Portoro≈æ, Slovenia, 23-28). European Language Resources Association (ELRA),
Paris, France.

[35] F√°bio Souza, Rodrigo Nogueira, and Roberto Lotufo. 2020. BERTimbau: pretrained
BERT models for Brazilian Portuguese. In *9th Brazilian Conference on Intelligent*
*Systems, BRACIS, Rio Grande do Sul, Brazil, October 20-23 (to appear)* .

[36] Marlo Souza and Renata Vieira. 2012. Sentiment Analysis on Twitter Data for
Portuguese Language. In *Computational Processing of the Portuguese Language*,
Helena Caseli, Aline Villavicencio, Ant√≥nio Teixeira, and Fernando Perdig√£o
(Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 241‚Äì247.

[37] spaCy. 2023. Portuguese Models. https://spacy.io/models/pt. Acessado em:
22/06/2024.

[38] Ronald J. Tallarida and Rodney B. Murray. 1987. *Mann-Whitney Test* . Springer New
York, New York, NY, 149‚Äì153. https://doi.org/10.1007/978-1-4612-4974-0_46

[39] X. 2024. DSA Transparency Report - April 2024. https://transparency.x.com/dsatransparency-report.html Acessado em: 14/06/2024.

[40] Yinfei Yang, Daniel Cer, Amin Ahmad, Mandy Guo, Jax Law, Noah Constant, Gustavo Hernandez Abrego, Steve Yuan, Chris Tar, Yun-Hsuan Sung, et al . 2019. Multilingual Universal Sentence Encoder for Semantic Retrieval. arXiv:1907.04307


62


-----

