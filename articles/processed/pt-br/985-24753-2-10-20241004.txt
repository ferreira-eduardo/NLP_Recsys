# **Estrat√©gias de Undersampling para Redu√ß√£o de Vi√©s em** **Classifica√ß√£o de Texto Baseada em Transformers**

## Washington Cunha
#### washingtoncunha@dcc.ufmg.br UFMG Minas Gerais, Brazil

## Guilherme Fonseca
#### guilhermefonseca8426@aluno.ufsj.edu.br UFSJ Minas Gerais, Brazil

## Gabriel Prenassi
#### prenassigabriel@aluno.ufsj.edu.br UFSJ Minas Gerais, Brazil

## Marcos Andr√© Gon√ßalves
#### mgoncalv@dcc.ufmg.br UFMG Minas Gerais, Brazil
### **ABSTRACT**

Automatic Text Classification (ATC) in unbalanced datasets is a
common challenge in real-world applications. In this scenario, one
(or more) class(es) is overrepresented, which usually causes a bias
in the learning process towards these majority classes. This work
investigates the effect of undersampling methods, which aim to
reduce instances of the majority class, on the effectiveness of recent
ATC methods. Through a systematic mapping of the literature, we
selected and implemented 15 undersampling strategies. We also
propose two new strategies and compare all 17 methods using
RoBERTa as sentiment analysis classifier. Our results suggest that
a set of undersampling approaches is capable of significantly reducing the learning bias of ATC methods towards the majority class on
imbalanced datasets, without incurring any effectiveness loss, and
with improvements in efficiency and reduction of carbon emissions.
### **KEYWORDS**

Classifica√ß√£o de Texto, Transformers, Undersampling
### **1 INTRODU√á√ÉO**

Classifica√ß√£o Autom√°tica de Texto (CAT) [ 16, 29 ] tem experimentado uma grande evolu√ß√£o nos √∫ltimos anos, com √™nfase em estrat√©gias supervisionadas motivadas por avan√ßos em aprendizagem
profunda baseados em *Transformers* [ 11, 25 ]. Essas estrat√©gias se
beneficiaram de aplica√ß√µes que constantemente produzem grandes
volumes de dados rotulados (por exemplo, redes sociais), nos quais
os usu√°rios podem classificar manualmente mensagens, an√∫ncios
e produtos, produzindo um grande volume de anota√ß√µes. √Ä medida
que a quantidade de dados aumenta, estrat√©gias de CAT baseadas
em *Transformers* tornam-se mais eficazes, superando significativamente m√©todos tradicionais de CAT [ 30 ], tais como Regress√£o
Log√≠stica, KNN, *Random Forest* e *SVM* [7].
Apesar dos enormes avan√ßos de efetividade alcan√ßados pelo uso
de *Transformers* em CAT, o impacto dessas novas abordagens em
problemas tradicionais de classifica√ß√£o, como o vi√©s de aprendizado

In: Proceedings of the Brazilian Symposium on Multimedia and the Web (WebMe
dia‚Äô2024). Juiz de Fora, Brazil. Porto Alegre: Brazilian Computer Society, 2024.
¬© 2024 SBC ‚Äì Sociedade Brasileira de Computa√ß√£o.
ISSN 2966-2753

## Leonardo Rocha
#### lcrocha@ufsj.edu.br UFSJ Minas Gerais, Brazil

oriundo de cole√ß√µes de dados desbalanceadas, tem sido pouco estudado [ 5 ]. Em cole√ß√µes de dados desbalanceadas, as classes minorit√°rias podem ser sub-representadas no processo de aprendizado,
resultando em modelos com baixa capacidade de generaliza√ß√£o,
enviesados para as classes majorit√°rias. Al√©m de quest√µes √©ticas
relacionadas a modelos enviesados [ 14 ], existem diversos cen√°rios
em que a classe minorit√°ria √© a classe de interesse.
Por exemplo, na √°rea de sa√∫de, a predi√ß√£o de doen√ßas √© geralmente uma tarefa desbalanceada [42], dado que a maioria das pessoas s√£o saud√°veis ou pelo menos n√£o apresentam a condi√ß√£o de
interesse. Nesse caso, existe a tend√™ncia de um modelo treinado com
uma amostra de dados reflita essa distribui√ß√£o, sendo enviesado
para a classe ‚Äúsaud√°vel‚Äù. Um modelo de classifica√ß√£o enviesado pode
ser bastante acurado apenas predizendo a classe majorit√°ria, por√©m
o impacto de um falso negativo (pacientes portadores da doen√ßa erroneamente diagnosticados como n√£o portadores) √© muito alto[ 42 ].
Outro exemplo s√£o aplica√ß√µes relacionadas √† an√°lise de sentimento, foco do presente trabalho. Em cen√°rios de produtos [ 13, 27 ]
e pontos de interesse (POI) [ 18 ], usu√°rios comumente tomam suas
decis√µes de consumo analisando coment√°rios e avalia√ß√µes de outros
usu√°rios. Alguns usu√°rios levam mais em considera√ß√£o as avalia√ß√µes
classificadas como positivas (e.g., pontos positivos de um hotel), outros as avalia√ß√µes negativas (por que n√£o comprar certo produto?).
Em ambas as situa√ß√µes a classe alvo pode ser a minorit√°ria e o resultado de classifica√ß√£o de um modelo enviesado poder√° influenciar
de forma equivocada a decis√£o do usu√°rio.
Assim, a primeira pergunta de pesquisa que procuramos responder √© *PP1: Como algoritmos estado da arte recentes, baseados em*
*Transformers, s√£o afetados pelo desbalanceamento de classes em tare-*
*fas de an√°lise de sentimentos? H√° espa√ßo para melhorias?* .
Para responder esta pergunta, comparamos o desempenho de
seis m√©todos de classifica√ß√£o tradicionais (KNN, *Random Forest*, Regress√£o Log√≠stica, Support Vector Machine (SVM), XGBoost e LightGBM) e tr√™s m√©todos baseados em *Transformers* (RoBERTa [ 25 ],
BART [ 23 ] e BERT [ 11 ]), avaliando tanto a efetividade (em termos
de MacroF1) quanto o vi√©s dos modelos resultantes (em termos
de TPRGap, uma m√©trica que captura o vi√©s a partir da diferen√ßa
absoluta entre o TPR - *True Positive Rate* - das classes [21]).
Nossos resultados mostram que modelos baseados em *Transform-*
*ers*, al√©m de efetivos, possuem um vi√©s menor quando comparados
a modelos gerados por classificadores tradicionais. No entanto, nossos resultados tamb√©m apontam que, apesar disso, ainda h√° espa√ßo


144


-----

WebMedia‚Äô2024, Juiz de Fora, Brazil Guilherme Fonseca, Gabriel Prenassi, Washington Cunha, Marcos Andr√© Gon√ßalves, & Leonardo Rocha


consider√°vel para melhorias, principalmente em bases de dados
que possuem um elevado grau de desbalanceamento (raz√£o entre
n√∫mero de documentos da classe majorit√°ria e o n√∫mero de documentos da classe minorit√°ria superior a 5).
Existem duas principais abordagens utilizadas para lidar com
o desbalanceamento de dados. O *oversampling* consiste em criar
novas amostras (geralmente sint√©ticas) da classe minorit√°ria, para
igual√°-la em termos de inst√¢ncias √† classe majorit√°ria [ 15 ]. Essa
abordagem incorre em um aumento significativo no tempo de gera√ß√£o dos modelos, uma vez que aumenta-se o total de inst√¢ncias a
serem consideradas no aprendizado. Mais ainda, a gera√ß√£o sint√©tica
de novos dados, principalmente textuais, pode ser n√£o trivial [12].
A abordagem alternativa para enfrentar o desbalanceamento √© o
*undersampling* (US), foco do presente trabalho, que s√£o t√©cnicas que
reduzem inst√¢ncias da classe majorit√°ria para equilibrar as classes.
At√© onde sabemos, n√£o existem estudos na literatura que abordam
como os m√©todos de *undersampling* interagem com os algoritmos
de CAT do estado da arte baseados em *Transformers* . Assim, nossa
segunda pergunta de pesquisa √© *PP2: M√©todos de undersampling,*
*aplicados juntamente com classificadores baseados em Transformers,*
*s√£o capazes de reduzir o vi√©s dos modelos de classifica√ß√£o? Qual o*
*impacto dessa combina√ß√£o na efetividade do modelo?*
Para responder a PP2, primeiramente realizamos uma revis√£o
sistem√°tica sobre os principais m√©todos de *undersampling* propostos na literatura. Identificamos e implementamos 14 m√©todos de
*undersampling* que est√£o entre os mais utilizados. Apesar de terem
fins diferentes, as √°reas de sele√ß√£o de inst√¢ncias (SI) [ 8 ] e *undersam-*
*pling* s√£o bastante relacionadas, pois ambas tratam de t√©cnicas que
visam selecionar um subconjunto de dados representativos ‚Äì o que
as difere s√£o os objetivos da redu√ß√£o. Nesse sentido, adaptamos uma
estrat√©gia de SI, que √© considerada estado da arte, para o cen√°rio de
*undersampling*, o E2SC [ 6 ]. Por fim, propomos duas novas estrat√©gias de *undersampling*, que s√£o contribui√ß√µes desse trabalho: (1) a
UBR ( *Undersampling* Baseado em Redund√¢ncia), que se concentra
em remover inst√¢ncias da classe majorit√°ria consideradas redundantes (muito similares √† outras inst√¢ncias); e (2) E2SC-RL, uma varia√ß√£o do m√©todo de SI E2SC que realiza o c√°lculo das probabilidades
das inst√¢ncias serem removidas por meio de Regress√£o Log√≠stica.
Investigamos o desempenho das 17 t√©cnicas de *undersampling*
em conjunto com o RoBERTa, classificador baseado em *Transform-*
*ers* considerado estado da arte em an√°lise de sentimentos [ 26 ]. De
fato, *benchmarks* recentes [ 10, 26 ] demonstraram que as diferen√ßas
entre as novas vers√µes desses *Transformers* (incluindo RoBERTa,
BERT, DistilBERT, BART, AlBERT e XLNet) em diversos conjuntos
de dados utilizados em nossos experimentos s√£o muito pequenas.
Nossos resultados apontaram que os m√©todos de *undersampling*
NM1 [ 28 ], NM2 [ 28 ], E2SC [ 6 ], E2SC-RL (nossa proposta) e UBR
(nossa proposta) foram capazes de reduzir o vi√©s do modelo de
classifica√ß√£o, mantendo sua efetividade.
M√©todos de CAT baseados em *Transformers* demandam elevado
custo computacional no processo de aprendizado dos modelos de
classifica√ß√£o, resultando em longos tempos de execu√ß√£o e tamb√©m
contribuindo significativamente para a emiss√£o de carbono na atmosfera [ 1 ]. Assim, precisamos investigar o impacto desse novo
passo de pr√©-processamento na efici√™ncia (i.e. tempo e custo computacional para gera√ß√£o e classifica√ß√£o) dos modelos. Dessa forma,


nossa terceira pergunta de pesquisa √©: *PP3: Qual o impacto da apli-*
*ca√ß√£o dessa etapa adicional de pr√©-processamento (undersampling)*
*em termos de efici√™ncia? E em termos da emiss√£o de carbono?* .
Nossos resultados apontam que o uso de algumas das estrat√©gias
de *undersampling*, mais especificamente UBR, NM1, E2SC-RL, NM2
e E2SC, que foram capazes n√£o apenas de reduzir o vi√©s sem perda
de efetividade, mas tamb√©m diminu√≠ram significativamente o tempo
de treinamento dos modelos (50% em m√©dia), o que, consequentemente, contribuiu para redu√ß√£o na emiss√£o de *ùê∂ùëÇ* 2 (50%, em m√©dia)
durante a gera√ß√£o e execu√ß√£o dos modelos de classifica√ß√£o.
Assim, as principais contribui√ß√µes deste trabalho s√£o:

  - Mapeamento sistem√°tico da literatura sobre m√©todos de *un-*
*dersampling*, identificando e implementando 14 m√©todos que
est√£o entre os mais utilizados. Identificamos e adaptamos
tamb√©m um m√©todo de sele√ß√£o de inst√¢ncias para a tarefa
de *undersampling* ;

   - Propostas de duas novas estrat√©gias de *undersampling* ;

  - Avalia√ß√£o das t√©cnicas de *undersampling* em conjunto com
classificadores baseado em *Transformers* sob tr√™s perspectivas: (1) efetividade da classifica√ß√£o; (2) efici√™ncia (tempo); e
(3) capacidade de generaliza√ß√£o (vi√©s).
### **2 LEVANTAMENTO DAS ESTRAT√âGIAS**

Nesta se√ß√£o, detalhamos o processo de revis√£o sistem√°tica da literatura (RSL) [ 7, 8 ] para selecionar quais estrat√©gias de *undersampling*
e sele√ß√£o de inst√¢ncias que ser√£o avaliadas.
### **2.1 M√©todos de Undersampling**

Recorremos ao mecanismo de pesquisa do Google Scholar para submeter a consulta e gerar nosso conjunto inicial de artigos. O Google
Scholar foi escolhido devido √† sua ampla cobertura, abrangendo as
principais bibliotecas digitais de editoras como ACM, IEEE e Elsevier, al√©m de reposit√≥rios de pr√©-impress√£o como Arxiv. A *string* de
busca utilizada foi " *Undersampling* " e, para maximizar a abrang√™ncia
da pesquisa, o mecanismo de busca n√£o aplicou nenhum filtro de
local ou ano. Com base nisso, coletamos, inicialmente, um total de
500 artigos √∫nicos que, de alguma forma, utiliza alguma estrat√©gia
de *undersampling* .
Analisamos manualmente os 500 artigos, procurando identificar
os mais pertinentes para o estudo. Um artigo foi considerado **rel-**
**evante** caso utilizasse t√©cnicas de *undersampling* para reduzir desbalanceamento, sendo que o m√©todo de *undersampling* empregado
deveria ser explicitamente mencionado (citado). Identificamos 139
artigos relevantes e, a partir deles, enumeramos todas as t√©cnicas de *undersampling* utilizadas, encontrando, ao todo, 32 t√©cnicas
diferentes. Uma tabela completa com uma descri√ß√£o de todas as
estrat√©gias identificadas est√° dispon√≠vel online [1] . Optamos por considerar em nossa avalia√ß√£o aqueles que foram utilizados em mais
de um dos trabalhos relevantes. Faremos nossa avalia√ß√£o sobre os
seguintes m√©todos:

**- Links de Tomek (TL) [** **37** **]:** dados dois exemplos *ùëí* *ùëñ* e *ùëí* *ùëó* de diferentes classes, com *ùëë* ( *ùëí* *ùëñ* *,ùëí* *ùëó* ) representando a dist√¢ncia entre *ùëí* *ùëñ* e *ùëí* *ùëó*,
um par *ùê¥* ( *ùëí* *ùëñ* *,ùëí* *ùëó* ) √© chamado de link de Tomek se n√£o houver nenhum exemplo *ùëí* *ùëô* tal que *ùëë* ( *ùëí* *ùëñ* *,ùëí* *ùëô* ) *< ùëë* ( *ùëí* *ùëñ* *,ùëí* *ùëó* ) ou *ùëë* ( *ùëí* *ùëó* *,ùëí* *ùëô* ) *< ùëë* ( *ùëí* *ùëñ* *,ùëí* *ùëó* ).

1 https://github.com/guilherme8426/Undersampling


145


-----

Estrat√©gias de Undersampling para Redu√ß√£o de Vi√©s em Classifica√ß√£o de Texto Baseada em Transformers WebMedia‚Äô2024, Juiz de Fora, Brazil


Se dois exemplos formam um link de Tomek, ent√£o ou um desses exemplos foi classificado manualmente errado ou ambos s√£o exemplos
pertencentes √† fronteiras entre as classes e podem ser removidos.

**- Condensed Nearest Neighbors (CNN)[** **17** **]:** O conjunto de dados *ùëÜ* √© inicializado com um exemplo da classe majorit√°ria e todos
os exemplos da classe minorit√°ria e um conjunto *ùëá* √© criado com os
elementos que n√£o pertencem a *ùëÜ* . Cada exemplo de *ùëá* √© classificado
pelo KNN usando *ùëÜ* como conjunto de treinamento. Caso o KNN
acerte a classe do exemplo, ele permanece em *ùëá* ; caso contr√°rio, o
exemplo √© removido de *ùëá* e colocado em *ùëÜ* . Esse processo se repete
at√© que n√£o ocorram mais mudan√ßas no conjunto *ùëÜ* . Ao final, os
elementos de *ùëá* s√£o descartados.

**- One-Sided Selection (OSS)[** **20** **]:** Combina o TL e uma varia√ß√£o do
CNN. inicialmente, como no CNN, um conjunto *ùëÜ* √© inicializado com
todas as inst√¢ncias da classe minorit√°ria e uma da classe majorit√°ria
e um conjunto *ùëá* com o restante dos elementos, depois as inst√¢ncias
de *ùëá* s√£o classificadas com o KNN treinado em *ùëÜ* e cada inst√¢ncia
classificada erroneamente √© colocada em *ùëÜ* . No final, o TL √© utilizado
em *ùëÜ* para identificar pares amb√≠guos na fronteira da classe.

**- Edited Nearest Neighbours (ENN)[** **39** **]:** insere todas as inst√¢ncias do conjunto original *ùëá* no conjunto de solu√ß√£o *ùëÜ*, utilizando
o KNN de maneira iterativa para classificar todas as inst√¢ncias *ùë•*
dado que *ùë•* ‚àà *ùëÜ* e que *ùë•* perten√ßa a classe majorit√°ria (considerando
o conjunto { *ùëÜ* ‚àí{ *ùë•* }} como poss√≠veis vizinhos). Por fim, remove as
inst√¢ncias classificadas incorretamente.

**- Repeated Edited Nearest Neighbours (RENN)[** **36** **]:** ENN aplicado sucessivamente at√© que n√£o seja poss√≠vel remover mais pontos.

**- ALL k-NN [** **36** **]:** ENN aplicado sucessivamente, mas, a cada aplica√ß√£o, o n√∫mero de vizinhos a serem considerados aumenta.

**- Neighbourhood Cleaning Rule (NCR)[** **22** **]:** Utiliza o KNN para
classificar todas as inst√¢ncias da base de dados. Caso a classe prevista seja diferente da classe real e a inst√¢ncia perten√ßa √† classe
majorit√°ria, a inst√¢ncia √© eliminada. O NCR classifica tamb√©m as
inst√¢ncias da classe minorit√°ria. Se a classifica√ß√£o estiver incorreta, o m√©todo elimina os vizinhos mais pr√≥ximos da inst√¢ncia que
pertencem √† classe majorit√°ria.

**- Near Miss (NM)[** **28** **]:** tr√™s m√©todos de *undersampling* s√£o propostos. O NearMiss-1 (NM1) remove as inst√¢ncias da classe majorit√°ria
que t√™m a menor dist√¢ncia m√©dia entre as k inst√¢ncias da classe
minorit√°ria. O NearMiss-2 (NM2) seleciona os elementos da classe
majorit√°ria cuja dist√¢ncia m√©dia para os k pontos mais distantes
da classe minorit√°ria √© a mais baixa. J√° o NearMiss-3 (NM3) calcula,
para cada inst√¢ncia da classe minorit√°ria, as k inst√¢ncias da classe
majorit√°ria mais pr√≥ximas e as mant√©m na base de dados.

**- SBC [** **41** **]:** Todo o conjunto de treino √© dividido em N *clusters* . Para
cada um dos *clusters*, o n√∫mero de inst√¢ncias a serem selecionadas
√© calculado com base no n√∫mero de amostras da classe majorit√°ria
e da classe minorit√°ria que existem no *cluster* . Ap√≥s isso, exemplos
da classe majorit√°ria s√£o selecionados aleatoriamente. Por fim, o
algoritmo combina as inst√¢ncias selecionadas de cada *cluster* com
as da classe minorit√°ria para formar um novo conjunto.

**- IHT [** **35** **]:** Utiliza um classificador (c) para obter o *instance hard-*
*ness* (IH) de cada inst√¢ncia. O IH de uma inst√¢ncia √© dado por
*ùêºùêª* ( *< ùë•* *ùëñ* *,ùë¶* *ùëñ* *>* ) = 1 ‚àí *ùëù* ( *ùë¶* *ùëñ* | *ùë•* *ùëñ* *,ùëê* ) onde *ùëù* ( *ùë¶* *ùëñ* | *ùë•* *ùëñ* *,ùëê* ) denota a probabilidade, gerada pelo classificador c, da inst√¢ncia *ùë•* *ùëñ* pertencer √† classe
*ùë¶* *ùëñ* . O IHT seleciona amostras da classe majorit√°ria com baixa probabilidade de pertencerem √† classe majorit√°ria para serem removidas.



**- CC-NN [** **24** **]:** As inst√¢ncias da classe majorit√°ria s√£o divididas em
N *clusters*, com N sendo o n√∫mero de inst√¢ncias da classe minorit√°ria.
Ap√≥s isso, o vizinho mais pr√≥ximo do centr√≥ide de cada um dos
*clusters* que perten√ßa √† classe majorit√°ria √© escolhido para compor,
junto com as inst√¢ncias da classe minorit√°ria, o conjunto final.

**- OBU [** **38** **]:** Utiliza o Fuzzy c-means para dividir os dados em 2 *clus-*
*ters*, onde o *cluster* que tiver mais inst√¢ncias da classe minorit√°ria
√© chamado de *ùê∂ùëÄ* . Depois disso, o algoritmo remove todas as inst√¢ncias da classe majorit√°ria cujo grau de pertencimento para o
CM √© menor que *ùõº* (hiperpar√¢metro).
### **2.2 M√©todos de sele√ß√£o de inst√¢ncia**

Apesar de terem fins diferentes, as √°reas de sele√ß√£o de inst√¢ncias
(SI) e *undersampling* (US) s√£o relacionadas, pois tratam de t√©cnicas que visam selecionar um subconjunto de dados a ser usado no
treinamento do modelo e que cumpram seus objetivos: (1) no caso
de SI, melhorar a efici√™ncia sem perda de efetividade; e (2) no caso
de US, reduzir o vi√©s da classe majorit√°ria, mantendo a efetividade.
Apesar dos objetivos finais serem diferentes, partimos da hip√≥tese
de que h√° uma rela√ß√£o subjacente entre ambas as tarefas, principalmente para m√©todos de SI baseados em redu√ß√£o de redund√¢ncia [ 8 ],
que podem ser adaptados para remo√ß√£o de inst√¢ncias redundantes
da classe majorit√°ria. Essa hip√≥tese norteia a concep√ß√£o do nosso
novo m√©todo de US - UBR - descrito na pr√≥xima se√ß√£o e tamb√©m nos
motivou a selecionar e adaptar trabalhos de SI para *undersampling* .
Uma varredura na literatura de SI aplicada a CAT nos revela
que o m√©todo E2SC [ 6, 32 ] √© o estado da arte. O m√©todo funciona
em duas etapas. Na primeira, calcula as probabilidades de cada inst√¢ncia ser removida. Estas probabilidades s√£o obtidas por meio da
confian√ßa do classificador KNN, que √© calibrado (classificador cujas
previs√µes de probabilidade de classe correspondem bem √† acur√°cia
do classificador) [ 34 ]. Na segunda etapa, o E2SC tenta estimar qual
a taxa de redu√ß√£o √≥tima para a base de dados. Ap√≥s isso, as inst√¢ncias s√£o amostradas aleatoriamente, ponderadas pela probabilidade
encontrada no primeiro passo. Para o nosso trabalho, realizamos
uma modifica√ß√£o do E2SC, chamada E2SC_RL, que segue o mesmo
princ√≠pio do E2SC, por√©m, em vez do KNN como classificador, utilizaremos Regress√£o Log√≠stica (RL). Optamos por essa abordagem
ser um classificador igualmente calibrado e possuir baixo custo computacional, inferior ao KNN. Portanto, consideramos em nossos
experimentos o E2SC e o E2SC_RL, ambos adaptados para remover
apenas inst√¢ncias da classe majorit√°ria. Al√©m de todos as estrat√©gias apresentadas nesta se√ß√£o, apresentamos a seguir nossa nova
proposta de estrat√©gia de *undersampling* .
### **3 M√âTODO PROPOSTO**

Nesta se√ß√£o, apresentamos nossa segunda contribui√ß√£o neste trabalho, uma nova abordagem denominada UBR ( *Undersampling*
Baseado em Redund√¢ncia). Essa abordagem busca inspira√ß√£o em
t√©cnicas de SI. Um par de documentos √© considerado redundante se
apresenta alta similaridade entre si. Nossa hip√≥tese √© que manter
apenas uma das inst√¢ncias no conjunto de treinamento √© suficiente,
pois a presen√ßa de ambas n√£o trar√° aumento significativo na aprendizagem do modelo. Ao se concentrar na redu√ß√£o de redund√¢ncia
na classe majorit√°ria, obtemos um potencial de redu√ß√£o do desbalanceamento e, consequentemente, do vi√©s para essa classe. O
**Algoritmo 1** detalha o pseudoc√≥digo do UBR.


146


-----

WebMedia‚Äô2024, Juiz de Fora, Brazil Guilherme Fonseca, Gabriel Prenassi, Washington Cunha, Marcos Andr√© Gon√ßalves, & Leonardo Rocha


**Algoritmo 1:** Algoritmo UBR

**Input:** X, *ùõº*
**Output:** instanciasSel

**1** *ùëã* *ùëÄùëéùëó* ‚Üê *ùëúùëèùë°ùëíùëüùêºùëõùë†ùë°ùëéùëõùëêùëñùëéùë†* ( *ùëã,ùëêùëôùëéùë†ùë†ùëí* = *ùëöùëéùëóùëúùëüùëñùë°ùëéùëüùëñùëé* ) ;

**2** *ùëã* *ùëÄùëñùëõ* ‚Üê *ùëúùëèùë°ùëíùëüùêºùëõùë†ùë°ùëéùëõùëêùëñùëéùë†* ( *ùëã,ùëêùëôùëéùë†ùë†ùëí* = *ùëöùëñùëõùëúùëüùëñùë°ùëéùëüùëñùëé* ) ;

**3** *ùëñùëõùë†ùë°ùëéùëõùëêùëñùëéùë†ùëÜùëíùëô* ‚Üê *ùëã* *ùëÄùëñùëõ* ;

**4** *ùê∑* ‚Üê *ùëëùëñùë†ùë°ùëéùëõùëêùëñùëéùê¥ùëùùëüùëúùë•ùëñùëöùëéùëëùëéùëÅùëâùëñùëßùëñùëõ‚Ñéùëúùë†* ( *ùëã* *ùëÄùëéùëó* ) ;

**5** *ùëêùëôùë¢ùë†ùë°ùëíùëüùë†* ‚Üê *ùëã* *ùëÄùëéùëó* ;

**6** *ùëÅ* ‚Üê ÔøΩÔøΩ *ùëã* *ùëÄùëéùëó* ÔøΩÔøΩ ‚àí‚à• *ùëã* *ùëÄùëñùëõ* ‚à• ;

**7** **while** *ùëÅ* *>* 0 **do**
**8** *ùê¥, ùêµ* ‚Üê *ùëÉùëéùëüùëÄùëéùëñùë†ùëÜùëñùëöùëñùëôùëéùëü* ( *ùëã* *ùëÄùëéùëó* *, ùê∑* ) ;

**9** **if** (‚à• *ùëêùëôùë¢ùë†ùë°ùëíùëüùë†* [ *ùê¥* ]‚à• *> ùõº* ) *ùëÇùëÖ* (‚à• *ùëêùëôùë¢ùë†ùë°ùëíùëüùë†* [ *ùêµ* ]‚à• *> ùõº* ) **then**
**10** *ùëêùëúùëõùë°ùëñùëõùë¢ùëí* ;

**11** **end**

**12** **if** *ùëêùëôùë¢ùë†ùë°ùëíùëüùë†* [ *ùê¥* ] ‚â† *ùëêùëôùë¢ùë†ùë°ùëíùëüùë†* [ *ùêµ* ] **then**
**13** *ùëêùëôùë¢ùë†ùë°ùëíùëüùë†* [ *ùê¥* ] ‚Üê *ùëêùëôùë¢ùë†ùë°ùëíùëüùë†* [ *ùê¥* ] [ÔøΩ] *ùëêùëôùë¢ùë†ùë°ùëíùëüùë†* [ *ùêµ* ] ;

**14** *ùëëùëíùëôùëíùë°ùëéùëü* ( *ùëêùëôùë¢ùë†ùë°ùëíùëü* [ *ùêµ* ]) ;

**15** *ùëÅ* = *ùëÅ* ‚àí 1 ;

**16** **end**

**17** **end**

**18** *ùëíùë†ùëêùëúùëô‚Ñéùëñùëëùëúùë†* ‚Üê *ùëíùë†ùëêùëúùëô‚ÑéùëíùëÖùëíùëùùëüùëíùë†ùëíùëõùë°ùëéùëõùë°ùëí* ( *ùëêùëôùë¢ùë†ùë°ùëíùëüùë†* ) ;

**19** *ùëñùëõùë†ùë°ùëéùëõùëêùëñùëéùë†ùëÜùëíùëô* ‚Üê *ùëñùëõùë†ùë°ùëéùëõùëêùëñùëéùë†ùëÜùëíùëô* [ÔøΩ] *ùëíùë†ùëêùëúùëô‚Ñéùëñùëëùëúùë†* ;

Dado *ùëã* como o conjunto total de inst√¢ncias de treinamento, inicialmente dividimos *ùëã* em dois conjuntos, *ùëã* *ùëÄùëéùëó* e *ùëã* *ùëÄùëñùëõ*, onde *ùëã* *ùëÄùëéùëó*
consiste em inst√¢ncias de *ùëã* pertencentes √† classe majorit√°ria, e
*ùëã* *ùëÄùëñùëõ* consiste em inst√¢ncias de *ùëã* pertencentes √† classe minorit√°ria.
Para cada inst√¢ncia de *ùëã* *ùëÄùëéùëó*, calculamos a similaridade de cosseno
da inst√¢ncia para os seus K vizinhos mais pr√≥ximos e colocamos
em uma lista ordenada *ùê∑* .

Por quest√µes de otimiza√ß√£o de tempo e de uso de mem√≥ria, utilizamos uma vers√£o aproximada do KNN [ 33 ]. Ap√≥s isso, passamos
a considerar cada inst√¢ncia de *ùëã* *ùëÄùëéùëó* como um *cluster* individual e
realizamos *ùëÅ* itera√ß√µes, onde *ùëÅ* = *ùëã* *ùëÄùëéùëó* ‚àí *ùëã* *ùëÄùëñùëõ* . Em cada itera√ß√£o,
buscamos em *ùê∑* o par de inst√¢ncias *ùê¥* e *ùêµ* pertencentes a *ùëã* *ùëÄùëéùëó* que
apresenta a maior similaridade e que est√£o em *clusters* distintos e
cujos *clusters* n√£o sejam maiores que *ùõº* (hiperpar√¢metro do m√©todo
que controla a quantidade de vizinhos a ser avaliada), com o objetivo de unir os *clusters* aos quais *ùê¥* e *ùêµ* pertencem. Ao final, temos
| *ùëã* *ùëÄùëñùëõ* | *clusters* dentro do conjunto *ùëã* *ùëÄùëéùëó*, dos quais ser√° selecionado
aleatoriamente um representante para compor, juntamente com o
conjunto *ùëã* *ùëÄùëñùëõ*, o novo conjunto de treinamento. [2]

|dataset|# docs|# majorit√°ria|# minorit√°ria|RD|Nome|
|---|---|---|---|---|---|
|sentistrength_twitter_2L vader_amazon_2L english_dailabor_2L debate_2L sentistrength_youtube_2L sentistrength_rw_2L vader_twitter_2L tweet_semevaltest_2L sentistrength_digg_2L sentistrength_myspace_2L sentistrength_bbc_2L digital_music_2L|2,289 3,610 1,227 1,979 2,432 705 4,196 3,060 782 834 752 162,989|1,340 2,128 739 1,249 1,665 484 2,897 2,223 572 702 653 158,985|949 1,482 488 730 767 221 1,299 837 210 132 99 4,004|1.41 1.44 1.51 1.71 2.17 2.19 2.23 2.66 2.72 5.32 6.60 39.71|A B C D E F G H I J K L|



**Tabela 1: Cole√ß√µes de dados utilizadas nos experimentos. A**
**coluna ‚Äúnome‚Äù cont√©m como a base vai ser referenciada.**

2 Nossa t√©cnica √© limitada a problemas de classifica√ß√£o bin√°rios. Deixamos para o futuro
a extens√£o da abordagem para problemas multi-r√≥tulo.

### **4 CONFIGURA√á√ÉO EXPERIMENTAL** **4.1 Base de dados**


A efici√™ncia √© medida com base no custo de cada m√©todo em termos
do tempo total necess√°rio para construir o modelo e realizar as clasifica√ß√µes. O *Speedup* √© calculado como *ùëÜ* = *[ùëá]* *ùëá* *[ùë§ùëú]* *ùë§* [, onde] *[ ùëá]* *[ùë§]* [√© o tempo]

total gasto na constru√ß√£o do modelo, mais o tempo da classifica√ß√£o,
usando alguma abordagem de *undersampling*, e *ùëá* *ùë§ùëú* √© o tempo total
gasto na execu√ß√£o (modelo e classifica√ß√£o) sem a fase de *undersam-*
*pling* . A emiss√£o de *ùê∂ùëÇ* 2 √© o equivalente de di√≥xido de carbono gasto
para treinamento de um modelo e classifica√ß√£o baseado em [21].
Os experimentos foram realizados na AWS. Para as bases de
dados de A at√© K, as etapas *undersampling*, que demandam estritamente processamento em CPU, utilizaram uma inst√¢ncia do tipo
**c6a.4xlarge** e a classifica√ß√£o, que demanda hardware especializado
(GPU), inst√¢ncias do tipo **g4dn.xlarge** . Para a base L, que √© bem
maior que as demais, demandou um poder computacional maior e
ambas as etapas foram executadas em inst√¢ncias do tipo **g5.4xlarge** .
As bases de dados foram divididas utilizando o m√©todo de valida√ß√£o
cruzada com 5 parti√ß√µes (base L) ou 10 parti√ß√µes (demais bases).
As compara√ß√µes foram realizadas utilizando o m√©todo estat√≠stico
Teste-T com corre√ß√£o de Bonferroni [8].


Consideramos 12 *datasets*, com diferentes n√≠veis de desbalanceamento. A Tabela 1 mostra os *datasets* com o n√∫mero de documentos,
n√∫mero de documentos pertencentes √† classe majorit√°ria e √† minorit√°ria, o nome pelo qual vamos nos referir a base de dados ao
longo do trabalho e a raz√£o de desbalanceamento (RD)[ 31 ], m√©trica
que demonstra o qu√£o desbalanceado √© uma base de dados (quanto
maior for a RD mais desbalanceado √© a base de dados). O RD √©
calculado como sendo *ùëÖùê∑* = *[ùëêùëôùëéùë†ùë†ùëíùëöùëé]* *[ùëó]* *[ùëúùëüùëñùë°ùëéùëüùëñùëé]*

*ùëêùëôùëéùë†ùë†ùëíùëöùëñùëõùëúùëüùëñùë°ùëéùëüùëñùëé* [.]
### **4.2** **M√©todo de Classifica√ß√£o de Texto**

Consideramos m√©todos de CAT baseados em *Transformers* **BART**

[ 23 ], **RoBERTa** [ 25 ] e **BERT** [ 11 ], que atualmente se apresentam
como os melhores entre os m√©todos de classifica√ß√£o utilizados na
literatura para tarefa de An√°lise de Sentimento [ 8 ]. Para ajustar os
hiperpar√¢metros, utilizamos a mesma metodologia discutida em [ 8 ].
Assim, fixamos a taxa de aprendizado inicial como 5 √ó 10 [‚àí][5], o
n√∫mero m√°ximo de √©pocas como 20 e a paci√™ncia como 5 √©pocas. Por
fim, realizamos um grid search em max_len (150 e 256) e batch_size
(16, 32 e 64), pois esses valores especificados impactam diretamente
na efici√™ncia e efetividade do modelo. Utilizamos, tamb√©m, 6 classificadores tradicionais: **KNN**, *Random Forest* [ 3 ], Regress√£o Log√≠stica
( **RL** ) [ 40 ], **SVM** [ 2 ], *XGBoost* ( **XGB** ) [ 4 ] e *LightGBM* ( **LGBM** ) [ 19 ].
### **4.3 M√©tricas e Protocolo Experimental**

Nossa avalia√ß√£o √© feita sob tr√™s perspectivas: (1) efetividade da
classifica√ß√£o; (2) capacidade de generaliza√ß√£o dos modelos (vi√©s);
e (3) efici√™ncia (tempo e emiss√£o de *ùê∂ùëÇ* 2 ). A efetividade √© avaliada
utilizando a *Macro Average F1* (MacroF1). A capacidade de generaliza√ß√£o √© medida pela m√©trica TPRGap apresentada em [ 9 ], definida
na Equa√ß√£o 1, onde *ùëáùëÉùëÖ* ( *ùëñ* ) √© *true positive rate* da classe *ùëñ*, *ùëá* √© o
n√∫mero total de classes, *ùëÅ* √© o fator de normaliza√ß√£o, que √© igual
ao n√∫mero de pares de classes que comparamos [ÔøΩ] *[ùëá]* 2 ÔøΩ.


*ùëáùëÉùëÖùê∫ùëéùëù* =

*ùëñ,ùëóùúñùëá*

‚àëÔ∏Å


*ùëñ,ùëóùúñùëá*


| *ùëáùëÉùëÖ* ( *ùëñ* ) ‚àí *ùëáùëÉùëÖ* ( *ùëó* ) |

(1)
*ùëÅ*


147


-----

Estrat√©gias de Undersampling para Redu√ß√£o de Vi√©s em Classifica√ß√£o de Texto Baseada em Transformers WebMedia‚Äô2024, Juiz de Fora, Brazil

**Tabela 2: Resultados de Macro-F1 e TPRGap dos classificadores. C√©lulas em negrito s√£o os maiores valores num√©ricos para uma**

|Col1|RoBERTa|BART|BERT|SVM|LR|RF|XGB|LGBM|KNN|
|---|---|---|---|---|---|---|---|---|---|
|dataset|Macro F1 TPRGap|Macro F1 TPRGap|Macro F1 TPRGap|Macro F1 TPRGap|Macro F1 TPRGap|Macro F1 TPRGap|Macro F1 TPRGap|Macro F1 TPRGap|Macro F1 TPRGap|
|A|88.6(0.7) 0.063 89.0(0.7) 0.065 93.3(1.1) 0.041 89.3(1.2) 0.076 89.7(1.9) 0.096 87.3(3.4) 0.126 94.2(1.0) 0.160 90.1(1.5) 0.102 83.8(5.0) 0.190 83.2(3.4) 0.333 81.0(4.5) 0.350 87.8(2.5) 0.308|89.3(1.1) 0.048 88.3(1.4) 0.079 93.7(1.2) 0.036 89.1(1.1) 0.085 88.9(1.7) 0.117 88.0(3.3) 0.128 93.7(1.0) 0.053 90.1(1.6) 0.099 81.6(5.6) 0.198 83.0(5.8) 0.283 78.0(6.1) 0.410 88.6(1.2) 0.296|84.3(1.7) 0.050 86.9(0.8) 0.057 89.1(2.2) 0.063 85.5(2.0) 0.146 86.1(1.8) 0.134 80.9(2.5) 0.202 88.0(1.3) 0.108 86.4(1.9) 0.125 79.1(3.6) 0.290 79.8(4.9) 0.350 76.4(4.4) 0.447 85.3(0.7) 0.383|71.8(2.5) 0.187 72.1(1.5) 0.257 79.3(3.1) 0.111 76.4(2.1) 0.213 79.0(1.7) 0.215 69.1(3.4) 0.421 82.0(1.0) 0.238 70.9(2.0) 0.404 67.0(5.6) 0.539 68.1(3.8) 0.610 50.5(5.0) 0.944 78.7(0.3) 0.601|71.4(2.5) 0.228 72.9(1.5) 0.209 80.4(2.1) 0.117 75.6(3.6) 0.223 78.6(2.0) 0.245 68.2(2.8) 0.471 80.4(1.4) 0.320 71.9(1.7) 0.399 63.0(6.8) 0.619 63.1(6.4) 0.733 53.3(4.7) 0.914 78.2(0.7) 0.562|67.0(2.4) 0.370 68.6(1.8) 0.422 75.7(2.8) 0.221 73.3(3.0) 0.271 72.6(4.0) 0.257 59.3(4.1) 0.698 72.6(1.9) 0.526 64.5(2.0) 0.615 54.9(5.1) 0.731 59.8(4.6) 0.809 54.3(5.7) 0.888 78.9(0.4) 0.561|64.9(2.4) 0.417 67.6(1.4) 0.247 75.0(1.5) 0.171 71.5(1.8) 0.302 71.1(1.7) 0.472 63.1(5.0) 0.582 74.0(1.4) 0.476 64.0(1.9) 0.660 56.7(5.2) 0.665 59.2(3.5) 0.803 53.4(5.3) 0.898 72.0(0.3) 0.698|63.2(3.2) 0.375 69.4(2.7) 0.250 68.9(5.9) 0.208 72.8(3.4) 0.296 71.7(3.7) 0.385 65.8(4.2) 0.454 74.0(2.8) 0.372 63.9(4.4) 0.633 56.4(5.3) 0.598 58.4(10.5) 0.763 55.7(11.2) 0.833 73.6(0.7) 0.668|64.3(3.1) 0.478 65.9(2.8) 0.498 76.9(2.1) 0.166 72.7(3.2) 0.330 73.3(3.4) 0.263 58.8(2.2) 0.698 75.4(1.3) 0.454 60.8(1.5) 0.654 55.2(6.4) 0.800 56.5(4.4) 0.875 46.4(0.1) 0.998 60.9(0.5) 0.866|
|B||||||||||
|C||||||||||
|D||||||||||
|E||||||||||
|F||||||||||
|G||||||||||
|H||||||||||
|I||||||||||
|J||||||||||
|K||||||||||
|L||||||||||
|M√©dia:|0.159|0.153|0.196|0.395|0.420|0.531|0.533|0.486|0.590|

**base de dados e c√©lulas em verde s√£o estatisticamente equivalentes √† classifica√ß√£o de maior valor num√©rico.**

### **5 AN√ÅLISE DOS RESULTADOS** **5.1 PP1: Compara√ß√£o entre m√©todos de CAT**

Para responder a **PP1** ( *Como algoritmos estado da arte recentes,*
*baseados em Transformers, s√£o afetados pelo desbalanceamento de*
*classes em tarefas de an√°lise de sentimentos? H√° espa√ßo para melho-*
*rias?* ), comparamos os classificadores tradicionais **KNN**, **RF**, **RL**,
**SVM**, **XGB** e **LGBM** com os baseados em *Transformers* **RoBERTa**,
**BART** e **BERT** .

A Tabela 2 apresenta os resultados de MacroF1 e TPRGap para
estes classificadores. Como primeira an√°lise, podemos destacar a
superioridade, em termos de *efetividade*, dos classificadores baseados em *Transformers* quando comparados aos classificadores tradicionais ‚Äì estes foram inferiores (estatisticamente) aos *Transformers*
em todas as 12 bases de dados consideradas, resultado condizente
com a literatura [ 7 ]. J√° dentre os classificadores baseados em *Trans-*
*formers*, o RoBERTa e o BART se destacam, ambos com resultados de
classifica√ß√£o estatisticamente equivalentes em todas bases. O BERT,
por sua vez, √© estatisticamente equivalente ao RoBERTa e ao BART
em apenas 4 das 12 bases de dados. Por fim, quando analisamos
os valores num√©ricos absolutos de cada classificador, o modelo
RoBERTa produz os maiores valores de MacroF1 em 8 cole√ß√µes
enquanto o BART o faz em 4 delas, refor√ßando a ideia da literatura

[ 8 ] de que o RoBERTa produz resultados condizentes com o estado
da arte atual de an√°lise de sentimentos. Por isso, nas an√°lises das
pr√≥ximas se√ß√µes, passaremos a utilizar apenas o **RoBERTa** .
Focando agora no vi√©s (TPRGap m√©dio) das abordagens (quanto
menor TPRGap, menor vi√©s), observamos que os *Transformers* apresentam menor vi√©s quando comparados aos m√©todos de CAT
tradicionais. Para os classificadores tradicionais, o m√©todo que
obteve os melhores valores foi o SVM com um TPRGap m√©dio
de 0.395, o que √© mais que o dobro do TPRGap m√©dio dos m√©todos
baseados em *Transformers* que conseguiram 0.159 (RoBERTa), 0.153
(BART) e 0.196 (BERT). Esse resultado √© muito interessante e at√©
onde sabemos n√£o foi reportado na literatura - *a boa capacidade*
*dos Transformers de lidar com desbalanceamento de dados* .
Apesar disso, os *Transformers* ainda apresentam resultados de
TPRGap alto em bases de dados que t√™m um desbalanceamento
elevado, como √© o caso das bases J, K e L, com RD igual a 5.32, 6.60
e 39.71, respectivamente. Isso nos mostra que ainda h√° espa√ßo para
melhorias, isto √©, espa√ßo para usar t√©cnicas capazes de reduzir o
vi√©s dos modelos *Transformers* .


Portanto, os classificadores baseados em *Transformers* conseguem
gerar modelos que, al√©m da efetividade estado da arte, apresentam
um vi√©s consideravelmente menor quando comparados aos classificadores tradicionais. Al√©m disso, observamos que, mesmo para
os *Transformers*, ainda h√° espa√ßo consider√°vel de melhoria. Esse
espa√ßo √© explorado a seguir.
### **5.2 PP2: Efetividade e Vi√©s de CAT com** **undersampling**

Na Tabela 3, apresentamos os resultados de efetividade obtidos por
meio da aplica√ß√£o dos m√©todos de US juntamente com o classificador RoBERTa. A coluna ‚ÄúNoUnder‚Äù apresenta o resultado sem o
*undersampling* do conjunto de treinamento. Um ponto importante
√© que, para todos os m√©todos que permitem hiperparametriza√ß√£o
no que tange a quantidade de inst√¢ncias a serem removidas (UBR,
E2SC, E2SC_RL, NM1, NM2, IHT e CC_NN), limitamos a remo√ß√£o
de no m√°ximo 50% da base de dados, pois trabalhos recentes relacionados √† sele√ß√£o de inst√¢ncias [ 6 ] apontam que esse √© o limite
emp√≠rico de redu√ß√£o onde ainda √© poss√≠vel n√£o ocorrer perdas na
efetividade. Os outros m√©todos n√£o foram modificados, seguindo
a pol√≠tica de remo√ß√£o pr√≥pria.
Podemos observar que os m√©todos UBR, NM1, E2SC_RL, NM2,
E2SC, TL e OSS conseguem empate estat√≠stico com a classifica√ß√£o
sem *undersampling* (i.e., com o treino completo desbalanceado) em
todas as cole√ß√µes analisadas. Isso demonstra que todas as t√©cnicas
listadas acima tem a capacidade de balancear a base sem causar
perdas de efetividade. Os demais m√©todos n√£o obtiveram bons resultados em rela√ß√£o aos anteriores, perdendo em 4 (IHT), 3 (OBU,
SBC, RENN e ALLKNN), 2 (NM3) ou em 1 (NCR, ENN) base(s),
respectivamente. Os m√©todos CNN e CC_NN s√£o estatisticamente
equivalentes ao US em 11 de 12 bases de dados, por√©m, no maior
conjunto de dados (L), ambos tiveram um tempo de *undersampling*
que ultrapassou o tempo de treinamento do modelo de classifica√ß√£o
sem o *undersampling*, sendo, portanto, desconsiderados para essa
an√°lise devido a sua impraticabilidade.
Na Tabela 4 apresentamos os resultados para a m√©trica TPRGap,
a qual mede o vi√©s dos modelos. A coluna ‚ÄúNoUnder‚Äù apresenta o
resultado sem o *undersampling*, enquanto que as demais apresentam o TPRGap dos modelos com *undersampling* . As cores do fundo
das c√©lulas representam o quanto os modelos conseguiram reduzir
o vi√©s do modelo comparados ao ‚ÄúNoUnder‚Äù. Ou seja, quanto maior
o tom de verde, maior a redu√ß√£o do vi√©s, e quanto mais vermelho,


148


-----

WebMedia‚Äô2024, Juiz de Fora, Brazil Guilherme Fonseca, Gabriel Prenassi, Washington Cunha, Marcos Andr√© Gon√ßalves, & Leonardo Rocha

|dataset|NoUnder|UBR|NM1|E2SC_RL|NM2|E2SC|NM3|IHT|OBU|SBC|NCR|TL|OSS|RENN|ALLKNN|ENN|CNN|CC_NN|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|A|88.6(0.7) 89.0(0.7) 93.3(1.1) 89.3(1.2) 89.7(1.9) 87.3(3.4) 94.2(1.0) 90.1(1.5) 83.8(5.0) 83.2(3.4) 81.0(4.5) 87.8(2.5)|88.6(0.8) 88.9(0.8) 88.8(1.1) 89.0(0.8) 88.6(1.2) 88.5(1.0) 87.7(1.2) 85.1(1.4) 87.6(1.5) 87.2(2.0) 89.2(1.2) 88.3(0.6) 85.6(0.9) 87.2(2.1) 85.6(0.9) 88.2(1.5) 88.7(1.4) 88.7(1.1) 88.3(1.2) 89.1(1.1) 88.2(0.7) 88.6(1.4) 51.3(13.5) 87.8(1.5) 85.6(1.4) 87.9(1.2) 89.4(1.4) 88.7(0.9) 88.7(0.9) 83.1(8.9) 70.2(5.1) 83.4(9.0) 88.1(2.0) 90.0(1.2) 94.3(1.4) 94.2(1.5) 93.4(1.3) 94.1(1.1) 93.8(1.6) 93.9(1.4) 92.0(1.2) 92.3(1.6) 89.3(3.3) 92.4(1.4) 93.4(1.7) 94.3(1.5) 92.5(1.7) 91.7(2.0) 92.5(1.7) 93.7(1.1) 94.5(1.4) 87.6(1.5) 88.0(1.5) 88.7(1.7) 86.3(1.5) 88.1(1.7) 87.7(2.0) 84.3(3.2) 80.7(1.6) 87.7(1.2) 86.7(1.5) 88.4(1.5) 89.1(1.4) 83.4(2.1) 83.6(3.4) 83.4(2.1) 88.2(1.0) 81.7(13.8) 87.9(1.6) 88.4(1.8) 89.4(1.7) 89.3(1.9) 89.1(1.9) 89.0(1.7) 82.3(1.4) 88.2(2.3) 79.2(4.2) 68.7(7.2) 89.9(1.6) 89.9(1.6) 55.2(3.5) 58.6(3.5) 55.2(3.5) 89.6(1.5) 89.3(1.6) 82.3(3.5) 83.1(4.4) 85.4(3.5) 86.7(3.7) 88.6(3.6) 86.3(2.9) 80.6(2.2) 77.1(5.1) 86.9(3.0) 87.4(2.8) 88.4(4.0) 88.2(3.8) 81.6(3.1) 84.6(5.2) 87.7(3.6) 86.7(3.2) 84.1(3.2) 92.7(0.9) 92.6(1.1) 93.1(1.2) 92.5(1.2) 92.6(1.1) 92.9(1.3) 87.9(1.1) 86.7(2.4) 92.0(0.9) 93.2(1.0) 93.4(1.4) 93.8(1.1) 91.5(1.0) 93.1(0.9) 92.9(0.8) 93.0(1.0) 93.0(1.0) 88.6(1.6) 89.7(2.1) 88.5(1.5) 89.2(1.8) 89.3(1.8) 88.9(1.6) 83.0(2.0) 88.3(1.7) 88.1(0.9) 90.1(1.5) 90.3(1.1) 90.6(1.6) 86.8(1.9) 88.7(1.8) 89.2(1.3) 89.8(1.8) 88.8(1.5) 82.9(4.5) 80.5(4.3) 80.6(4.7) 81.3(4.1) 81.3(4.7) 81.0(3.9) 74.1(4.5) 77.6(3.3) 81.0(4.6) 84.0(4.9) 87.2(4.7) 85.4(3.7) 75.8(4.4) 77.3(5.5) 81.2(5.3) 83.0(5.0) 82.4(4.6) 80.1(4.2) 81.0(4.7) 81.5(5.2) 80.8(5.5) 82.9(5.0) 79.4(5.3) 74.5(3.7) 81.8(6.0) 60.2(2.9) 84.5(4.6) 83.2(4.8) 84.5(4.6) 80.7(3.9) 82.4(4.1) 84.1(3.3) 81.5(3.6) 79.9(9.5) 79.3(3.1) 78.0(4.1) 78.7(4.2) 75.0(5.0) 79.2(4.7) 74.0(3.2) 73.3(4.7) 71.7(4.4) 71.0(4.5) 79.8(5.1) 78.7(4.6) 77.2(5.0) 79.4(5.0) 77.4(6.1) 77.8(5.9) 77.8(4.3) 76.7(3.7) 81.9(4.8) 87.1(1.3) 88.7(0.3) 85.1(3.5) 88.7(0.3) 51.0(1.7) 60.3(1.5) 77.3(9.1) 30.9(1.7) 80.1(21.4) 80.0(21.4) 72.7(26.5) 69.2(3.5) 67.9(2.6) 79.8(21.2) - -|||||||||||||||||
|B|||||||||||||||||||
|C|||||||||||||||||||
|D|||||||||||||||||||
|E|||||||||||||||||||
|F|||||||||||||||||||
|G|||||||||||||||||||
|H|||||||||||||||||||
|I|||||||||||||||||||
|J|||||||||||||||||||
|K|||||||||||||||||||
|L|||||||||||||||||||



**Tabela 3: Macro-F1 do RoBERTa utilizando as abordagens de** *undersampling* **. C√©lulas em negrito s√£o os maiores valores num√©ricos**
**para uma base de dados. C√©lulas em verde representam resultados que s√£o estatisticamente equivalentes √† classifica√ß√£o sem**
*undersampling* **(NoUnder). C√©lulas com ‚Äú-‚Äù representam m√©todos que resultaram em um tempo superior ao tempo de classifica√ß√£o**
**da mesma base sem o** *undersampling* **e, portanto, desconsiderado.**

**Tabela 4: TPRGap dos modelos gerados pelo classificador RoBERTa em conjunto com as abordagens de** *undersampling* **utilizando**

|dataset|NoUnder|UBR|NM1|E2SC_RL|NM2|E2SC|NM3|IHT|OBU|SBC|NCR|TL|OSS|RENN|ALLKNN|ENN|CNN|CC_NN|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|A|0.063 0.065 0.041 0.076|0.010 0.004 0.002 0.005 0.003 0.011 0.072 0.114 0.039 0.077 0.035 0.036 0.141 0.098 0.141 0.047 0.011 0.043 0.026 0.034 0.013 0.033 0.692 0.075 0.100 0.012 0.048 0.060 0.060 0.188 0.445 0.166 0.027 0.023 0.002 0.003 0.000 0.018 0.007 0.022 0.059 0.019 0.149 0.038 0.029 0.025 0.061 0.062 0.061 0.002 0.011 0.005 0.043 0.019 0.019 0.006 0.020 0.107 0.097 0.013 0.032 0.052 0.042 0.143 0.108 0.143 0.006 0.070|||||||||||||||||
|B|||||||||||||||||||
|C|||||||||||||||||||
|D|||||||||||||||||||
|M√©dia|0.061|0.015 0.019 0.014 0.014 0.012 0.186 0.078 0.083 0.053 0.049 0.044 0.041 0.133 0.178 0.128 0.021 0.029|||||||||||||||||
|E|0.096 0.126 0.160 0.102 0.190|0.037 0.012 0.001 0.010 0.031 0.026 0.197 0.023 0.245 0.403 0.093 0.090 0.634 0.593 0.634 0.032 0.024 0.006 0.047 0.029 0.054 0.025 0.036 0.132 0.144 0.024 0.043 0.108 0.134 0.111 0.034 0.010 0.000 0.011 0.002 0.003 0.006 0.001 0.001 0.012 0.122 0.094 0.017 0.018 0.063 0.062 0.037 0.007 0.004 0.012 0.012 0.030 0.000 0.006 0.021 0.020 0.001 0.158 0.007 0.035 0.028 0.085 0.077 0.072 0.021 0.007 0.016 0.024 0.037 0.027 0.040 0.036 0.006 0.063 0.212 0.066 0.029 0.018 0.118 0.131 0.158 0.136 0.046 0.006 0.037|||||||||||||||||
|F|||||||||||||||||||
|G|||||||||||||||||||
|H|||||||||||||||||||
|I|||||||||||||||||||
|M√©dia|0.135|0.023 0.018 0.017 0.025 0.017 0.027 0.164 0.067 0.070 0.102 0.093 0.099 0.202 0.158 0.140 0.013 0.022|||||||||||||||||
|J|0.333 0.350|0.148 0.176 0.222 0.193 0.221 0.111 0.085 0.264 0.352 0.256 0.336 0.304 0.216 0.248 0.262 0.112 0.247 0.182 0.209 0.215 0.210 0.226 0.064 0.059 0.173 0.047 0.237 0.361 0.400 0.287 0.324 0.324 0.193 0.329|||||||||||||||||
|K|||||||||||||||||||
|M√©dia|0.342|0.165 0.192 0.218 0.202 0.224 0.087 0.072 0.219 0.199 0.247 0.349 0.352 0.251 0.286 0.293 0.153 0.288|||||||||||||||||
|L|0.308|0.182 0.207 0.214 0.208 0.216 0.198 0.067 0.245 0.619 0.434 0.443 0.579 0.045 0.042 0.403 - -|||||||||||||||||
|M√©dia Total|0.159|0.057 0.063 0.066 0.066 0.066 0.105 0.112 0.112 0.132 0.136 0.149 0.162 0.174 0.177 0.183 - -|||||||||||||||||

**o classificador RoBERTa. Quanto mais verde a c√©lula, maior a redu√ß√£o do vi√©s. Quanto mais vermelho, maior o aumento do vi√©s.**


maior o agravamento do vi√©s. Para auxiliar essa an√°lise, dividimos
nossas bases em 4 grupos com rela√ß√£o a seu grau de desbalanceamento (RD). No primeiro grupo s√£o as bases de dados que t√™m um
RD at√© 2 (bases A, B, C, D), o segundo cont√©m as bases com RD
maiores que 2 e menores que 5 (bases E, F, G, H e I), o terceiro aquelas com RD maior que 5 e menor que 10 (bases J e K). Por fim, no
√∫ltimo grupo, temos apenas a base de dados L, com um RD de 39.71.
Em rela√ß√£o ao vi√©s m√©dio total calculado, os m√©todos que conseguiram a maior redu√ß√£o de vi√©s dos modelos em todas as 12
cole√ß√µes foram UBR (vi√©s total m√©dio de 0.057), NM1 (0.063), E2SC_RL
(0.066), NM2 (0.066) e E2SC (0.066), com uma redu√ß√£o de quase 3
vezes comparada ao NoUnder (0.159).
Os m√©todos RENN, ALLKNN, ENN, que j√° est√£o entre os piores
em termos de efetividade, tamb√©m desempenham mal em rela√ß√£o
ao enviesamento do modelo, aumentando o vi√©s m√©dio. Os m√©todos TL e OSS, apesar de apresentarem bons resultados em termos
de efetividade, demonstram um baixo desempenho em rela√ß√£o ao
enviesamento, piorando o modelo em alguns casos (em 3 datasets
cada) e tendo um TPRGap m√©dio total pr√≥ximo ao NoUnder ‚Äì 0.149
(TL) e 0.162 (OSS).
Por fim, observamos tamb√©m que o m√©todo UBR ‚Äì que obteve os
melhores resultados quanto a m√©dia total de TRPGap ‚Äì se mostra
bastante eficaz individualmente por base, principalmente naquelas
mais desbalanceadas. Por exemplo, nas bases do grupo 3 (bases K


e J) e 4 (L), o UBR reduziu o vi√©s do modelo NoUnder em cerca de
duas vezes, estando sempre muito pr√≥ximo do menor vi√©s geral
alcan√ßado por qualquer m√©todo para essas bases. Observa√ß√£o similar √© v√°lida para os outros dois grupos: UBR sempre aparece entre
os melhores resultados. O E2SC tamb√©m √© bastante competitivo,
apresentando os melhores resultados m√©dios para os grupos 1 e 2
e estando, tamb√©m, entre os melhores nos demais grupos.
Sumarizando, conseguimos, com as an√°lises reportadas acima,
responder positivamente √† **PP2** ( *M√©todos de undersampling, apli-*
*cados juntamente com classificadores baseados em Transformers, s√£o*
*capazes de reduzir o vi√©s dos modelos de classifica√ß√£o? Qual o impacto*
*dessa combina√ß√£o na efetividade do modelo?* ), pois os m√©todos UBR,
NM1, E2SC_RL, NM2 e E2SC s√£o capazes de significativamente reduzir o vi√©s do modelo, sem perda de efetividade em todas as bases.
### **5.3** **PP3: Efici√™ncia de CAT com undersampling**

Analisamos aqui os m√©todos de US em rela√ß√£o √† sua efici√™ncia,
buscando verificar qual o impacto dessa nova etapa de pr√©-processamento dos dados no tempo total e na emiss√£o total de *ùê∂ùëÇ* 2 proveniente do treinamento dos modelos. A Tabela 5 apresenta o *speedup*
produzido pelos m√©todos de US. Conforme mencionamos na Se√ß√£o
4.3, o *speedup* √© calculado pela raz√£o entre o tempo total gasto
na constru√ß√£o do modelo, mais o tempo da classifica√ß√£o, usando
alguma abordagem de *undersampling* pelo tempo total gasto na
execu√ß√£o (modelo e classifica√ß√£o) sem a fase de *undersampling* .


149


-----

Estrat√©gias de Undersampling para Redu√ß√£o de Vi√©s em Classifica√ß√£o de Texto Baseada em Transformers WebMedia‚Äô2024, Juiz de Fora, Brazil

**Tabela 5: Resultados de Speedup no custo total (tempo) para gera√ß√£o dos modelos utilizando o classificador RoBERTa em**

|dataset|UBR|NM1|E2SC_RL|NM2|E2SC|NM3|IHT|OBU|SBC|NCR|TL|OSS|RENN|ALLKNN|ENN|CNN|CC_NN|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|A|1.209 1.076 1.094 1.135 1.178 1.096 1.181 1.374 1.216 1.210 0.929 0.961 1.376 1.230 1.415 1.243 1.193 1.203 1.163 1.273 1.114 1.099 1.588 1.230 1.342 1.364 0.988 0.962 0.990 1.513 1.452 1.476 1.005 1.186 1.315 1.237 1.400 1.096 1.253 1.247 1.115 1.214 1.638 1.223 0.873 0.885 1.039 1.120 1.070 1.361 1.202 1.558 1.469 1.712 1.450 1.456 1.493 1.402 1.282 1.637 1.516 1.185 1.150 1.854 1.447 1.966 1.519 1.500 1.450 1.312 1.569 1.312 1.361 1.400 1.182 1.381 1.769 1.607 0.937 0.948 1.611 1.641 1.663 1.176 1.467 1.534 1.299 1.371 1.450 1.666 1.544 1.627 1.491 1.507 1.413 1.068 1.065 1.416 1.632 1.504 1.601 1.529 1.527 1.530 1.518 1.374 1.354 1.414 1.298 1.329 1.444 1.122 0.946 0.995 1.220 1.159 1.270 1.310 1.521 1.749 1.659 1.950 1.619 1.788 1.757 1.668 1.607 1.728 1.319 1.055 1.067 1.771 1.587 1.395 1.494 1.867 1.657 1.923 1.635 1.601 1.609 1.519 1.634 1.331 1.564 1.401 1.034 1.014 1.516 1.751 1.537 1.510 1.612 1.487 1.730 1.617 1.523 1.876 2.128 1.535 1.302 2.861 0.877 1.003 0.800 0.998 0.977 0.990 2.283 1.608 1.695 1.691 1.802 1.621 1.741 3.054 1.602 1.411 3.433 1.487 1.107 0.972 1.220 1.341 1.335 2.377 1.442 2.662 2.709 2.903 2.867 3.039 39.486 2.103 1.777 12.498 1.038 0.892 1.318 0.946 1.713 1.230 - -|||||||||||||||||
|B||||||||||||||||||
|C||||||||||||||||||
|D||||||||||||||||||
|E||||||||||||||||||
|F||||||||||||||||||
|G||||||||||||||||||
|H||||||||||||||||||
|I||||||||||||||||||
|J||||||||||||||||||
|K||||||||||||||||||
|L||||||||||||||||||
|M√©dia|1.587 1.566 1.654 1.513 1.618 4.811 1.465 1.404 2.722 1.267 0.999 1.014 1.373 1.421 1.404 - -|||||||||||||||||

**conjunto com as abordagens de** *undersampling* **. Quanto mais verde a c√©lula, maior a redu√ß√£o no tempo total de treinamento**
**em rela√ß√£o a abordagem sem** *undersampling* **. Quanto mais vermelho, maior o tempo.**

**Tabela 6: Emiss√£o de Carbono (** *ùê∂ùëÇ* 2 **) para gera√ß√£o dos modelos utilizando o classificador RoBERTa em conjunto com as**

|dataset|NoUnder|UBR|NM1|E2SC_RL|NM2|E2SC|NM3|IHT|OBU|SBC|NCR|TL|OSS|RENN|ALLKNN|ENN|CNN|CC_NN|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|A|55.537 83.539 34.265 93.391 55.470 36.458 171.805 78.329 22.538 21.994 23.693 2,552.335|45.884 51.580 50.740 48.897 47.114 50.650 46.966 40.362 43.922 45.838 59.770 57.725 40.322 45.119 39.218 40.892 44.769 69.377 71.793 65.550 74.933 75.923 52.539 67.865 62.154 59.487 84.470 86.764 84.280 55.137 57.481 56.526 66.378 66.234 26.042 27.693 24.463 31.241 27.324 27.460 30.724 28.192 20.567 27.991 39.227 38.706 32.962 30.580 32.013 24.429 27.903 59.893 63.529 54.531 64.380 64.097 62.535 66.566 72.778 56.550 61.574 78.756 81.160 50.329 64.525 47.462 57.948 61.228 38.202 42.243 35.322 42.254 40.692 39.576 46.877 40.118 30.730 34.474 59.146 58.448 34.394 33.765 33.315 41.039 35.803 23.745 28.052 26.563 25.116 21.848 23.591 22.375 24.414 23.945 25.780 34.099 34.192 25.725 22.307 24.220 22.403 23.493 112.413 112.145 113.060 124.901 126.778 121.423 132.204 129.121 116.158 152.980 181.434 172.539 140.629 148.092 135.182 117.260 108.297 44.724 47.164 40.116 48.316 43.737 44.516 46.895 48.635 41.999 59.281 74.156 73.297 44.120 49.254 56.096 43.587 39.587 13.581 11.704 13.769 14.060 13.986 14.816 13.768 16.906 14.135 16.061 21.784 22.209 14.847 12.854 14.647 14.468 13.676 14.773 12.700 13.592 14.429 11.708 10.321 14.307 16.869 7.486 25.071 21.912 27.473 22.023 22.498 22.193 9.291 13.296 13.934 13.980 13.114 14.579 13.568 7.724 14.747 16.740 6.504 15.897 21.369 24.348 19.383 17.626 17.710 9.510 15.948 942.877 938.264 876.957 879.055 834.978 60.623 1,209.117 1,414.486 117.465 2,324.505 2,760.191 1,831.865 1,210.973 1,245.247 1,943.847 - -|||||||||||||||||
|B|||||||||||||||||||
|C|||||||||||||||||||
|D|||||||||||||||||||
|E|||||||||||||||||||
|F|||||||||||||||||||
|G|||||||||||||||||||
|H|||||||||||||||||||
|I|||||||||||||||||||
|J|||||||||||||||||||
|K|||||||||||||||||||
|L|||||||||||||||||||

**abordagens de** *undersampling* **. Quanto mais verde a c√©lula, maior a redu√ß√£o da emiss√£o em rela√ß√£o a abordagem sem** *undersampling* **.**


Podemos observar que, com exce√ß√£o do TL, todos os m√©todos,
em m√©dia, conseguiram manter ou reduzir o tempo em compara√ß√£o
com o RoBERTa aplicado aos dados originais (sem *undersampling* ).
Os m√©todos UBR, NM1, E2SC_RL, NM2 e E2SC, que nas an√°lises
anteriores se mostraram superiores quantos aos crit√©rios de efetividade e redu√ß√£o do enviesamento, conseguem tamb√©m um bom
desempenho no crit√©rio de efici√™ncia. Os *speedups* alcan√ßados, respectivamente, de 1.587, 1.566, 1.654, 1.513 e 1.618 s√£o muito bons.
Juntamente com o NM3 (4.811) e SBC (2.722), esses s√£o os m√©todos
com maior ganho de *speedup* . Contudo, vale lembrar que o NM3 e o
SBC geram perdas de efetividade para algumas cole√ß√µes (Tabela 3)
ao produzir os respectivos ganhos de *speedup* .
Por fim, na Tabela 6, apresentamos os valores de emiss√£o de *ùê∂ùëÇ* 2
(em g) produzido pelos m√©todos de *undersampling* . Assim como
causaram perda de efici√™ncia, os m√©todos TL e OSS tamb√©m produzem um aumento de emiss√£o de *ùê∂ùëÇ* 2 para algumas bases. J√°
todos os demais m√©todos, em menor ou maior grau, geram alguma
redu√ß√£o de emiss√£o. Para as bases de dados de A a K, a emiss√£o de
carbono √© muito pequena quando comparada a base L, que √© ordens
de magnitude maior que as demais. Por essa mesma raz√£o, o tempo
de processamento de L √© muito maior, mesmo ela sendo executada
em uma m√°quina de maior poder computacional. Por isso, nossa
an√°lise nesse crit√©rio focar√° nessa base. Ao analisar a emiss√£o dos

m√©todos de *undersampling* para a base de dados L, observamos que
os m√©todos UBR (emiss√£o 942.877 g *ùê∂ùëÇ* 2 ), NM1 (938.264 g *ùê∂ùëÇ* 2 ),
E2SC_RL (876.957 g *ùê∂ùëÇ* 2 ), NM2 (879.055 g *ùê∂ùëÇ* 2 ) e E2SC (834.978


g *ùê∂ùëÇ* 2 ), os mesmos m√©todos destacados nas an√°lises anteriores,
tamb√©m conseguem reduzir mais que pela metade a emiss√£o em
compara√ß√£o com o NoUnder (2,552.335 g *ùê∂ùëÇ* 2 ). Traduzindo esses
n√∫meros para exemplos ilustrativos, podemos dizer que a emiss√£o
antes era equivalente a 2.73 meses de uma √°rvore sequestrando carbono ou a emiss√£o de 14.40 km percorridos por um carro [ 21 ]. J√° a
emiss√£o ap√≥s o *undersampling*, considerando o UBR como exemplo,
seria equivalente a 1.03 meses de sequestro de carbono feito por
uma √°rvore ou a emiss√£o de de 5.41 Km percorridos por um carro
de passageiros. Se individualmente essa parece ser uma redu√ß√£o pequena, se considerarmos milh√µes de m√°quinas ao redor do mundo
rodando processos similares todos os dias, dezenas ou centenas de
vezes, essa redu√ß√£o pode passar a ser consider√°vel.
Voltando √† nossa **PP3** ( *Qual o impacto da aplica√ß√£o dessa etapa*
*adicional de pr√©-processamento (undersampling) em termos de efi-*
*ci√™ncia? E em termos da emiss√£o de carbono?* ), temos que os m√©todos
UBR, NM1, E2SC_RL, NM2 e E2SC conseguem reduzir o enviesamento do modelo, mantendo a efetividade e reduzindo o tempo de
treinamento dos modelos e, consequentemente, as emiss√µes de *ùê∂ùëÇ* 2 .
### **5.4 Discuss√£o Final**

Dadas as an√°lises apresentadas nesta se√ß√£o, onde os m√©todos de
*undersampling* foram avaliados quanto √† sua efetividade, sua capacidade reduzir o enviesamento dos modelos e sua efici√™ncia, podemos
concluir que os melhores m√©todos de *undersampling* analisados
foram UBR, NM1, E2SC_RL, NM2 e E2SC. Todos eles conseguiram
reduzir o enviesamento do modelo para a classe majorit√°ria sem


150


-----

WebMedia‚Äô2024, Juiz de Fora, Brazil Guilherme Fonseca, Gabriel Prenassi, Washington Cunha, Marcos Andr√© Gon√ßalves, & Leonardo Rocha


produzir nenhum tipo de perda de efetividade global (em termos
de MacroF1). Esses m√©todos tamb√©m apresentaram uma redu√ß√£o
no tempo de treinamento do modelo com uma consequente redu√ß√£o na emiss√£o de *ùê∂ùëÇ* 2 . Das estrat√©gias que se destacaram, **duas**
foram originalmente propostas neste trabalho - UBR e E2SC_RL.
Em particular a **UBR** foi aquela que apresentou os resultados mais
consistentes de redu√ß√£o de enviesamento sem perda de efetividade,
com um bom speedup e redu√ß√£o de emiss√£o de *ùê∂ùëÇ* 2, sendo nossa
recomenda√ß√£o final para o problema, se tivermos de fazer uma.
### **6 CONCLUS√ïES E TRABALHOS FUTUROS**

O impacto do desbalanceamento de classes, relacionado ao vi√©s de
um classificador para a classe majorit√°ria, em estrat√©gias do estado
da arte de CAT baseadas em *Transformers*, tem sido pouco discutido
na literatura [ 5 ]. Neste trabalho, apresentamos uma avalia√ß√£o detalhada de m√©todos de *undersampling* (US) aplicados em conjunto com
algoritmos baseados em *Transformers* na tarefa de An√°lise de Sentimento. Primeiramente, realizamos uma an√°lise comparativa entre
m√©todos de classifica√ß√£o baseados em *Transformers* e tradicionais
sob duas perspectivas: efetividade e enviesamento. Essa an√°lise revelou que, al√©m de mais efetivos, como conhecidos, os *Transformers*
s√£o capazes de lidar de forma mais adequada com o problema do vi√©s
que os algoritmos tradicionais. Nossos resultados experimentais
tamb√©m indicaram que ainda existe espa√ßo para melhoria, principalmente em bases de dados com um desbalanceamento maior.
Baseado em um mapeamento da literatura sobre *undersampling*,
selecionamos e implementamos os 14 m√©todos mais utilizados, al√©m
de adaptarmos diretamente um m√©todo de sele√ß√£o de inst√¢ncias
para a tarefa de *undersampling* devido a conex√µes entre as tarefas.
Propomos, tamb√©m, duas novas estrat√©gias de US: E2SC_RL e UBR,
totalizando em um conjunto de 17 m√©todos a serem comparados.
Uma avalia√ß√£o experimental vasta, utilizando esses 17 m√©todos
e 12 bases de dados revelou que um conjunto de cinco m√©todos de
*undersampling* ‚Äì UBR (nossa proposta), NM1, E2SC_RL (nossa proposta), NM2, E2SC ‚Äì foram capazes de reduzir o vi√©s dos modelos
de CAT quando comparados com modelos sem *undersampling* sem
perdas de efetividade (qualidade da classifica√ß√£o). Al√©m disso, esses
mesmos m√©todos produziram uma redu√ß√£o significativa no tempo
de treino e na emiss√£o de *ùê∂ùëÇ* 2 no treinamento dos modelos *Trans-*
*formers* . Entre esses 5 m√©todos, o UBR apresentou os resultados
mais consistentes considerando todos os crit√©rios analisados.

Como trabalhos futuro, visamos estender o presente estudo considerando, tamb√©m, outros cen√°rios de CAT, como multiclasses
e/ou hier√°rquico, al√©m de avaliar outros algoritmos de CAT al√©m
do RoBERTa, tais como BERT e BART. Ademais, considerando que
a efic√°cia dos LLMs recentes em compara√ß√£o com modelos anteriores baseados em *Transformer*, como o RoBERTa, para an√°lise de
sentimentos e prop√≥sitos de CAT ainda n√£o est√° clara [ 10 ], e que,
quando LLMs superam alguns *Transformers* de 1 [a] e 2 [a] gera√ß√£o, os
ganhos s√£o tipicamente de apenas alguns pontos percentuais [10],
consideramos incerto se esses ganhos marginais se traduzem em
benef√≠cios pr√°ticos em aplica√ß√µes do mundo real. Desta forma, em
trabalhos futuros, planejamos realizar uma an√°lise completa sobre
o custo-benef√≠cio dos LLMs em rela√ß√£o aos *Transformers* de 1 [a] e 2 [a]

gera√ß√£o, de modo a habilitar a aplica√ß√£o dos m√©todos de *undersam-*
*pling* como etapas de pr√©-processamento de LLMs recentes.

### **AGRADECIMENTOS**

Este trabalho foi financiado por CNPq, CAPES, Fapemig, FAPESP,
CIIA-Sa√∫de e AWS.
### **REFERENCES**

[1] Lasse F Wolff Anthony, Benjamin Kanding, and Raghavendra Selvan. 2020. Carbontracker: Tracking and predicting the carbon footprint of training deep learning models. *arXiv preprint arXiv:2007.03051* (2020).

[2] Bernhard E Boser, Isabelle M Guyon, and Vladimir N Vapnik. 1992. A training
algorithm for optimal margin classifiers. In *5th COLT* .

[3] Leo Breiman. 2001. Random forests. *Machine learning* (2001).

[4] Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system.
In *Proceedings of the 22nd acm sigkdd KDD* .

[5] Washington Cunha, S√©rgio D. Canuto, Felipe Viegas, Thiago Salles, Christian Gomes, V√≠tor Mangaravite, Elaine Resende, Thierson Rosa, Marcos Andr√©
Gon√ßalves, and Leonardo Rocha. 2020. Extended pre-processing pipeline for text
classification: On the role of meta-feature representations, sparsification and
selective sampling. *IP&M.* (2020).

[6] Washington Cunha, Celso Fran√ßa, Guilherme Fonseca, Leonardo Rocha, and
Marcos Andr√© Gon√ßalves. 2023. An Effective, Efficient, and Scalable ConfidenceBased Instance Selection Framework for Transformer-Based Text Classification.
In *the 46th ACM SIGIR* .

[7] Washington Cunha, V√≠tor Mangaravite, Christian Gomes, S√©rgio Canuto, Felipe Viegas, Celso Fran√ßa, Wellington Santos Martins, Jussara M Almeida, et al .
2021. On the cost-effectiveness of neural and non-neural approaches and representations for text classification: A comprehensive comparative study. *IP&M*
(2021).

[8] Washington Cunha, Felipe Viegas, Celso Fran√ßa, Thierson Rosa, Leonardo Rocha,
and Marcos Andr√© Gon√ßalves. 2023. A Comparative Survey of Instance Selection Methods applied to NonNeural and Transformer-Based Text Classification.
*Comput. Surveys* (2023).

[9] Paula Czarnowska, Yogarshi Vyas, and Kashif Shah. 2021. Quantifying social
biases in NLP: A generalization and empirical comparison of extrinsic fairness
metrics. *TACL* (2021).

[10] Claudio MV de Andrade, Fabiano M Bel√©m, Washington Cunha, Celso Fran√ßa,
Felipe Viegas, Leonardo Rocha, and Marcos Andr√© Gon√ßalves. 2023. On the class
separability of contextual embeddings representations‚Äìor ‚ÄúThe classifier does
not matter when the (text) representation is so good!‚Äù. *IP&M* (2023).

[11] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:
Pre-training of deep bidirectional transformers for language understanding. *arXiv*
*preprint arXiv:1810.04805* (2018).

[12] Georgios Douzas, Maria Lechleitner, and Fernando Bacao. 2022. Improving
the quality of predictive models in small data GSDOT: A new algorithm for
generating synthetic data. *Plos one* (2022).

[13] Vinicius HS Durelli, Rafael S Durelli, Andre T Endo, Elder Cirilo, Washington
Luiz, and Leonardo Rocha. 2018. Please please me: does the presence of test cases
influence mobile app users‚Äô satisfaction?. In *Proceedings of the XXXII Brazilian*
*Symposium on Software Engineering* .

[14] Xavier Ferrer, Tom van Nuenen, Jose M. Such, Mark Cot√©, and Natalia Criado.
2021. Bias and Discrimination in AI: A Cross-Disciplinary Perspective. *IEEE*
*Technology and Society Magazine* (2021).

[15] Hui Han, Wen-Yuan Wang, and Bing-Huan Mao. 2005. Borderline-SMOTE: a
new over-sampling method in imbalanced data sets learning. In *International*
*conference on intelligent computing* . Springer.

[16] Xiao Han, Yuqi Liu, and Jimmy Lin. 2021. The simplest thing that can possibly
work:(pseudo-) relevance feedback via text classification. In *Proceedings of the*
*2021 ACM SIGIR ICTIR* .

[17] Peter Hart. 1968. The condensed nearest neighbor rule (corresp.). *IEEE transac-*
*tions on information theory* (1968).

[18] Ant√¥nio J√∫nior, Pablo Cecilio, Felipe Viegas, Washington Cunha, Elisa Albergaria,
and Leonardo Rocha. 2022. Evaluating topic modeling pre-processing pipelines
for portuguese texts. In *WebMedia* .

[19] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma,
Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: A highly efficient gradient boosting
decision tree. *Advances in NeurIPS* (2017).

[20] Miroslav Kubat, Stan Matwin, et al . 1997. Addressing the curse of imbalanced
training sets: one-sided selection. In *Icml* . Citeseer.

[21] Lo√Øc Lannelongue, Jason Grealey, and Michael Inouye. 2021. Green algorithms:
quantifying the carbon footprint of computation. *Advanced science* (2021).

[22] Jorma Laurikkala. 2001. Improving identification of difficult small classes by
balancing class distribution. In *8th Conference on AIME* .

[23] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman
Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. Bart:
Denoising sequence-to-sequence pre-training for natural language generation,
translation, and comprehension. In *ACL* .


151


-----

Estrat√©gias de Undersampling para Redu√ß√£o de Vi√©s em Classifica√ß√£o de Texto Baseada em Transformers WebMedia‚Äô2024, Juiz de Fora, Brazil



[24] Wei-Chao Lin, Chih-Fong Tsai, Ya-Han Hu, and Jing-Shang Jhang. 2017.
Clustering-based undersampling in class-imbalanced data. *Info. Sciences* (2017).

[25] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A
robustly optimized bert pretraining approach. *arXiv preprint arXiv:1907.11692*
(2019).

[26] Hongxia Lu, Louis Ehwerhemuepha, and Cyril Rakovski. 2022. A comparative
study on deep learning models for text classification of unstructured medical
notes with various levels of class imbalance. *BMC medical research methodology*
(2022).

[27] Washington Luiz, Felipe Viegas, Rafael Alencar, Fernando Mour√£o, Thiago Salles,
D√°rlinton Carvalho, Marcos Andre Gon√ßalves, and Leonardo Rocha. 2018. A
Feature-Oriented Sentiment Rating for Mobile App Reviews. In *the World Wide*
*Web Conference (WWW ‚Äô18)* .

[28] Inderjeet Mani and I Zhang. 2003. kNN approach to unbalanced data distributions:
a case study involving information extraction. In *Proceedings of workshop on*
*learning from imbalanced datasets* . ICML.

[29] Luiz Felipe Mendes, Marcos Gon√ßalves, Washington Cunha, Leonardo Rocha,
Thierson Couto-Rosa, and Wellington Martins. 2020. " Keep it Simple, Lazy"‚Äì
MetaLazy: A New MetaStrategy for Lazy Text Classification. In *Proceedings of*
*the 29th ACM International CIKM* .

[30] Andrew Ng. 2017. Machine learning yearning. *URL: http://www. mlyearning.*
*org/(96)* (2017).

[31] Albert Orriols-Puig and Ester Bernad√≥-Mansilla. 2009. Evolutionary rule-based
systems for imbalanced data sets. *Soft Computing* (2009).

[32] Andrea Pasin, Washington Cunha, Marcos Andr√© Gon√ßalves, and Nicola Ferro.
2024. A Quantum Annealing Instance Selection Approach for Efficient and


Effective Transformer Fine-Tuning. In *ICTIR* .

[33] Alexander Ponomarenko, Nikita Avrelin, Bilegsaikhan Naidan, and Leonid
Boytsov. 2014. Comparative analysis of data structures for approximate nearest
neighbor search. *Data analytics* (2014).

[34] Sivaramakrishnan Rajaraman, Prasanth Ganesan, and Sameer Antani. 2022. Deep
learning model calibration for improving performance in class-imbalanced medical image classification tasks. *PloS one* (2022).

[35] Michael R Smith, Tony Martinez, and Christophe Giraud-Carrier. 2014. An
instance level analysis of data complexity. *Machine learning* (2014).

[36] Ivan Tomek. 1976. An experiment with the edited nearest-neighbor rule. (1976).

[37] Ivan Tomek. 1976. Two Modifications of CNN. *IEEE Transactions on Systems,*
*Man, and Cybernetics* (1976).

[38] Pattaramon Vuttipittayamongkol, Eyad Elyan, Andrei Petrovski, and Chrisina
Jayne. 2018. Overlap-based undersampling for improving imbalanced data classification. In *19th IDEAL* . Springer.

[39] Dennis L Wilson. 1972. Asymptotic properties of nearest neighbor rules using
edited data. *IEEE Transactions on Systems* (1972).

[40] Raymond E Wright. 1995. Logistic regression. (1995).

[41] Show-Jane Yen and Yue-Shi Lee. 2006. Under-sampling approaches for improving
prediction of the minority class in an imbalanced dataset. In *ICIC Kunming, China,*
*August 16‚Äì19, 2006* . Springer.

[42] Bruna Stella Zanotto, Ana Paula Beck da Silva Etges, Avner Dal Bosco, Eduardo Gabriel Cortes, Renata Ruschel, Washington Luiz, et al . 2021. Stroke
outcome measurements from electronic medical records: cross-sectional study
on the effectiveness of neural and nonneural classifiers. *JMIR Medical Informatics*
(2021).


152


-----

