# **EstratÃ©gias de Undersampling para ReduÃ§Ã£o de ViÃ©s em** **ClassificaÃ§Ã£o de Texto Baseada em Transformers**

## Washington Cunha
#### washingtoncunha@dcc.ufmg.br UFMG Minas Gerais, Brazil

## Guilherme Fonseca
#### guilhermefonseca8426@aluno.ufsj.edu.br UFSJ Minas Gerais, Brazil

## Gabriel Prenassi
#### prenassigabriel@aluno.ufsj.edu.br UFSJ Minas Gerais, Brazil

## Marcos AndrÃ© GonÃ§alves
#### mgoncalv@dcc.ufmg.br UFMG Minas Gerais, Brazil
### **ABSTRACT**

Automatic Text Classification (ATC) in unbalanced datasets is a
common challenge in real-world applications. In this scenario, one
(or more) class(es) is overrepresented, which usually causes a bias
in the learning process towards these majority classes. This work
investigates the effect of undersampling methods, which aim to
reduce instances of the majority class, on the effectiveness of recent
ATC methods. Through a systematic mapping of the literature, we
selected and implemented 15 undersampling strategies. We also
propose two new strategies and compare all 17 methods using
RoBERTa as sentiment analysis classifier. Our results suggest that
a set of undersampling approaches is capable of significantly reducing the learning bias of ATC methods towards the majority class on
imbalanced datasets, without incurring any effectiveness loss, and
with improvements in efficiency and reduction of carbon emissions.
### **KEYWORDS**

ClassificaÃ§Ã£o de Texto, Transformers, Undersampling
### **1 INTRODUÃ‡ÃƒO**

ClassificaÃ§Ã£o AutomÃ¡tica de Texto (CAT) [ 16, 29 ] tem experimentado uma grande evoluÃ§Ã£o nos Ãºltimos anos, com Ãªnfase em estratÃ©gias supervisionadas motivadas por avanÃ§os em aprendizagem
profunda baseados em *Transformers* [ 11, 25 ]. Essas estratÃ©gias se
beneficiaram de aplicaÃ§Ãµes que constantemente produzem grandes
volumes de dados rotulados (por exemplo, redes sociais), nos quais
os usuÃ¡rios podem classificar manualmente mensagens, anÃºncios
e produtos, produzindo um grande volume de anotaÃ§Ãµes. Ã€ medida
que a quantidade de dados aumenta, estratÃ©gias de CAT baseadas
em *Transformers* tornam-se mais eficazes, superando significativamente mÃ©todos tradicionais de CAT [ 30 ], tais como RegressÃ£o
LogÃ­stica, KNN, *Random Forest* e *SVM* [7].
Apesar dos enormes avanÃ§os de efetividade alcanÃ§ados pelo uso
de *Transformers* em CAT, o impacto dessas novas abordagens em
problemas tradicionais de classificaÃ§Ã£o, como o viÃ©s de aprendizado

In: Proceedings of the Brazilian Symposium on Multimedia and the Web (WebMe
diaâ€™2024). Juiz de Fora, Brazil. Porto Alegre: Brazilian Computer Society, 2024.
Â© 2024 SBC â€“ Sociedade Brasileira de ComputaÃ§Ã£o.
ISSN 2966-2753

## Leonardo Rocha
#### lcrocha@ufsj.edu.br UFSJ Minas Gerais, Brazil

oriundo de coleÃ§Ãµes de dados desbalanceadas, tem sido pouco estudado [ 5 ]. Em coleÃ§Ãµes de dados desbalanceadas, as classes minoritÃ¡rias podem ser sub-representadas no processo de aprendizado,
resultando em modelos com baixa capacidade de generalizaÃ§Ã£o,
enviesados para as classes majoritÃ¡rias. AlÃ©m de questÃµes Ã©ticas
relacionadas a modelos enviesados [ 14 ], existem diversos cenÃ¡rios
em que a classe minoritÃ¡ria Ã© a classe de interesse.
Por exemplo, na Ã¡rea de saÃºde, a prediÃ§Ã£o de doenÃ§as Ã© geralmente uma tarefa desbalanceada [42], dado que a maioria das pessoas sÃ£o saudÃ¡veis ou pelo menos nÃ£o apresentam a condiÃ§Ã£o de
interesse. Nesse caso, existe a tendÃªncia de um modelo treinado com
uma amostra de dados reflita essa distribuiÃ§Ã£o, sendo enviesado
para a classe â€œsaudÃ¡velâ€. Um modelo de classificaÃ§Ã£o enviesado pode
ser bastante acurado apenas predizendo a classe majoritÃ¡ria, porÃ©m
o impacto de um falso negativo (pacientes portadores da doenÃ§a erroneamente diagnosticados como nÃ£o portadores) Ã© muito alto[ 42 ].
Outro exemplo sÃ£o aplicaÃ§Ãµes relacionadas Ã  anÃ¡lise de sentimento, foco do presente trabalho. Em cenÃ¡rios de produtos [ 13, 27 ]
e pontos de interesse (POI) [ 18 ], usuÃ¡rios comumente tomam suas
decisÃµes de consumo analisando comentÃ¡rios e avaliaÃ§Ãµes de outros
usuÃ¡rios. Alguns usuÃ¡rios levam mais em consideraÃ§Ã£o as avaliaÃ§Ãµes
classificadas como positivas (e.g., pontos positivos de um hotel), outros as avaliaÃ§Ãµes negativas (por que nÃ£o comprar certo produto?).
Em ambas as situaÃ§Ãµes a classe alvo pode ser a minoritÃ¡ria e o resultado de classificaÃ§Ã£o de um modelo enviesado poderÃ¡ influenciar
de forma equivocada a decisÃ£o do usuÃ¡rio.
Assim, a primeira pergunta de pesquisa que procuramos responder Ã© *PP1: Como algoritmos estado da arte recentes, baseados em*
*Transformers, sÃ£o afetados pelo desbalanceamento de classes em tare-*
*fas de anÃ¡lise de sentimentos? HÃ¡ espaÃ§o para melhorias?* .
Para responder esta pergunta, comparamos o desempenho de
seis mÃ©todos de classificaÃ§Ã£o tradicionais (KNN, *Random Forest*, RegressÃ£o LogÃ­stica, Support Vector Machine (SVM), XGBoost e LightGBM) e trÃªs mÃ©todos baseados em *Transformers* (RoBERTa [ 25 ],
BART [ 23 ] e BERT [ 11 ]), avaliando tanto a efetividade (em termos
de MacroF1) quanto o viÃ©s dos modelos resultantes (em termos
de TPRGap, uma mÃ©trica que captura o viÃ©s a partir da diferenÃ§a
absoluta entre o TPR - *True Positive Rate* - das classes [21]).
Nossos resultados mostram que modelos baseados em *Transform-*
*ers*, alÃ©m de efetivos, possuem um viÃ©s menor quando comparados
a modelos gerados por classificadores tradicionais. No entanto, nossos resultados tambÃ©m apontam que, apesar disso, ainda hÃ¡ espaÃ§o


144


-----

WebMediaâ€™2024, Juiz de Fora, Brazil Guilherme Fonseca, Gabriel Prenassi, Washington Cunha, Marcos AndrÃ© GonÃ§alves, & Leonardo Rocha


considerÃ¡vel para melhorias, principalmente em bases de dados
que possuem um elevado grau de desbalanceamento (razÃ£o entre
nÃºmero de documentos da classe majoritÃ¡ria e o nÃºmero de documentos da classe minoritÃ¡ria superior a 5).
Existem duas principais abordagens utilizadas para lidar com
o desbalanceamento de dados. O *oversampling* consiste em criar
novas amostras (geralmente sintÃ©ticas) da classe minoritÃ¡ria, para
igualÃ¡-la em termos de instÃ¢ncias Ã  classe majoritÃ¡ria [ 15 ]. Essa
abordagem incorre em um aumento significativo no tempo de geraÃ§Ã£o dos modelos, uma vez que aumenta-se o total de instÃ¢ncias a
serem consideradas no aprendizado. Mais ainda, a geraÃ§Ã£o sintÃ©tica
de novos dados, principalmente textuais, pode ser nÃ£o trivial [12].
A abordagem alternativa para enfrentar o desbalanceamento Ã© o
*undersampling* (US), foco do presente trabalho, que sÃ£o tÃ©cnicas que
reduzem instÃ¢ncias da classe majoritÃ¡ria para equilibrar as classes.
AtÃ© onde sabemos, nÃ£o existem estudos na literatura que abordam
como os mÃ©todos de *undersampling* interagem com os algoritmos
de CAT do estado da arte baseados em *Transformers* . Assim, nossa
segunda pergunta de pesquisa Ã© *PP2: MÃ©todos de undersampling,*
*aplicados juntamente com classificadores baseados em Transformers,*
*sÃ£o capazes de reduzir o viÃ©s dos modelos de classificaÃ§Ã£o? Qual o*
*impacto dessa combinaÃ§Ã£o na efetividade do modelo?*
Para responder a PP2, primeiramente realizamos uma revisÃ£o
sistemÃ¡tica sobre os principais mÃ©todos de *undersampling* propostos na literatura. Identificamos e implementamos 14 mÃ©todos de
*undersampling* que estÃ£o entre os mais utilizados. Apesar de terem
fins diferentes, as Ã¡reas de seleÃ§Ã£o de instÃ¢ncias (SI) [ 8 ] e *undersam-*
*pling* sÃ£o bastante relacionadas, pois ambas tratam de tÃ©cnicas que
visam selecionar um subconjunto de dados representativos â€“ o que
as difere sÃ£o os objetivos da reduÃ§Ã£o. Nesse sentido, adaptamos uma
estratÃ©gia de SI, que Ã© considerada estado da arte, para o cenÃ¡rio de
*undersampling*, o E2SC [ 6 ]. Por fim, propomos duas novas estratÃ©gias de *undersampling*, que sÃ£o contribuiÃ§Ãµes desse trabalho: (1) a
UBR ( *Undersampling* Baseado em RedundÃ¢ncia), que se concentra
em remover instÃ¢ncias da classe majoritÃ¡ria consideradas redundantes (muito similares Ã  outras instÃ¢ncias); e (2) E2SC-RL, uma variaÃ§Ã£o do mÃ©todo de SI E2SC que realiza o cÃ¡lculo das probabilidades
das instÃ¢ncias serem removidas por meio de RegressÃ£o LogÃ­stica.
Investigamos o desempenho das 17 tÃ©cnicas de *undersampling*
em conjunto com o RoBERTa, classificador baseado em *Transform-*
*ers* considerado estado da arte em anÃ¡lise de sentimentos [ 26 ]. De
fato, *benchmarks* recentes [ 10, 26 ] demonstraram que as diferenÃ§as
entre as novas versÃµes desses *Transformers* (incluindo RoBERTa,
BERT, DistilBERT, BART, AlBERT e XLNet) em diversos conjuntos
de dados utilizados em nossos experimentos sÃ£o muito pequenas.
Nossos resultados apontaram que os mÃ©todos de *undersampling*
NM1 [ 28 ], NM2 [ 28 ], E2SC [ 6 ], E2SC-RL (nossa proposta) e UBR
(nossa proposta) foram capazes de reduzir o viÃ©s do modelo de
classificaÃ§Ã£o, mantendo sua efetividade.
MÃ©todos de CAT baseados em *Transformers* demandam elevado
custo computacional no processo de aprendizado dos modelos de
classificaÃ§Ã£o, resultando em longos tempos de execuÃ§Ã£o e tambÃ©m
contribuindo significativamente para a emissÃ£o de carbono na atmosfera [ 1 ]. Assim, precisamos investigar o impacto desse novo
passo de prÃ©-processamento na eficiÃªncia (i.e. tempo e custo computacional para geraÃ§Ã£o e classificaÃ§Ã£o) dos modelos. Dessa forma,


nossa terceira pergunta de pesquisa Ã©: *PP3: Qual o impacto da apli-*
*caÃ§Ã£o dessa etapa adicional de prÃ©-processamento (undersampling)*
*em termos de eficiÃªncia? E em termos da emissÃ£o de carbono?* .
Nossos resultados apontam que o uso de algumas das estratÃ©gias
de *undersampling*, mais especificamente UBR, NM1, E2SC-RL, NM2
e E2SC, que foram capazes nÃ£o apenas de reduzir o viÃ©s sem perda
de efetividade, mas tambÃ©m diminuÃ­ram significativamente o tempo
de treinamento dos modelos (50% em mÃ©dia), o que, consequentemente, contribuiu para reduÃ§Ã£o na emissÃ£o de *ğ¶ğ‘‚* 2 (50%, em mÃ©dia)
durante a geraÃ§Ã£o e execuÃ§Ã£o dos modelos de classificaÃ§Ã£o.
Assim, as principais contribuiÃ§Ãµes deste trabalho sÃ£o:

  - Mapeamento sistemÃ¡tico da literatura sobre mÃ©todos de *un-*
*dersampling*, identificando e implementando 14 mÃ©todos que
estÃ£o entre os mais utilizados. Identificamos e adaptamos
tambÃ©m um mÃ©todo de seleÃ§Ã£o de instÃ¢ncias para a tarefa
de *undersampling* ;

   - Propostas de duas novas estratÃ©gias de *undersampling* ;

  - AvaliaÃ§Ã£o das tÃ©cnicas de *undersampling* em conjunto com
classificadores baseado em *Transformers* sob trÃªs perspectivas: (1) efetividade da classificaÃ§Ã£o; (2) eficiÃªncia (tempo); e
(3) capacidade de generalizaÃ§Ã£o (viÃ©s).
### **2 LEVANTAMENTO DAS ESTRATÃ‰GIAS**

Nesta seÃ§Ã£o, detalhamos o processo de revisÃ£o sistemÃ¡tica da literatura (RSL) [ 7, 8 ] para selecionar quais estratÃ©gias de *undersampling*
e seleÃ§Ã£o de instÃ¢ncias que serÃ£o avaliadas.
### **2.1 MÃ©todos de Undersampling**

Recorremos ao mecanismo de pesquisa do Google Scholar para submeter a consulta e gerar nosso conjunto inicial de artigos. O Google
Scholar foi escolhido devido Ã  sua ampla cobertura, abrangendo as
principais bibliotecas digitais de editoras como ACM, IEEE e Elsevier, alÃ©m de repositÃ³rios de prÃ©-impressÃ£o como Arxiv. A *string* de
busca utilizada foi " *Undersampling* " e, para maximizar a abrangÃªncia
da pesquisa, o mecanismo de busca nÃ£o aplicou nenhum filtro de
local ou ano. Com base nisso, coletamos, inicialmente, um total de
500 artigos Ãºnicos que, de alguma forma, utiliza alguma estratÃ©gia
de *undersampling* .
Analisamos manualmente os 500 artigos, procurando identificar
os mais pertinentes para o estudo. Um artigo foi considerado **rel-**
**evante** caso utilizasse tÃ©cnicas de *undersampling* para reduzir desbalanceamento, sendo que o mÃ©todo de *undersampling* empregado
deveria ser explicitamente mencionado (citado). Identificamos 139
artigos relevantes e, a partir deles, enumeramos todas as tÃ©cnicas de *undersampling* utilizadas, encontrando, ao todo, 32 tÃ©cnicas
diferentes. Uma tabela completa com uma descriÃ§Ã£o de todas as
estratÃ©gias identificadas estÃ¡ disponÃ­vel online [1] . Optamos por considerar em nossa avaliaÃ§Ã£o aqueles que foram utilizados em mais
de um dos trabalhos relevantes. Faremos nossa avaliaÃ§Ã£o sobre os
seguintes mÃ©todos:

**- Links de Tomek (TL) [** **37** **]:** dados dois exemplos *ğ‘’* *ğ‘–* e *ğ‘’* *ğ‘—* de diferentes classes, com *ğ‘‘* ( *ğ‘’* *ğ‘–* *,ğ‘’* *ğ‘—* ) representando a distÃ¢ncia entre *ğ‘’* *ğ‘–* e *ğ‘’* *ğ‘—*,
um par *ğ´* ( *ğ‘’* *ğ‘–* *,ğ‘’* *ğ‘—* ) Ã© chamado de link de Tomek se nÃ£o houver nenhum exemplo *ğ‘’* *ğ‘™* tal que *ğ‘‘* ( *ğ‘’* *ğ‘–* *,ğ‘’* *ğ‘™* ) *< ğ‘‘* ( *ğ‘’* *ğ‘–* *,ğ‘’* *ğ‘—* ) ou *ğ‘‘* ( *ğ‘’* *ğ‘—* *,ğ‘’* *ğ‘™* ) *< ğ‘‘* ( *ğ‘’* *ğ‘–* *,ğ‘’* *ğ‘—* ).

1 https://github.com/guilherme8426/Undersampling


145


-----

EstratÃ©gias de Undersampling para ReduÃ§Ã£o de ViÃ©s em ClassificaÃ§Ã£o de Texto Baseada em Transformers WebMediaâ€™2024, Juiz de Fora, Brazil


Se dois exemplos formam um link de Tomek, entÃ£o ou um desses exemplos foi classificado manualmente errado ou ambos sÃ£o exemplos
pertencentes Ã  fronteiras entre as classes e podem ser removidos.

**- Condensed Nearest Neighbors (CNN)[** **17** **]:** O conjunto de dados *ğ‘†* Ã© inicializado com um exemplo da classe majoritÃ¡ria e todos
os exemplos da classe minoritÃ¡ria e um conjunto *ğ‘‡* Ã© criado com os
elementos que nÃ£o pertencem a *ğ‘†* . Cada exemplo de *ğ‘‡* Ã© classificado
pelo KNN usando *ğ‘†* como conjunto de treinamento. Caso o KNN
acerte a classe do exemplo, ele permanece em *ğ‘‡* ; caso contrÃ¡rio, o
exemplo Ã© removido de *ğ‘‡* e colocado em *ğ‘†* . Esse processo se repete
atÃ© que nÃ£o ocorram mais mudanÃ§as no conjunto *ğ‘†* . Ao final, os
elementos de *ğ‘‡* sÃ£o descartados.

**- One-Sided Selection (OSS)[** **20** **]:** Combina o TL e uma variaÃ§Ã£o do
CNN. inicialmente, como no CNN, um conjunto *ğ‘†* Ã© inicializado com
todas as instÃ¢ncias da classe minoritÃ¡ria e uma da classe majoritÃ¡ria
e um conjunto *ğ‘‡* com o restante dos elementos, depois as instÃ¢ncias
de *ğ‘‡* sÃ£o classificadas com o KNN treinado em *ğ‘†* e cada instÃ¢ncia
classificada erroneamente Ã© colocada em *ğ‘†* . No final, o TL Ã© utilizado
em *ğ‘†* para identificar pares ambÃ­guos na fronteira da classe.

**- Edited Nearest Neighbours (ENN)[** **39** **]:** insere todas as instÃ¢ncias do conjunto original *ğ‘‡* no conjunto de soluÃ§Ã£o *ğ‘†*, utilizando
o KNN de maneira iterativa para classificar todas as instÃ¢ncias *ğ‘¥*
dado que *ğ‘¥* âˆˆ *ğ‘†* e que *ğ‘¥* pertenÃ§a a classe majoritÃ¡ria (considerando
o conjunto { *ğ‘†* âˆ’{ *ğ‘¥* }} como possÃ­veis vizinhos). Por fim, remove as
instÃ¢ncias classificadas incorretamente.

**- Repeated Edited Nearest Neighbours (RENN)[** **36** **]:** ENN aplicado sucessivamente atÃ© que nÃ£o seja possÃ­vel remover mais pontos.

**- ALL k-NN [** **36** **]:** ENN aplicado sucessivamente, mas, a cada aplicaÃ§Ã£o, o nÃºmero de vizinhos a serem considerados aumenta.

**- Neighbourhood Cleaning Rule (NCR)[** **22** **]:** Utiliza o KNN para
classificar todas as instÃ¢ncias da base de dados. Caso a classe prevista seja diferente da classe real e a instÃ¢ncia pertenÃ§a Ã  classe
majoritÃ¡ria, a instÃ¢ncia Ã© eliminada. O NCR classifica tambÃ©m as
instÃ¢ncias da classe minoritÃ¡ria. Se a classificaÃ§Ã£o estiver incorreta, o mÃ©todo elimina os vizinhos mais prÃ³ximos da instÃ¢ncia que
pertencem Ã  classe majoritÃ¡ria.

**- Near Miss (NM)[** **28** **]:** trÃªs mÃ©todos de *undersampling* sÃ£o propostos. O NearMiss-1 (NM1) remove as instÃ¢ncias da classe majoritÃ¡ria
que tÃªm a menor distÃ¢ncia mÃ©dia entre as k instÃ¢ncias da classe
minoritÃ¡ria. O NearMiss-2 (NM2) seleciona os elementos da classe
majoritÃ¡ria cuja distÃ¢ncia mÃ©dia para os k pontos mais distantes
da classe minoritÃ¡ria Ã© a mais baixa. JÃ¡ o NearMiss-3 (NM3) calcula,
para cada instÃ¢ncia da classe minoritÃ¡ria, as k instÃ¢ncias da classe
majoritÃ¡ria mais prÃ³ximas e as mantÃ©m na base de dados.

**- SBC [** **41** **]:** Todo o conjunto de treino Ã© dividido em N *clusters* . Para
cada um dos *clusters*, o nÃºmero de instÃ¢ncias a serem selecionadas
Ã© calculado com base no nÃºmero de amostras da classe majoritÃ¡ria
e da classe minoritÃ¡ria que existem no *cluster* . ApÃ³s isso, exemplos
da classe majoritÃ¡ria sÃ£o selecionados aleatoriamente. Por fim, o
algoritmo combina as instÃ¢ncias selecionadas de cada *cluster* com
as da classe minoritÃ¡ria para formar um novo conjunto.

**- IHT [** **35** **]:** Utiliza um classificador (c) para obter o *instance hard-*
*ness* (IH) de cada instÃ¢ncia. O IH de uma instÃ¢ncia Ã© dado por
*ğ¼ğ»* ( *< ğ‘¥* *ğ‘–* *,ğ‘¦* *ğ‘–* *>* ) = 1 âˆ’ *ğ‘* ( *ğ‘¦* *ğ‘–* | *ğ‘¥* *ğ‘–* *,ğ‘* ) onde *ğ‘* ( *ğ‘¦* *ğ‘–* | *ğ‘¥* *ğ‘–* *,ğ‘* ) denota a probabilidade, gerada pelo classificador c, da instÃ¢ncia *ğ‘¥* *ğ‘–* pertencer Ã  classe
*ğ‘¦* *ğ‘–* . O IHT seleciona amostras da classe majoritÃ¡ria com baixa probabilidade de pertencerem Ã  classe majoritÃ¡ria para serem removidas.



**- CC-NN [** **24** **]:** As instÃ¢ncias da classe majoritÃ¡ria sÃ£o divididas em
N *clusters*, com N sendo o nÃºmero de instÃ¢ncias da classe minoritÃ¡ria.
ApÃ³s isso, o vizinho mais prÃ³ximo do centrÃ³ide de cada um dos
*clusters* que pertenÃ§a Ã  classe majoritÃ¡ria Ã© escolhido para compor,
junto com as instÃ¢ncias da classe minoritÃ¡ria, o conjunto final.

**- OBU [** **38** **]:** Utiliza o Fuzzy c-means para dividir os dados em 2 *clus-*
*ters*, onde o *cluster* que tiver mais instÃ¢ncias da classe minoritÃ¡ria
Ã© chamado de *ğ¶ğ‘€* . Depois disso, o algoritmo remove todas as instÃ¢ncias da classe majoritÃ¡ria cujo grau de pertencimento para o
CM Ã© menor que *ğ›¼* (hiperparÃ¢metro).
### **2.2 MÃ©todos de seleÃ§Ã£o de instÃ¢ncia**

Apesar de terem fins diferentes, as Ã¡reas de seleÃ§Ã£o de instÃ¢ncias
(SI) e *undersampling* (US) sÃ£o relacionadas, pois tratam de tÃ©cnicas que visam selecionar um subconjunto de dados a ser usado no
treinamento do modelo e que cumpram seus objetivos: (1) no caso
de SI, melhorar a eficiÃªncia sem perda de efetividade; e (2) no caso
de US, reduzir o viÃ©s da classe majoritÃ¡ria, mantendo a efetividade.
Apesar dos objetivos finais serem diferentes, partimos da hipÃ³tese
de que hÃ¡ uma relaÃ§Ã£o subjacente entre ambas as tarefas, principalmente para mÃ©todos de SI baseados em reduÃ§Ã£o de redundÃ¢ncia [ 8 ],
que podem ser adaptados para remoÃ§Ã£o de instÃ¢ncias redundantes
da classe majoritÃ¡ria. Essa hipÃ³tese norteia a concepÃ§Ã£o do nosso
novo mÃ©todo de US - UBR - descrito na prÃ³xima seÃ§Ã£o e tambÃ©m nos
motivou a selecionar e adaptar trabalhos de SI para *undersampling* .
Uma varredura na literatura de SI aplicada a CAT nos revela
que o mÃ©todo E2SC [ 6, 32 ] Ã© o estado da arte. O mÃ©todo funciona
em duas etapas. Na primeira, calcula as probabilidades de cada instÃ¢ncia ser removida. Estas probabilidades sÃ£o obtidas por meio da
confianÃ§a do classificador KNN, que Ã© calibrado (classificador cujas
previsÃµes de probabilidade de classe correspondem bem Ã  acurÃ¡cia
do classificador) [ 34 ]. Na segunda etapa, o E2SC tenta estimar qual
a taxa de reduÃ§Ã£o Ã³tima para a base de dados. ApÃ³s isso, as instÃ¢ncias sÃ£o amostradas aleatoriamente, ponderadas pela probabilidade
encontrada no primeiro passo. Para o nosso trabalho, realizamos
uma modificaÃ§Ã£o do E2SC, chamada E2SC_RL, que segue o mesmo
princÃ­pio do E2SC, porÃ©m, em vez do KNN como classificador, utilizaremos RegressÃ£o LogÃ­stica (RL). Optamos por essa abordagem
ser um classificador igualmente calibrado e possuir baixo custo computacional, inferior ao KNN. Portanto, consideramos em nossos
experimentos o E2SC e o E2SC_RL, ambos adaptados para remover
apenas instÃ¢ncias da classe majoritÃ¡ria. AlÃ©m de todos as estratÃ©gias apresentadas nesta seÃ§Ã£o, apresentamos a seguir nossa nova
proposta de estratÃ©gia de *undersampling* .
### **3 MÃ‰TODO PROPOSTO**

Nesta seÃ§Ã£o, apresentamos nossa segunda contribuiÃ§Ã£o neste trabalho, uma nova abordagem denominada UBR ( *Undersampling*
Baseado em RedundÃ¢ncia). Essa abordagem busca inspiraÃ§Ã£o em
tÃ©cnicas de SI. Um par de documentos Ã© considerado redundante se
apresenta alta similaridade entre si. Nossa hipÃ³tese Ã© que manter
apenas uma das instÃ¢ncias no conjunto de treinamento Ã© suficiente,
pois a presenÃ§a de ambas nÃ£o trarÃ¡ aumento significativo na aprendizagem do modelo. Ao se concentrar na reduÃ§Ã£o de redundÃ¢ncia
na classe majoritÃ¡ria, obtemos um potencial de reduÃ§Ã£o do desbalanceamento e, consequentemente, do viÃ©s para essa classe. O
**Algoritmo 1** detalha o pseudocÃ³digo do UBR.


146


-----

WebMediaâ€™2024, Juiz de Fora, Brazil Guilherme Fonseca, Gabriel Prenassi, Washington Cunha, Marcos AndrÃ© GonÃ§alves, & Leonardo Rocha


**Algoritmo 1:** Algoritmo UBR

**Input:** X, *ğ›¼*
**Output:** instanciasSel

**1** *ğ‘‹* *ğ‘€ğ‘ğ‘—* â† *ğ‘œğ‘ğ‘¡ğ‘’ğ‘Ÿğ¼ğ‘›ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘ğ‘ * ( *ğ‘‹,ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’* = *ğ‘šğ‘ğ‘—ğ‘œğ‘Ÿğ‘–ğ‘¡ğ‘ğ‘Ÿğ‘–ğ‘* ) ;

**2** *ğ‘‹* *ğ‘€ğ‘–ğ‘›* â† *ğ‘œğ‘ğ‘¡ğ‘’ğ‘Ÿğ¼ğ‘›ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘ğ‘ * ( *ğ‘‹,ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’* = *ğ‘šğ‘–ğ‘›ğ‘œğ‘Ÿğ‘–ğ‘¡ğ‘ğ‘Ÿğ‘–ğ‘* ) ;

**3** *ğ‘–ğ‘›ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘†ğ‘’ğ‘™* â† *ğ‘‹* *ğ‘€ğ‘–ğ‘›* ;

**4** *ğ·* â† *ğ‘‘ğ‘–ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘ğ´ğ‘ğ‘Ÿğ‘œğ‘¥ğ‘–ğ‘šğ‘ğ‘‘ğ‘ğ‘ğ‘‰ğ‘–ğ‘§ğ‘–ğ‘›â„ğ‘œğ‘ * ( *ğ‘‹* *ğ‘€ğ‘ğ‘—* ) ;

**5** *ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ * â† *ğ‘‹* *ğ‘€ğ‘ğ‘—* ;

**6** *ğ‘* â† ï¿½ï¿½ *ğ‘‹* *ğ‘€ğ‘ğ‘—* ï¿½ï¿½ âˆ’âˆ¥ *ğ‘‹* *ğ‘€ğ‘–ğ‘›* âˆ¥ ;

**7** **while** *ğ‘* *>* 0 **do**
**8** *ğ´, ğµ* â† *ğ‘ƒğ‘ğ‘Ÿğ‘€ğ‘ğ‘–ğ‘ ğ‘†ğ‘–ğ‘šğ‘–ğ‘™ğ‘ğ‘Ÿ* ( *ğ‘‹* *ğ‘€ğ‘ğ‘—* *, ğ·* ) ;

**9** **if** (âˆ¥ *ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ * [ *ğ´* ]âˆ¥ *> ğ›¼* ) *ğ‘‚ğ‘…* (âˆ¥ *ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ * [ *ğµ* ]âˆ¥ *> ğ›¼* ) **then**
**10** *ğ‘ğ‘œğ‘›ğ‘¡ğ‘–ğ‘›ğ‘¢ğ‘’* ;

**11** **end**

**12** **if** *ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ * [ *ğ´* ] â‰  *ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ * [ *ğµ* ] **then**
**13** *ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ * [ *ğ´* ] â† *ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ * [ *ğ´* ] [ï¿½] *ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ * [ *ğµ* ] ;

**14** *ğ‘‘ğ‘’ğ‘™ğ‘’ğ‘¡ğ‘ğ‘Ÿ* ( *ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿ* [ *ğµ* ]) ;

**15** *ğ‘* = *ğ‘* âˆ’ 1 ;

**16** **end**

**17** **end**

**18** *ğ‘’ğ‘ ğ‘ğ‘œğ‘™â„ğ‘–ğ‘‘ğ‘œğ‘ * â† *ğ‘’ğ‘ ğ‘ğ‘œğ‘™â„ğ‘’ğ‘…ğ‘’ğ‘ğ‘Ÿğ‘’ğ‘ ğ‘’ğ‘›ğ‘¡ğ‘ğ‘›ğ‘¡ğ‘’* ( *ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ * ) ;

**19** *ğ‘–ğ‘›ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘†ğ‘’ğ‘™* â† *ğ‘–ğ‘›ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘†ğ‘’ğ‘™* [ï¿½] *ğ‘’ğ‘ ğ‘ğ‘œğ‘™â„ğ‘–ğ‘‘ğ‘œğ‘ * ;

Dado *ğ‘‹* como o conjunto total de instÃ¢ncias de treinamento, inicialmente dividimos *ğ‘‹* em dois conjuntos, *ğ‘‹* *ğ‘€ğ‘ğ‘—* e *ğ‘‹* *ğ‘€ğ‘–ğ‘›*, onde *ğ‘‹* *ğ‘€ğ‘ğ‘—*
consiste em instÃ¢ncias de *ğ‘‹* pertencentes Ã  classe majoritÃ¡ria, e
*ğ‘‹* *ğ‘€ğ‘–ğ‘›* consiste em instÃ¢ncias de *ğ‘‹* pertencentes Ã  classe minoritÃ¡ria.
Para cada instÃ¢ncia de *ğ‘‹* *ğ‘€ğ‘ğ‘—*, calculamos a similaridade de cosseno
da instÃ¢ncia para os seus K vizinhos mais prÃ³ximos e colocamos
em uma lista ordenada *ğ·* .

Por questÃµes de otimizaÃ§Ã£o de tempo e de uso de memÃ³ria, utilizamos uma versÃ£o aproximada do KNN [ 33 ]. ApÃ³s isso, passamos
a considerar cada instÃ¢ncia de *ğ‘‹* *ğ‘€ğ‘ğ‘—* como um *cluster* individual e
realizamos *ğ‘* iteraÃ§Ãµes, onde *ğ‘* = *ğ‘‹* *ğ‘€ğ‘ğ‘—* âˆ’ *ğ‘‹* *ğ‘€ğ‘–ğ‘›* . Em cada iteraÃ§Ã£o,
buscamos em *ğ·* o par de instÃ¢ncias *ğ´* e *ğµ* pertencentes a *ğ‘‹* *ğ‘€ğ‘ğ‘—* que
apresenta a maior similaridade e que estÃ£o em *clusters* distintos e
cujos *clusters* nÃ£o sejam maiores que *ğ›¼* (hiperparÃ¢metro do mÃ©todo
que controla a quantidade de vizinhos a ser avaliada), com o objetivo de unir os *clusters* aos quais *ğ´* e *ğµ* pertencem. Ao final, temos
| *ğ‘‹* *ğ‘€ğ‘–ğ‘›* | *clusters* dentro do conjunto *ğ‘‹* *ğ‘€ğ‘ğ‘—*, dos quais serÃ¡ selecionado
aleatoriamente um representante para compor, juntamente com o
conjunto *ğ‘‹* *ğ‘€ğ‘–ğ‘›*, o novo conjunto de treinamento. [2]

|dataset|# docs|# majoritÃ¡ria|# minoritÃ¡ria|RD|Nome|
|---|---|---|---|---|---|
|sentistrength_twitter_2L vader_amazon_2L english_dailabor_2L debate_2L sentistrength_youtube_2L sentistrength_rw_2L vader_twitter_2L tweet_semevaltest_2L sentistrength_digg_2L sentistrength_myspace_2L sentistrength_bbc_2L digital_music_2L|2,289 3,610 1,227 1,979 2,432 705 4,196 3,060 782 834 752 162,989|1,340 2,128 739 1,249 1,665 484 2,897 2,223 572 702 653 158,985|949 1,482 488 730 767 221 1,299 837 210 132 99 4,004|1.41 1.44 1.51 1.71 2.17 2.19 2.23 2.66 2.72 5.32 6.60 39.71|A B C D E F G H I J K L|



**Tabela 1: ColeÃ§Ãµes de dados utilizadas nos experimentos. A**
**coluna â€œnomeâ€ contÃ©m como a base vai ser referenciada.**

2 Nossa tÃ©cnica Ã© limitada a problemas de classificaÃ§Ã£o binÃ¡rios. Deixamos para o futuro
a extensÃ£o da abordagem para problemas multi-rÃ³tulo.

### **4 CONFIGURAÃ‡ÃƒO EXPERIMENTAL** **4.1 Base de dados**


A eficiÃªncia Ã© medida com base no custo de cada mÃ©todo em termos
do tempo total necessÃ¡rio para construir o modelo e realizar as clasificaÃ§Ãµes. O *Speedup* Ã© calculado como *ğ‘†* = *[ğ‘‡]* *ğ‘‡* *[ğ‘¤ğ‘œ]* *ğ‘¤* [, onde] *[ ğ‘‡]* *[ğ‘¤]* [Ã© o tempo]

total gasto na construÃ§Ã£o do modelo, mais o tempo da classificaÃ§Ã£o,
usando alguma abordagem de *undersampling*, e *ğ‘‡* *ğ‘¤ğ‘œ* Ã© o tempo total
gasto na execuÃ§Ã£o (modelo e classificaÃ§Ã£o) sem a fase de *undersam-*
*pling* . A emissÃ£o de *ğ¶ğ‘‚* 2 Ã© o equivalente de diÃ³xido de carbono gasto
para treinamento de um modelo e classificaÃ§Ã£o baseado em [21].
Os experimentos foram realizados na AWS. Para as bases de
dados de A atÃ© K, as etapas *undersampling*, que demandam estritamente processamento em CPU, utilizaram uma instÃ¢ncia do tipo
**c6a.4xlarge** e a classificaÃ§Ã£o, que demanda hardware especializado
(GPU), instÃ¢ncias do tipo **g4dn.xlarge** . Para a base L, que Ã© bem
maior que as demais, demandou um poder computacional maior e
ambas as etapas foram executadas em instÃ¢ncias do tipo **g5.4xlarge** .
As bases de dados foram divididas utilizando o mÃ©todo de validaÃ§Ã£o
cruzada com 5 partiÃ§Ãµes (base L) ou 10 partiÃ§Ãµes (demais bases).
As comparaÃ§Ãµes foram realizadas utilizando o mÃ©todo estatÃ­stico
Teste-T com correÃ§Ã£o de Bonferroni [8].


Consideramos 12 *datasets*, com diferentes nÃ­veis de desbalanceamento. A Tabela 1 mostra os *datasets* com o nÃºmero de documentos,
nÃºmero de documentos pertencentes Ã  classe majoritÃ¡ria e Ã  minoritÃ¡ria, o nome pelo qual vamos nos referir a base de dados ao
longo do trabalho e a razÃ£o de desbalanceamento (RD)[ 31 ], mÃ©trica
que demonstra o quÃ£o desbalanceado Ã© uma base de dados (quanto
maior for a RD mais desbalanceado Ã© a base de dados). O RD Ã©
calculado como sendo *ğ‘…ğ·* = *[ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’ğ‘šğ‘]* *[ğ‘—]* *[ğ‘œğ‘Ÿğ‘–ğ‘¡ğ‘ğ‘Ÿğ‘–ğ‘]*

*ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’ğ‘šğ‘–ğ‘›ğ‘œğ‘Ÿğ‘–ğ‘¡ğ‘ğ‘Ÿğ‘–ğ‘* [.]
### **4.2** **MÃ©todo de ClassificaÃ§Ã£o de Texto**

Consideramos mÃ©todos de CAT baseados em *Transformers* **BART**

[ 23 ], **RoBERTa** [ 25 ] e **BERT** [ 11 ], que atualmente se apresentam
como os melhores entre os mÃ©todos de classificaÃ§Ã£o utilizados na
literatura para tarefa de AnÃ¡lise de Sentimento [ 8 ]. Para ajustar os
hiperparÃ¢metros, utilizamos a mesma metodologia discutida em [ 8 ].
Assim, fixamos a taxa de aprendizado inicial como 5 Ã— 10 [âˆ’][5], o
nÃºmero mÃ¡ximo de Ã©pocas como 20 e a paciÃªncia como 5 Ã©pocas. Por
fim, realizamos um grid search em max_len (150 e 256) e batch_size
(16, 32 e 64), pois esses valores especificados impactam diretamente
na eficiÃªncia e efetividade do modelo. Utilizamos, tambÃ©m, 6 classificadores tradicionais: **KNN**, *Random Forest* [ 3 ], RegressÃ£o LogÃ­stica
( **RL** ) [ 40 ], **SVM** [ 2 ], *XGBoost* ( **XGB** ) [ 4 ] e *LightGBM* ( **LGBM** ) [ 19 ].
### **4.3 MÃ©tricas e Protocolo Experimental**

Nossa avaliaÃ§Ã£o Ã© feita sob trÃªs perspectivas: (1) efetividade da
classificaÃ§Ã£o; (2) capacidade de generalizaÃ§Ã£o dos modelos (viÃ©s);
e (3) eficiÃªncia (tempo e emissÃ£o de *ğ¶ğ‘‚* 2 ). A efetividade Ã© avaliada
utilizando a *Macro Average F1* (MacroF1). A capacidade de generalizaÃ§Ã£o Ã© medida pela mÃ©trica TPRGap apresentada em [ 9 ], definida
na EquaÃ§Ã£o 1, onde *ğ‘‡ğ‘ƒğ‘…* ( *ğ‘–* ) Ã© *true positive rate* da classe *ğ‘–*, *ğ‘‡* Ã© o
nÃºmero total de classes, *ğ‘* Ã© o fator de normalizaÃ§Ã£o, que Ã© igual
ao nÃºmero de pares de classes que comparamos [ï¿½] *[ğ‘‡]* 2 ï¿½.


*ğ‘‡ğ‘ƒğ‘…ğºğ‘ğ‘* =

*ğ‘–,ğ‘—ğœ–ğ‘‡*

âˆ‘ï¸


*ğ‘–,ğ‘—ğœ–ğ‘‡*


| *ğ‘‡ğ‘ƒğ‘…* ( *ğ‘–* ) âˆ’ *ğ‘‡ğ‘ƒğ‘…* ( *ğ‘—* ) |

(1)
*ğ‘*


147


-----

EstratÃ©gias de Undersampling para ReduÃ§Ã£o de ViÃ©s em ClassificaÃ§Ã£o de Texto Baseada em Transformers WebMediaâ€™2024, Juiz de Fora, Brazil

**Tabela 2: Resultados de Macro-F1 e TPRGap dos classificadores. CÃ©lulas em negrito sÃ£o os maiores valores numÃ©ricos para uma**

|Col1|RoBERTa|BART|BERT|SVM|LR|RF|XGB|LGBM|KNN|
|---|---|---|---|---|---|---|---|---|---|
|dataset|Macro F1 TPRGap|Macro F1 TPRGap|Macro F1 TPRGap|Macro F1 TPRGap|Macro F1 TPRGap|Macro F1 TPRGap|Macro F1 TPRGap|Macro F1 TPRGap|Macro F1 TPRGap|
|A|88.6(0.7) 0.063 89.0(0.7) 0.065 93.3(1.1) 0.041 89.3(1.2) 0.076 89.7(1.9) 0.096 87.3(3.4) 0.126 94.2(1.0) 0.160 90.1(1.5) 0.102 83.8(5.0) 0.190 83.2(3.4) 0.333 81.0(4.5) 0.350 87.8(2.5) 0.308|89.3(1.1) 0.048 88.3(1.4) 0.079 93.7(1.2) 0.036 89.1(1.1) 0.085 88.9(1.7) 0.117 88.0(3.3) 0.128 93.7(1.0) 0.053 90.1(1.6) 0.099 81.6(5.6) 0.198 83.0(5.8) 0.283 78.0(6.1) 0.410 88.6(1.2) 0.296|84.3(1.7) 0.050 86.9(0.8) 0.057 89.1(2.2) 0.063 85.5(2.0) 0.146 86.1(1.8) 0.134 80.9(2.5) 0.202 88.0(1.3) 0.108 86.4(1.9) 0.125 79.1(3.6) 0.290 79.8(4.9) 0.350 76.4(4.4) 0.447 85.3(0.7) 0.383|71.8(2.5) 0.187 72.1(1.5) 0.257 79.3(3.1) 0.111 76.4(2.1) 0.213 79.0(1.7) 0.215 69.1(3.4) 0.421 82.0(1.0) 0.238 70.9(2.0) 0.404 67.0(5.6) 0.539 68.1(3.8) 0.610 50.5(5.0) 0.944 78.7(0.3) 0.601|71.4(2.5) 0.228 72.9(1.5) 0.209 80.4(2.1) 0.117 75.6(3.6) 0.223 78.6(2.0) 0.245 68.2(2.8) 0.471 80.4(1.4) 0.320 71.9(1.7) 0.399 63.0(6.8) 0.619 63.1(6.4) 0.733 53.3(4.7) 0.914 78.2(0.7) 0.562|67.0(2.4) 0.370 68.6(1.8) 0.422 75.7(2.8) 0.221 73.3(3.0) 0.271 72.6(4.0) 0.257 59.3(4.1) 0.698 72.6(1.9) 0.526 64.5(2.0) 0.615 54.9(5.1) 0.731 59.8(4.6) 0.809 54.3(5.7) 0.888 78.9(0.4) 0.561|64.9(2.4) 0.417 67.6(1.4) 0.247 75.0(1.5) 0.171 71.5(1.8) 0.302 71.1(1.7) 0.472 63.1(5.0) 0.582 74.0(1.4) 0.476 64.0(1.9) 0.660 56.7(5.2) 0.665 59.2(3.5) 0.803 53.4(5.3) 0.898 72.0(0.3) 0.698|63.2(3.2) 0.375 69.4(2.7) 0.250 68.9(5.9) 0.208 72.8(3.4) 0.296 71.7(3.7) 0.385 65.8(4.2) 0.454 74.0(2.8) 0.372 63.9(4.4) 0.633 56.4(5.3) 0.598 58.4(10.5) 0.763 55.7(11.2) 0.833 73.6(0.7) 0.668|64.3(3.1) 0.478 65.9(2.8) 0.498 76.9(2.1) 0.166 72.7(3.2) 0.330 73.3(3.4) 0.263 58.8(2.2) 0.698 75.4(1.3) 0.454 60.8(1.5) 0.654 55.2(6.4) 0.800 56.5(4.4) 0.875 46.4(0.1) 0.998 60.9(0.5) 0.866|
|B||||||||||
|C||||||||||
|D||||||||||
|E||||||||||
|F||||||||||
|G||||||||||
|H||||||||||
|I||||||||||
|J||||||||||
|K||||||||||
|L||||||||||
|MÃ©dia:|0.159|0.153|0.196|0.395|0.420|0.531|0.533|0.486|0.590|

**base de dados e cÃ©lulas em verde sÃ£o estatisticamente equivalentes Ã  classificaÃ§Ã£o de maior valor numÃ©rico.**

### **5 ANÃLISE DOS RESULTADOS** **5.1 PP1: ComparaÃ§Ã£o entre mÃ©todos de CAT**

Para responder a **PP1** ( *Como algoritmos estado da arte recentes,*
*baseados em Transformers, sÃ£o afetados pelo desbalanceamento de*
*classes em tarefas de anÃ¡lise de sentimentos? HÃ¡ espaÃ§o para melho-*
*rias?* ), comparamos os classificadores tradicionais **KNN**, **RF**, **RL**,
**SVM**, **XGB** e **LGBM** com os baseados em *Transformers* **RoBERTa**,
**BART** e **BERT** .

A Tabela 2 apresenta os resultados de MacroF1 e TPRGap para
estes classificadores. Como primeira anÃ¡lise, podemos destacar a
superioridade, em termos de *efetividade*, dos classificadores baseados em *Transformers* quando comparados aos classificadores tradicionais â€“ estes foram inferiores (estatisticamente) aos *Transformers*
em todas as 12 bases de dados consideradas, resultado condizente
com a literatura [ 7 ]. JÃ¡ dentre os classificadores baseados em *Trans-*
*formers*, o RoBERTa e o BART se destacam, ambos com resultados de
classificaÃ§Ã£o estatisticamente equivalentes em todas bases. O BERT,
por sua vez, Ã© estatisticamente equivalente ao RoBERTa e ao BART
em apenas 4 das 12 bases de dados. Por fim, quando analisamos
os valores numÃ©ricos absolutos de cada classificador, o modelo
RoBERTa produz os maiores valores de MacroF1 em 8 coleÃ§Ãµes
enquanto o BART o faz em 4 delas, reforÃ§ando a ideia da literatura

[ 8 ] de que o RoBERTa produz resultados condizentes com o estado
da arte atual de anÃ¡lise de sentimentos. Por isso, nas anÃ¡lises das
prÃ³ximas seÃ§Ãµes, passaremos a utilizar apenas o **RoBERTa** .
Focando agora no viÃ©s (TPRGap mÃ©dio) das abordagens (quanto
menor TPRGap, menor viÃ©s), observamos que os *Transformers* apresentam menor viÃ©s quando comparados aos mÃ©todos de CAT
tradicionais. Para os classificadores tradicionais, o mÃ©todo que
obteve os melhores valores foi o SVM com um TPRGap mÃ©dio
de 0.395, o que Ã© mais que o dobro do TPRGap mÃ©dio dos mÃ©todos
baseados em *Transformers* que conseguiram 0.159 (RoBERTa), 0.153
(BART) e 0.196 (BERT). Esse resultado Ã© muito interessante e atÃ©
onde sabemos nÃ£o foi reportado na literatura - *a boa capacidade*
*dos Transformers de lidar com desbalanceamento de dados* .
Apesar disso, os *Transformers* ainda apresentam resultados de
TPRGap alto em bases de dados que tÃªm um desbalanceamento
elevado, como Ã© o caso das bases J, K e L, com RD igual a 5.32, 6.60
e 39.71, respectivamente. Isso nos mostra que ainda hÃ¡ espaÃ§o para
melhorias, isto Ã©, espaÃ§o para usar tÃ©cnicas capazes de reduzir o
viÃ©s dos modelos *Transformers* .


Portanto, os classificadores baseados em *Transformers* conseguem
gerar modelos que, alÃ©m da efetividade estado da arte, apresentam
um viÃ©s consideravelmente menor quando comparados aos classificadores tradicionais. AlÃ©m disso, observamos que, mesmo para
os *Transformers*, ainda hÃ¡ espaÃ§o considerÃ¡vel de melhoria. Esse
espaÃ§o Ã© explorado a seguir.
### **5.2 PP2: Efetividade e ViÃ©s de CAT com** **undersampling**

Na Tabela 3, apresentamos os resultados de efetividade obtidos por
meio da aplicaÃ§Ã£o dos mÃ©todos de US juntamente com o classificador RoBERTa. A coluna â€œNoUnderâ€ apresenta o resultado sem o
*undersampling* do conjunto de treinamento. Um ponto importante
Ã© que, para todos os mÃ©todos que permitem hiperparametrizaÃ§Ã£o
no que tange a quantidade de instÃ¢ncias a serem removidas (UBR,
E2SC, E2SC_RL, NM1, NM2, IHT e CC_NN), limitamos a remoÃ§Ã£o
de no mÃ¡ximo 50% da base de dados, pois trabalhos recentes relacionados Ã  seleÃ§Ã£o de instÃ¢ncias [ 6 ] apontam que esse Ã© o limite
empÃ­rico de reduÃ§Ã£o onde ainda Ã© possÃ­vel nÃ£o ocorrer perdas na
efetividade. Os outros mÃ©todos nÃ£o foram modificados, seguindo
a polÃ­tica de remoÃ§Ã£o prÃ³pria.
Podemos observar que os mÃ©todos UBR, NM1, E2SC_RL, NM2,
E2SC, TL e OSS conseguem empate estatÃ­stico com a classificaÃ§Ã£o
sem *undersampling* (i.e., com o treino completo desbalanceado) em
todas as coleÃ§Ãµes analisadas. Isso demonstra que todas as tÃ©cnicas
listadas acima tem a capacidade de balancear a base sem causar
perdas de efetividade. Os demais mÃ©todos nÃ£o obtiveram bons resultados em relaÃ§Ã£o aos anteriores, perdendo em 4 (IHT), 3 (OBU,
SBC, RENN e ALLKNN), 2 (NM3) ou em 1 (NCR, ENN) base(s),
respectivamente. Os mÃ©todos CNN e CC_NN sÃ£o estatisticamente
equivalentes ao US em 11 de 12 bases de dados, porÃ©m, no maior
conjunto de dados (L), ambos tiveram um tempo de *undersampling*
que ultrapassou o tempo de treinamento do modelo de classificaÃ§Ã£o
sem o *undersampling*, sendo, portanto, desconsiderados para essa
anÃ¡lise devido a sua impraticabilidade.
Na Tabela 4 apresentamos os resultados para a mÃ©trica TPRGap,
a qual mede o viÃ©s dos modelos. A coluna â€œNoUnderâ€ apresenta o
resultado sem o *undersampling*, enquanto que as demais apresentam o TPRGap dos modelos com *undersampling* . As cores do fundo
das cÃ©lulas representam o quanto os modelos conseguiram reduzir
o viÃ©s do modelo comparados ao â€œNoUnderâ€. Ou seja, quanto maior
o tom de verde, maior a reduÃ§Ã£o do viÃ©s, e quanto mais vermelho,


148


-----

WebMediaâ€™2024, Juiz de Fora, Brazil Guilherme Fonseca, Gabriel Prenassi, Washington Cunha, Marcos AndrÃ© GonÃ§alves, & Leonardo Rocha

|dataset|NoUnder|UBR|NM1|E2SC_RL|NM2|E2SC|NM3|IHT|OBU|SBC|NCR|TL|OSS|RENN|ALLKNN|ENN|CNN|CC_NN|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|A|88.6(0.7) 89.0(0.7) 93.3(1.1) 89.3(1.2) 89.7(1.9) 87.3(3.4) 94.2(1.0) 90.1(1.5) 83.8(5.0) 83.2(3.4) 81.0(4.5) 87.8(2.5)|88.6(0.8) 88.9(0.8) 88.8(1.1) 89.0(0.8) 88.6(1.2) 88.5(1.0) 87.7(1.2) 85.1(1.4) 87.6(1.5) 87.2(2.0) 89.2(1.2) 88.3(0.6) 85.6(0.9) 87.2(2.1) 85.6(0.9) 88.2(1.5) 88.7(1.4) 88.7(1.1) 88.3(1.2) 89.1(1.1) 88.2(0.7) 88.6(1.4) 51.3(13.5) 87.8(1.5) 85.6(1.4) 87.9(1.2) 89.4(1.4) 88.7(0.9) 88.7(0.9) 83.1(8.9) 70.2(5.1) 83.4(9.0) 88.1(2.0) 90.0(1.2) 94.3(1.4) 94.2(1.5) 93.4(1.3) 94.1(1.1) 93.8(1.6) 93.9(1.4) 92.0(1.2) 92.3(1.6) 89.3(3.3) 92.4(1.4) 93.4(1.7) 94.3(1.5) 92.5(1.7) 91.7(2.0) 92.5(1.7) 93.7(1.1) 94.5(1.4) 87.6(1.5) 88.0(1.5) 88.7(1.7) 86.3(1.5) 88.1(1.7) 87.7(2.0) 84.3(3.2) 80.7(1.6) 87.7(1.2) 86.7(1.5) 88.4(1.5) 89.1(1.4) 83.4(2.1) 83.6(3.4) 83.4(2.1) 88.2(1.0) 81.7(13.8) 87.9(1.6) 88.4(1.8) 89.4(1.7) 89.3(1.9) 89.1(1.9) 89.0(1.7) 82.3(1.4) 88.2(2.3) 79.2(4.2) 68.7(7.2) 89.9(1.6) 89.9(1.6) 55.2(3.5) 58.6(3.5) 55.2(3.5) 89.6(1.5) 89.3(1.6) 82.3(3.5) 83.1(4.4) 85.4(3.5) 86.7(3.7) 88.6(3.6) 86.3(2.9) 80.6(2.2) 77.1(5.1) 86.9(3.0) 87.4(2.8) 88.4(4.0) 88.2(3.8) 81.6(3.1) 84.6(5.2) 87.7(3.6) 86.7(3.2) 84.1(3.2) 92.7(0.9) 92.6(1.1) 93.1(1.2) 92.5(1.2) 92.6(1.1) 92.9(1.3) 87.9(1.1) 86.7(2.4) 92.0(0.9) 93.2(1.0) 93.4(1.4) 93.8(1.1) 91.5(1.0) 93.1(0.9) 92.9(0.8) 93.0(1.0) 93.0(1.0) 88.6(1.6) 89.7(2.1) 88.5(1.5) 89.2(1.8) 89.3(1.8) 88.9(1.6) 83.0(2.0) 88.3(1.7) 88.1(0.9) 90.1(1.5) 90.3(1.1) 90.6(1.6) 86.8(1.9) 88.7(1.8) 89.2(1.3) 89.8(1.8) 88.8(1.5) 82.9(4.5) 80.5(4.3) 80.6(4.7) 81.3(4.1) 81.3(4.7) 81.0(3.9) 74.1(4.5) 77.6(3.3) 81.0(4.6) 84.0(4.9) 87.2(4.7) 85.4(3.7) 75.8(4.4) 77.3(5.5) 81.2(5.3) 83.0(5.0) 82.4(4.6) 80.1(4.2) 81.0(4.7) 81.5(5.2) 80.8(5.5) 82.9(5.0) 79.4(5.3) 74.5(3.7) 81.8(6.0) 60.2(2.9) 84.5(4.6) 83.2(4.8) 84.5(4.6) 80.7(3.9) 82.4(4.1) 84.1(3.3) 81.5(3.6) 79.9(9.5) 79.3(3.1) 78.0(4.1) 78.7(4.2) 75.0(5.0) 79.2(4.7) 74.0(3.2) 73.3(4.7) 71.7(4.4) 71.0(4.5) 79.8(5.1) 78.7(4.6) 77.2(5.0) 79.4(5.0) 77.4(6.1) 77.8(5.9) 77.8(4.3) 76.7(3.7) 81.9(4.8) 87.1(1.3) 88.7(0.3) 85.1(3.5) 88.7(0.3) 51.0(1.7) 60.3(1.5) 77.3(9.1) 30.9(1.7) 80.1(21.4) 80.0(21.4) 72.7(26.5) 69.2(3.5) 67.9(2.6) 79.8(21.2) - -|||||||||||||||||
|B|||||||||||||||||||
|C|||||||||||||||||||
|D|||||||||||||||||||
|E|||||||||||||||||||
|F|||||||||||||||||||
|G|||||||||||||||||||
|H|||||||||||||||||||
|I|||||||||||||||||||
|J|||||||||||||||||||
|K|||||||||||||||||||
|L|||||||||||||||||||



**Tabela 3: Macro-F1 do RoBERTa utilizando as abordagens de** *undersampling* **. CÃ©lulas em negrito sÃ£o os maiores valores numÃ©ricos**
**para uma base de dados. CÃ©lulas em verde representam resultados que sÃ£o estatisticamente equivalentes Ã  classificaÃ§Ã£o sem**
*undersampling* **(NoUnder). CÃ©lulas com â€œ-â€ representam mÃ©todos que resultaram em um tempo superior ao tempo de classificaÃ§Ã£o**
**da mesma base sem o** *undersampling* **e, portanto, desconsiderado.**

**Tabela 4: TPRGap dos modelos gerados pelo classificador RoBERTa em conjunto com as abordagens de** *undersampling* **utilizando**

|dataset|NoUnder|UBR|NM1|E2SC_RL|NM2|E2SC|NM3|IHT|OBU|SBC|NCR|TL|OSS|RENN|ALLKNN|ENN|CNN|CC_NN|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|A|0.063 0.065 0.041 0.076|0.010 0.004 0.002 0.005 0.003 0.011 0.072 0.114 0.039 0.077 0.035 0.036 0.141 0.098 0.141 0.047 0.011 0.043 0.026 0.034 0.013 0.033 0.692 0.075 0.100 0.012 0.048 0.060 0.060 0.188 0.445 0.166 0.027 0.023 0.002 0.003 0.000 0.018 0.007 0.022 0.059 0.019 0.149 0.038 0.029 0.025 0.061 0.062 0.061 0.002 0.011 0.005 0.043 0.019 0.019 0.006 0.020 0.107 0.097 0.013 0.032 0.052 0.042 0.143 0.108 0.143 0.006 0.070|||||||||||||||||
|B|||||||||||||||||||
|C|||||||||||||||||||
|D|||||||||||||||||||
|MÃ©dia|0.061|0.015 0.019 0.014 0.014 0.012 0.186 0.078 0.083 0.053 0.049 0.044 0.041 0.133 0.178 0.128 0.021 0.029|||||||||||||||||
|E|0.096 0.126 0.160 0.102 0.190|0.037 0.012 0.001 0.010 0.031 0.026 0.197 0.023 0.245 0.403 0.093 0.090 0.634 0.593 0.634 0.032 0.024 0.006 0.047 0.029 0.054 0.025 0.036 0.132 0.144 0.024 0.043 0.108 0.134 0.111 0.034 0.010 0.000 0.011 0.002 0.003 0.006 0.001 0.001 0.012 0.122 0.094 0.017 0.018 0.063 0.062 0.037 0.007 0.004 0.012 0.012 0.030 0.000 0.006 0.021 0.020 0.001 0.158 0.007 0.035 0.028 0.085 0.077 0.072 0.021 0.007 0.016 0.024 0.037 0.027 0.040 0.036 0.006 0.063 0.212 0.066 0.029 0.018 0.118 0.131 0.158 0.136 0.046 0.006 0.037|||||||||||||||||
|F|||||||||||||||||||
|G|||||||||||||||||||
|H|||||||||||||||||||
|I|||||||||||||||||||
|MÃ©dia|0.135|0.023 0.018 0.017 0.025 0.017 0.027 0.164 0.067 0.070 0.102 0.093 0.099 0.202 0.158 0.140 0.013 0.022|||||||||||||||||
|J|0.333 0.350|0.148 0.176 0.222 0.193 0.221 0.111 0.085 0.264 0.352 0.256 0.336 0.304 0.216 0.248 0.262 0.112 0.247 0.182 0.209 0.215 0.210 0.226 0.064 0.059 0.173 0.047 0.237 0.361 0.400 0.287 0.324 0.324 0.193 0.329|||||||||||||||||
|K|||||||||||||||||||
|MÃ©dia|0.342|0.165 0.192 0.218 0.202 0.224 0.087 0.072 0.219 0.199 0.247 0.349 0.352 0.251 0.286 0.293 0.153 0.288|||||||||||||||||
|L|0.308|0.182 0.207 0.214 0.208 0.216 0.198 0.067 0.245 0.619 0.434 0.443 0.579 0.045 0.042 0.403 - -|||||||||||||||||
|MÃ©dia Total|0.159|0.057 0.063 0.066 0.066 0.066 0.105 0.112 0.112 0.132 0.136 0.149 0.162 0.174 0.177 0.183 - -|||||||||||||||||

**o classificador RoBERTa. Quanto mais verde a cÃ©lula, maior a reduÃ§Ã£o do viÃ©s. Quanto mais vermelho, maior o aumento do viÃ©s.**


maior o agravamento do viÃ©s. Para auxiliar essa anÃ¡lise, dividimos
nossas bases em 4 grupos com relaÃ§Ã£o a seu grau de desbalanceamento (RD). No primeiro grupo sÃ£o as bases de dados que tÃªm um
RD atÃ© 2 (bases A, B, C, D), o segundo contÃ©m as bases com RD
maiores que 2 e menores que 5 (bases E, F, G, H e I), o terceiro aquelas com RD maior que 5 e menor que 10 (bases J e K). Por fim, no
Ãºltimo grupo, temos apenas a base de dados L, com um RD de 39.71.
Em relaÃ§Ã£o ao viÃ©s mÃ©dio total calculado, os mÃ©todos que conseguiram a maior reduÃ§Ã£o de viÃ©s dos modelos em todas as 12
coleÃ§Ãµes foram UBR (viÃ©s total mÃ©dio de 0.057), NM1 (0.063), E2SC_RL
(0.066), NM2 (0.066) e E2SC (0.066), com uma reduÃ§Ã£o de quase 3
vezes comparada ao NoUnder (0.159).
Os mÃ©todos RENN, ALLKNN, ENN, que jÃ¡ estÃ£o entre os piores
em termos de efetividade, tambÃ©m desempenham mal em relaÃ§Ã£o
ao enviesamento do modelo, aumentando o viÃ©s mÃ©dio. Os mÃ©todos TL e OSS, apesar de apresentarem bons resultados em termos
de efetividade, demonstram um baixo desempenho em relaÃ§Ã£o ao
enviesamento, piorando o modelo em alguns casos (em 3 datasets
cada) e tendo um TPRGap mÃ©dio total prÃ³ximo ao NoUnder â€“ 0.149
(TL) e 0.162 (OSS).
Por fim, observamos tambÃ©m que o mÃ©todo UBR â€“ que obteve os
melhores resultados quanto a mÃ©dia total de TRPGap â€“ se mostra
bastante eficaz individualmente por base, principalmente naquelas
mais desbalanceadas. Por exemplo, nas bases do grupo 3 (bases K


e J) e 4 (L), o UBR reduziu o viÃ©s do modelo NoUnder em cerca de
duas vezes, estando sempre muito prÃ³ximo do menor viÃ©s geral
alcanÃ§ado por qualquer mÃ©todo para essas bases. ObservaÃ§Ã£o similar Ã© vÃ¡lida para os outros dois grupos: UBR sempre aparece entre
os melhores resultados. O E2SC tambÃ©m Ã© bastante competitivo,
apresentando os melhores resultados mÃ©dios para os grupos 1 e 2
e estando, tambÃ©m, entre os melhores nos demais grupos.
Sumarizando, conseguimos, com as anÃ¡lises reportadas acima,
responder positivamente Ã  **PP2** ( *MÃ©todos de undersampling, apli-*
*cados juntamente com classificadores baseados em Transformers, sÃ£o*
*capazes de reduzir o viÃ©s dos modelos de classificaÃ§Ã£o? Qual o impacto*
*dessa combinaÃ§Ã£o na efetividade do modelo?* ), pois os mÃ©todos UBR,
NM1, E2SC_RL, NM2 e E2SC sÃ£o capazes de significativamente reduzir o viÃ©s do modelo, sem perda de efetividade em todas as bases.
### **5.3** **PP3: EficiÃªncia de CAT com undersampling**

Analisamos aqui os mÃ©todos de US em relaÃ§Ã£o Ã  sua eficiÃªncia,
buscando verificar qual o impacto dessa nova etapa de prÃ©-processamento dos dados no tempo total e na emissÃ£o total de *ğ¶ğ‘‚* 2 proveniente do treinamento dos modelos. A Tabela 5 apresenta o *speedup*
produzido pelos mÃ©todos de US. Conforme mencionamos na SeÃ§Ã£o
4.3, o *speedup* Ã© calculado pela razÃ£o entre o tempo total gasto
na construÃ§Ã£o do modelo, mais o tempo da classificaÃ§Ã£o, usando
alguma abordagem de *undersampling* pelo tempo total gasto na
execuÃ§Ã£o (modelo e classificaÃ§Ã£o) sem a fase de *undersampling* .


149


-----

EstratÃ©gias de Undersampling para ReduÃ§Ã£o de ViÃ©s em ClassificaÃ§Ã£o de Texto Baseada em Transformers WebMediaâ€™2024, Juiz de Fora, Brazil

**Tabela 5: Resultados de Speedup no custo total (tempo) para geraÃ§Ã£o dos modelos utilizando o classificador RoBERTa em**

|dataset|UBR|NM1|E2SC_RL|NM2|E2SC|NM3|IHT|OBU|SBC|NCR|TL|OSS|RENN|ALLKNN|ENN|CNN|CC_NN|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|A|1.209 1.076 1.094 1.135 1.178 1.096 1.181 1.374 1.216 1.210 0.929 0.961 1.376 1.230 1.415 1.243 1.193 1.203 1.163 1.273 1.114 1.099 1.588 1.230 1.342 1.364 0.988 0.962 0.990 1.513 1.452 1.476 1.005 1.186 1.315 1.237 1.400 1.096 1.253 1.247 1.115 1.214 1.638 1.223 0.873 0.885 1.039 1.120 1.070 1.361 1.202 1.558 1.469 1.712 1.450 1.456 1.493 1.402 1.282 1.637 1.516 1.185 1.150 1.854 1.447 1.966 1.519 1.500 1.450 1.312 1.569 1.312 1.361 1.400 1.182 1.381 1.769 1.607 0.937 0.948 1.611 1.641 1.663 1.176 1.467 1.534 1.299 1.371 1.450 1.666 1.544 1.627 1.491 1.507 1.413 1.068 1.065 1.416 1.632 1.504 1.601 1.529 1.527 1.530 1.518 1.374 1.354 1.414 1.298 1.329 1.444 1.122 0.946 0.995 1.220 1.159 1.270 1.310 1.521 1.749 1.659 1.950 1.619 1.788 1.757 1.668 1.607 1.728 1.319 1.055 1.067 1.771 1.587 1.395 1.494 1.867 1.657 1.923 1.635 1.601 1.609 1.519 1.634 1.331 1.564 1.401 1.034 1.014 1.516 1.751 1.537 1.510 1.612 1.487 1.730 1.617 1.523 1.876 2.128 1.535 1.302 2.861 0.877 1.003 0.800 0.998 0.977 0.990 2.283 1.608 1.695 1.691 1.802 1.621 1.741 3.054 1.602 1.411 3.433 1.487 1.107 0.972 1.220 1.341 1.335 2.377 1.442 2.662 2.709 2.903 2.867 3.039 39.486 2.103 1.777 12.498 1.038 0.892 1.318 0.946 1.713 1.230 - -|||||||||||||||||
|B||||||||||||||||||
|C||||||||||||||||||
|D||||||||||||||||||
|E||||||||||||||||||
|F||||||||||||||||||
|G||||||||||||||||||
|H||||||||||||||||||
|I||||||||||||||||||
|J||||||||||||||||||
|K||||||||||||||||||
|L||||||||||||||||||
|MÃ©dia|1.587 1.566 1.654 1.513 1.618 4.811 1.465 1.404 2.722 1.267 0.999 1.014 1.373 1.421 1.404 - -|||||||||||||||||

**conjunto com as abordagens de** *undersampling* **. Quanto mais verde a cÃ©lula, maior a reduÃ§Ã£o no tempo total de treinamento**
**em relaÃ§Ã£o a abordagem sem** *undersampling* **. Quanto mais vermelho, maior o tempo.**

**Tabela 6: EmissÃ£o de Carbono (** *ğ¶ğ‘‚* 2 **) para geraÃ§Ã£o dos modelos utilizando o classificador RoBERTa em conjunto com as**

|dataset|NoUnder|UBR|NM1|E2SC_RL|NM2|E2SC|NM3|IHT|OBU|SBC|NCR|TL|OSS|RENN|ALLKNN|ENN|CNN|CC_NN|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|A|55.537 83.539 34.265 93.391 55.470 36.458 171.805 78.329 22.538 21.994 23.693 2,552.335|45.884 51.580 50.740 48.897 47.114 50.650 46.966 40.362 43.922 45.838 59.770 57.725 40.322 45.119 39.218 40.892 44.769 69.377 71.793 65.550 74.933 75.923 52.539 67.865 62.154 59.487 84.470 86.764 84.280 55.137 57.481 56.526 66.378 66.234 26.042 27.693 24.463 31.241 27.324 27.460 30.724 28.192 20.567 27.991 39.227 38.706 32.962 30.580 32.013 24.429 27.903 59.893 63.529 54.531 64.380 64.097 62.535 66.566 72.778 56.550 61.574 78.756 81.160 50.329 64.525 47.462 57.948 61.228 38.202 42.243 35.322 42.254 40.692 39.576 46.877 40.118 30.730 34.474 59.146 58.448 34.394 33.765 33.315 41.039 35.803 23.745 28.052 26.563 25.116 21.848 23.591 22.375 24.414 23.945 25.780 34.099 34.192 25.725 22.307 24.220 22.403 23.493 112.413 112.145 113.060 124.901 126.778 121.423 132.204 129.121 116.158 152.980 181.434 172.539 140.629 148.092 135.182 117.260 108.297 44.724 47.164 40.116 48.316 43.737 44.516 46.895 48.635 41.999 59.281 74.156 73.297 44.120 49.254 56.096 43.587 39.587 13.581 11.704 13.769 14.060 13.986 14.816 13.768 16.906 14.135 16.061 21.784 22.209 14.847 12.854 14.647 14.468 13.676 14.773 12.700 13.592 14.429 11.708 10.321 14.307 16.869 7.486 25.071 21.912 27.473 22.023 22.498 22.193 9.291 13.296 13.934 13.980 13.114 14.579 13.568 7.724 14.747 16.740 6.504 15.897 21.369 24.348 19.383 17.626 17.710 9.510 15.948 942.877 938.264 876.957 879.055 834.978 60.623 1,209.117 1,414.486 117.465 2,324.505 2,760.191 1,831.865 1,210.973 1,245.247 1,943.847 - -|||||||||||||||||
|B|||||||||||||||||||
|C|||||||||||||||||||
|D|||||||||||||||||||
|E|||||||||||||||||||
|F|||||||||||||||||||
|G|||||||||||||||||||
|H|||||||||||||||||||
|I|||||||||||||||||||
|J|||||||||||||||||||
|K|||||||||||||||||||
|L|||||||||||||||||||

**abordagens de** *undersampling* **. Quanto mais verde a cÃ©lula, maior a reduÃ§Ã£o da emissÃ£o em relaÃ§Ã£o a abordagem sem** *undersampling* **.**


Podemos observar que, com exceÃ§Ã£o do TL, todos os mÃ©todos,
em mÃ©dia, conseguiram manter ou reduzir o tempo em comparaÃ§Ã£o
com o RoBERTa aplicado aos dados originais (sem *undersampling* ).
Os mÃ©todos UBR, NM1, E2SC_RL, NM2 e E2SC, que nas anÃ¡lises
anteriores se mostraram superiores quantos aos critÃ©rios de efetividade e reduÃ§Ã£o do enviesamento, conseguem tambÃ©m um bom
desempenho no critÃ©rio de eficiÃªncia. Os *speedups* alcanÃ§ados, respectivamente, de 1.587, 1.566, 1.654, 1.513 e 1.618 sÃ£o muito bons.
Juntamente com o NM3 (4.811) e SBC (2.722), esses sÃ£o os mÃ©todos
com maior ganho de *speedup* . Contudo, vale lembrar que o NM3 e o
SBC geram perdas de efetividade para algumas coleÃ§Ãµes (Tabela 3)
ao produzir os respectivos ganhos de *speedup* .
Por fim, na Tabela 6, apresentamos os valores de emissÃ£o de *ğ¶ğ‘‚* 2
(em g) produzido pelos mÃ©todos de *undersampling* . Assim como
causaram perda de eficiÃªncia, os mÃ©todos TL e OSS tambÃ©m produzem um aumento de emissÃ£o de *ğ¶ğ‘‚* 2 para algumas bases. JÃ¡
todos os demais mÃ©todos, em menor ou maior grau, geram alguma
reduÃ§Ã£o de emissÃ£o. Para as bases de dados de A a K, a emissÃ£o de
carbono Ã© muito pequena quando comparada a base L, que Ã© ordens
de magnitude maior que as demais. Por essa mesma razÃ£o, o tempo
de processamento de L Ã© muito maior, mesmo ela sendo executada
em uma mÃ¡quina de maior poder computacional. Por isso, nossa
anÃ¡lise nesse critÃ©rio focarÃ¡ nessa base. Ao analisar a emissÃ£o dos

mÃ©todos de *undersampling* para a base de dados L, observamos que
os mÃ©todos UBR (emissÃ£o 942.877 g *ğ¶ğ‘‚* 2 ), NM1 (938.264 g *ğ¶ğ‘‚* 2 ),
E2SC_RL (876.957 g *ğ¶ğ‘‚* 2 ), NM2 (879.055 g *ğ¶ğ‘‚* 2 ) e E2SC (834.978


g *ğ¶ğ‘‚* 2 ), os mesmos mÃ©todos destacados nas anÃ¡lises anteriores,
tambÃ©m conseguem reduzir mais que pela metade a emissÃ£o em
comparaÃ§Ã£o com o NoUnder (2,552.335 g *ğ¶ğ‘‚* 2 ). Traduzindo esses
nÃºmeros para exemplos ilustrativos, podemos dizer que a emissÃ£o
antes era equivalente a 2.73 meses de uma Ã¡rvore sequestrando carbono ou a emissÃ£o de 14.40 km percorridos por um carro [ 21 ]. JÃ¡ a
emissÃ£o apÃ³s o *undersampling*, considerando o UBR como exemplo,
seria equivalente a 1.03 meses de sequestro de carbono feito por
uma Ã¡rvore ou a emissÃ£o de de 5.41 Km percorridos por um carro
de passageiros. Se individualmente essa parece ser uma reduÃ§Ã£o pequena, se considerarmos milhÃµes de mÃ¡quinas ao redor do mundo
rodando processos similares todos os dias, dezenas ou centenas de
vezes, essa reduÃ§Ã£o pode passar a ser considerÃ¡vel.
Voltando Ã  nossa **PP3** ( *Qual o impacto da aplicaÃ§Ã£o dessa etapa*
*adicional de prÃ©-processamento (undersampling) em termos de efi-*
*ciÃªncia? E em termos da emissÃ£o de carbono?* ), temos que os mÃ©todos
UBR, NM1, E2SC_RL, NM2 e E2SC conseguem reduzir o enviesamento do modelo, mantendo a efetividade e reduzindo o tempo de
treinamento dos modelos e, consequentemente, as emissÃµes de *ğ¶ğ‘‚* 2 .
### **5.4 DiscussÃ£o Final**

Dadas as anÃ¡lises apresentadas nesta seÃ§Ã£o, onde os mÃ©todos de
*undersampling* foram avaliados quanto Ã  sua efetividade, sua capacidade reduzir o enviesamento dos modelos e sua eficiÃªncia, podemos
concluir que os melhores mÃ©todos de *undersampling* analisados
foram UBR, NM1, E2SC_RL, NM2 e E2SC. Todos eles conseguiram
reduzir o enviesamento do modelo para a classe majoritÃ¡ria sem


150


-----

WebMediaâ€™2024, Juiz de Fora, Brazil Guilherme Fonseca, Gabriel Prenassi, Washington Cunha, Marcos AndrÃ© GonÃ§alves, & Leonardo Rocha


produzir nenhum tipo de perda de efetividade global (em termos
de MacroF1). Esses mÃ©todos tambÃ©m apresentaram uma reduÃ§Ã£o
no tempo de treinamento do modelo com uma consequente reduÃ§Ã£o na emissÃ£o de *ğ¶ğ‘‚* 2 . Das estratÃ©gias que se destacaram, **duas**
foram originalmente propostas neste trabalho - UBR e E2SC_RL.
Em particular a **UBR** foi aquela que apresentou os resultados mais
consistentes de reduÃ§Ã£o de enviesamento sem perda de efetividade,
com um bom speedup e reduÃ§Ã£o de emissÃ£o de *ğ¶ğ‘‚* 2, sendo nossa
recomendaÃ§Ã£o final para o problema, se tivermos de fazer uma.
### **6 CONCLUSÃ•ES E TRABALHOS FUTUROS**

O impacto do desbalanceamento de classes, relacionado ao viÃ©s de
um classificador para a classe majoritÃ¡ria, em estratÃ©gias do estado
da arte de CAT baseadas em *Transformers*, tem sido pouco discutido
na literatura [ 5 ]. Neste trabalho, apresentamos uma avaliaÃ§Ã£o detalhada de mÃ©todos de *undersampling* (US) aplicados em conjunto com
algoritmos baseados em *Transformers* na tarefa de AnÃ¡lise de Sentimento. Primeiramente, realizamos uma anÃ¡lise comparativa entre
mÃ©todos de classificaÃ§Ã£o baseados em *Transformers* e tradicionais
sob duas perspectivas: efetividade e enviesamento. Essa anÃ¡lise revelou que, alÃ©m de mais efetivos, como conhecidos, os *Transformers*
sÃ£o capazes de lidar de forma mais adequada com o problema do viÃ©s
que os algoritmos tradicionais. Nossos resultados experimentais
tambÃ©m indicaram que ainda existe espaÃ§o para melhoria, principalmente em bases de dados com um desbalanceamento maior.
Baseado em um mapeamento da literatura sobre *undersampling*,
selecionamos e implementamos os 14 mÃ©todos mais utilizados, alÃ©m
de adaptarmos diretamente um mÃ©todo de seleÃ§Ã£o de instÃ¢ncias
para a tarefa de *undersampling* devido a conexÃµes entre as tarefas.
Propomos, tambÃ©m, duas novas estratÃ©gias de US: E2SC_RL e UBR,
totalizando em um conjunto de 17 mÃ©todos a serem comparados.
Uma avaliaÃ§Ã£o experimental vasta, utilizando esses 17 mÃ©todos
e 12 bases de dados revelou que um conjunto de cinco mÃ©todos de
*undersampling* â€“ UBR (nossa proposta), NM1, E2SC_RL (nossa proposta), NM2, E2SC â€“ foram capazes de reduzir o viÃ©s dos modelos
de CAT quando comparados com modelos sem *undersampling* sem
perdas de efetividade (qualidade da classificaÃ§Ã£o). AlÃ©m disso, esses
mesmos mÃ©todos produziram uma reduÃ§Ã£o significativa no tempo
de treino e na emissÃ£o de *ğ¶ğ‘‚* 2 no treinamento dos modelos *Trans-*
*formers* . Entre esses 5 mÃ©todos, o UBR apresentou os resultados
mais consistentes considerando todos os critÃ©rios analisados.

Como trabalhos futuro, visamos estender o presente estudo considerando, tambÃ©m, outros cenÃ¡rios de CAT, como multiclasses
e/ou hierÃ¡rquico, alÃ©m de avaliar outros algoritmos de CAT alÃ©m
do RoBERTa, tais como BERT e BART. Ademais, considerando que
a eficÃ¡cia dos LLMs recentes em comparaÃ§Ã£o com modelos anteriores baseados em *Transformer*, como o RoBERTa, para anÃ¡lise de
sentimentos e propÃ³sitos de CAT ainda nÃ£o estÃ¡ clara [ 10 ], e que,
quando LLMs superam alguns *Transformers* de 1 [a] e 2 [a] geraÃ§Ã£o, os
ganhos sÃ£o tipicamente de apenas alguns pontos percentuais [10],
consideramos incerto se esses ganhos marginais se traduzem em
benefÃ­cios prÃ¡ticos em aplicaÃ§Ãµes do mundo real. Desta forma, em
trabalhos futuros, planejamos realizar uma anÃ¡lise completa sobre
o custo-benefÃ­cio dos LLMs em relaÃ§Ã£o aos *Transformers* de 1 [a] e 2 [a]

geraÃ§Ã£o, de modo a habilitar a aplicaÃ§Ã£o dos mÃ©todos de *undersam-*
*pling* como etapas de prÃ©-processamento de LLMs recentes.

### **AGRADECIMENTOS**

Este trabalho foi financiado por CNPq, CAPES, Fapemig, FAPESP,
CIIA-SaÃºde e AWS.
### **REFERENCES**

[1] Lasse F Wolff Anthony, Benjamin Kanding, and Raghavendra Selvan. 2020. Carbontracker: Tracking and predicting the carbon footprint of training deep learning models. *arXiv preprint arXiv:2007.03051* (2020).

[2] Bernhard E Boser, Isabelle M Guyon, and Vladimir N Vapnik. 1992. A training
algorithm for optimal margin classifiers. In *5th COLT* .

[3] Leo Breiman. 2001. Random forests. *Machine learning* (2001).

[4] Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system.
In *Proceedings of the 22nd acm sigkdd KDD* .

[5] Washington Cunha, SÃ©rgio D. Canuto, Felipe Viegas, Thiago Salles, Christian Gomes, VÃ­tor Mangaravite, Elaine Resende, Thierson Rosa, Marcos AndrÃ©
GonÃ§alves, and Leonardo Rocha. 2020. Extended pre-processing pipeline for text
classification: On the role of meta-feature representations, sparsification and
selective sampling. *IP&M.* (2020).

[6] Washington Cunha, Celso FranÃ§a, Guilherme Fonseca, Leonardo Rocha, and
Marcos AndrÃ© GonÃ§alves. 2023. An Effective, Efficient, and Scalable ConfidenceBased Instance Selection Framework for Transformer-Based Text Classification.
In *the 46th ACM SIGIR* .

[7] Washington Cunha, VÃ­tor Mangaravite, Christian Gomes, SÃ©rgio Canuto, Felipe Viegas, Celso FranÃ§a, Wellington Santos Martins, Jussara M Almeida, et al .
2021. On the cost-effectiveness of neural and non-neural approaches and representations for text classification: A comprehensive comparative study. *IP&M*
(2021).

[8] Washington Cunha, Felipe Viegas, Celso FranÃ§a, Thierson Rosa, Leonardo Rocha,
and Marcos AndrÃ© GonÃ§alves. 2023. A Comparative Survey of Instance Selection Methods applied to NonNeural and Transformer-Based Text Classification.
*Comput. Surveys* (2023).

[9] Paula Czarnowska, Yogarshi Vyas, and Kashif Shah. 2021. Quantifying social
biases in NLP: A generalization and empirical comparison of extrinsic fairness
metrics. *TACL* (2021).

[10] Claudio MV de Andrade, Fabiano M BelÃ©m, Washington Cunha, Celso FranÃ§a,
Felipe Viegas, Leonardo Rocha, and Marcos AndrÃ© GonÃ§alves. 2023. On the class
separability of contextual embeddings representationsâ€“or â€œThe classifier does
not matter when the (text) representation is so good!â€. *IP&M* (2023).

[11] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:
Pre-training of deep bidirectional transformers for language understanding. *arXiv*
*preprint arXiv:1810.04805* (2018).

[12] Georgios Douzas, Maria Lechleitner, and Fernando Bacao. 2022. Improving
the quality of predictive models in small data GSDOT: A new algorithm for
generating synthetic data. *Plos one* (2022).

[13] Vinicius HS Durelli, Rafael S Durelli, Andre T Endo, Elder Cirilo, Washington
Luiz, and Leonardo Rocha. 2018. Please please me: does the presence of test cases
influence mobile app usersâ€™ satisfaction?. In *Proceedings of the XXXII Brazilian*
*Symposium on Software Engineering* .

[14] Xavier Ferrer, Tom van Nuenen, Jose M. Such, Mark CotÃ©, and Natalia Criado.
2021. Bias and Discrimination in AI: A Cross-Disciplinary Perspective. *IEEE*
*Technology and Society Magazine* (2021).

[15] Hui Han, Wen-Yuan Wang, and Bing-Huan Mao. 2005. Borderline-SMOTE: a
new over-sampling method in imbalanced data sets learning. In *International*
*conference on intelligent computing* . Springer.

[16] Xiao Han, Yuqi Liu, and Jimmy Lin. 2021. The simplest thing that can possibly
work:(pseudo-) relevance feedback via text classification. In *Proceedings of the*
*2021 ACM SIGIR ICTIR* .

[17] Peter Hart. 1968. The condensed nearest neighbor rule (corresp.). *IEEE transac-*
*tions on information theory* (1968).

[18] AntÃ´nio JÃºnior, Pablo Cecilio, Felipe Viegas, Washington Cunha, Elisa Albergaria,
and Leonardo Rocha. 2022. Evaluating topic modeling pre-processing pipelines
for portuguese texts. In *WebMedia* .

[19] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma,
Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: A highly efficient gradient boosting
decision tree. *Advances in NeurIPS* (2017).

[20] Miroslav Kubat, Stan Matwin, et al . 1997. Addressing the curse of imbalanced
training sets: one-sided selection. In *Icml* . Citeseer.

[21] LoÃ¯c Lannelongue, Jason Grealey, and Michael Inouye. 2021. Green algorithms:
quantifying the carbon footprint of computation. *Advanced science* (2021).

[22] Jorma Laurikkala. 2001. Improving identification of difficult small classes by
balancing class distribution. In *8th Conference on AIME* .

[23] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman
Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. Bart:
Denoising sequence-to-sequence pre-training for natural language generation,
translation, and comprehension. In *ACL* .


151


-----

EstratÃ©gias de Undersampling para ReduÃ§Ã£o de ViÃ©s em ClassificaÃ§Ã£o de Texto Baseada em Transformers WebMediaâ€™2024, Juiz de Fora, Brazil



[24] Wei-Chao Lin, Chih-Fong Tsai, Ya-Han Hu, and Jing-Shang Jhang. 2017.
Clustering-based undersampling in class-imbalanced data. *Info. Sciences* (2017).

[25] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A
robustly optimized bert pretraining approach. *arXiv preprint arXiv:1907.11692*
(2019).

[26] Hongxia Lu, Louis Ehwerhemuepha, and Cyril Rakovski. 2022. A comparative
study on deep learning models for text classification of unstructured medical
notes with various levels of class imbalance. *BMC medical research methodology*
(2022).

[27] Washington Luiz, Felipe Viegas, Rafael Alencar, Fernando MourÃ£o, Thiago Salles,
DÃ¡rlinton Carvalho, Marcos Andre GonÃ§alves, and Leonardo Rocha. 2018. A
Feature-Oriented Sentiment Rating for Mobile App Reviews. In *the World Wide*
*Web Conference (WWW â€™18)* .

[28] Inderjeet Mani and I Zhang. 2003. kNN approach to unbalanced data distributions:
a case study involving information extraction. In *Proceedings of workshop on*
*learning from imbalanced datasets* . ICML.

[29] Luiz Felipe Mendes, Marcos GonÃ§alves, Washington Cunha, Leonardo Rocha,
Thierson Couto-Rosa, and Wellington Martins. 2020. " Keep it Simple, Lazy"â€“
MetaLazy: A New MetaStrategy for Lazy Text Classification. In *Proceedings of*
*the 29th ACM International CIKM* .

[30] Andrew Ng. 2017. Machine learning yearning. *URL: http://www. mlyearning.*
*org/(96)* (2017).

[31] Albert Orriols-Puig and Ester BernadÃ³-Mansilla. 2009. Evolutionary rule-based
systems for imbalanced data sets. *Soft Computing* (2009).

[32] Andrea Pasin, Washington Cunha, Marcos AndrÃ© GonÃ§alves, and Nicola Ferro.
2024. A Quantum Annealing Instance Selection Approach for Efficient and


Effective Transformer Fine-Tuning. In *ICTIR* .

[33] Alexander Ponomarenko, Nikita Avrelin, Bilegsaikhan Naidan, and Leonid
Boytsov. 2014. Comparative analysis of data structures for approximate nearest
neighbor search. *Data analytics* (2014).

[34] Sivaramakrishnan Rajaraman, Prasanth Ganesan, and Sameer Antani. 2022. Deep
learning model calibration for improving performance in class-imbalanced medical image classification tasks. *PloS one* (2022).

[35] Michael R Smith, Tony Martinez, and Christophe Giraud-Carrier. 2014. An
instance level analysis of data complexity. *Machine learning* (2014).

[36] Ivan Tomek. 1976. An experiment with the edited nearest-neighbor rule. (1976).

[37] Ivan Tomek. 1976. Two Modifications of CNN. *IEEE Transactions on Systems,*
*Man, and Cybernetics* (1976).

[38] Pattaramon Vuttipittayamongkol, Eyad Elyan, Andrei Petrovski, and Chrisina
Jayne. 2018. Overlap-based undersampling for improving imbalanced data classification. In *19th IDEAL* . Springer.

[39] Dennis L Wilson. 1972. Asymptotic properties of nearest neighbor rules using
edited data. *IEEE Transactions on Systems* (1972).

[40] Raymond E Wright. 1995. Logistic regression. (1995).

[41] Show-Jane Yen and Yue-Shi Lee. 2006. Under-sampling approaches for improving
prediction of the minority class in an imbalanced dataset. In *ICIC Kunming, China,*
*August 16â€“19, 2006* . Springer.

[42] Bruna Stella Zanotto, Ana Paula Beck da Silva Etges, Avner Dal Bosco, Eduardo Gabriel Cortes, Renata Ruschel, Washington Luiz, et al . 2021. Stroke
outcome measurements from electronic medical records: cross-sectional study
on the effectiveness of neural and nonneural classifiers. *JMIR Medical Informatics*
(2021).


152


-----

