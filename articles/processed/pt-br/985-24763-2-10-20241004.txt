# **O Impacto de EstratÃ©gias de Embeddings de Grafos na** **Explicabilidade de Sistemas de RecomendaÃ§Ã£o**

## AndrÃ© Levi Zanon
#### andrezanon@usp.br Universidade de SÃ£o Paulo SÃ£o Carlos, SÃ£o Paulo, Brasil
### **ABSTRACT**

## Leonardo Rocha
#### lcrocha@ufsj.edu.br Universidade Federal de SÃ£o JoÃ£o del-Rei SÃ£o JoÃ£o del Rei, Minas Gerais, Brasil

## Marcelo Garcia Manzato
#### mmanzato@icmc.usp.br Universidade de SÃ£o Paulo SÃ£o Carlos, SÃ£o Paulo, Brasil


Explanations in recommender systems are essential in improving
trust, transparency, and persuasion. Recently, using Knowledge
Graphs (KG) to generate explanations gained attention due to the
semantic representation of information in which items and their attributes are represented as nodes, connected by edges, representing
connections among them. Model-agnostic KG explainable algorithms can be based on syntactic approaches or graph embeddings.
The impact of graph embedding strategies in generating meaningful explanations still needs to be studied in the literature. To fill this
gap, in this work, we evaluate the quality of explanations provided
by different graph embeddings and compare them with traditional
syntactic strategies. The quality of explanations was assessed using
three metrics from the literature: diversity, popularity and recency.
Results indicate that the embedding algorithm chosen impacts the
quality of explanations and generates more balanced results regarding popularity and explanation diversity compared to syntactic
approaches.
### **KEYWORDS**

Sistemas de RecomendaÃ§Ã£o, ExplicaÃ§Ãµes, *Embedding* de Grafos
### **1 INTRODUÃ‡ÃƒO**

Sistemas de RecomendaÃ§Ã£o (SsR) sÃ£o algoritmos que oferecem sugestÃµes a usuÃ¡rios nÃ£o apenas com base em seus histÃ³ricos de interaÃ§Ãµes, mas tambÃ©m em interaÃ§Ãµes de outros usuÃ¡rios, metadados
de itens, conhecimento de domÃ­nio e informaÃ§Ãµes contextuais [ 25 ].
Para usufruir de todos essas informaÃ§Ãµes, as arquiteturas de SsR
vÃªm se apresentando cada vez mais complexas e, consequentemente,
pouco transparentes quanto Ã s explicaÃ§Ãµes das recomendaÃ§Ãµes realizadas aos usuÃ¡rios, tornando-se verdadeiras caixas pretas [ 31 ].
No entanto, gerar explicaÃ§Ãµes para recomendaÃ§Ãµes tÃªm recebido
uma significativa atenÃ§Ã£o da literatura [ 3, 22 ], pois podem melhorar
os SsR ao fornecer transparÃªncia, confianÃ§a, eficÃ¡cia, persuasÃ£o, e
satisfaÃ§Ã£o [31].
Atualmente, as estratÃ©gias para geraÃ§Ã£o de explicaÃ§Ãµes para SsR
podem ser categorizadas, basicamente, em duas abordagens: 1)
intrÃ­nsecas ao modelo; e 2) agnÃ³sticas ao modelo, chamadas de
pÃ³s-hoc [ 26, 37 ]. Modelos intrÃ­nsecos buscam gerar explicaÃ§Ãµes
em conjunto com a recomendaÃ§Ã£o em si, apresentando os motivos

In: Proceedings of the Brazilian Symposium on Multimedia and the Web (WebMe
diaâ€™2024). Juiz de Fora, Brazil. 2024.
Â© 2024 SBC â€“ Sociedade Brasileira de ComputaÃ§Ã£o.
ISSN 2966-2753


pelos quais um item interagido estÃ¡ relacionado com o recomendado [ 33 ]. MÃ©todos agnÃ³sticos ou pÃ³s-hoc, por outro lado, utilizam
um algoritmo desassociado da recomendaÃ§Ã£o para relacionar itens
interagidos com itens recomendados e, portanto, nÃ£o dependem do
algoritmo de recomendaÃ§Ã£o [ 22 ]. MÃ©todos agnÃ³sticos, geralmente,
sÃ£o enriquecidos por fontes externas, como Grafos de Conhecimento (GCs), em que nÃ³s representam itens e atributos relacionados
a estes e arestas representam as relaÃ§Ãµes semÃ¢nticas entre os nÃ³s

[5], sendo esse o foco do presente trabalho.
Os atuais algoritmos GC pÃ³s-hoc predominantemente utilizam
abordagens sintÃ¡ticas em que a relevÃ¢ncia dos caminhos que conectam itens interagidos e recomendados Ã© medida por meio do
nÃºmero de links associados. No entanto, esta medida pode nÃ£o
capturar completamente as relaÃ§Ãµes semÃ¢nticas entre os dados. Em
contrapartida, abordagens baseadas em *embedding* de grafos [ 2, 17 ]
podem gerar representaÃ§Ãµes semÃ¢nticas de caminhos entre nÃ³s de
itens recomendados e interagidos ao projetÃ¡-los em um espaÃ§o vetorial. Apesar do potencial impacto que a escolha do algoritmo de
*embedding* de grafo utilizado pode ter na qualidade das explicaÃ§Ãµes
das recomendaÃ§Ãµes realizadas [ 21 ], nÃ£o encontramos na literatura
trabalhos que realizam essa avaliaÃ§Ã£o.
Assim, o objetivo principal desse artigo visa preencher essa lacuna da literatura e comparar o impacto de diferentes algoritmos de
*embedding* de grafos na qualidade de explicaÃ§Ã£o em algoritmos de
pÃ³s-hoc de explicaÃ§Ã£o em sistemas de recomendaÃ§Ã£o, comparandoos tambÃ©m com abordagens sintÃ¡ticas. Portanto, os objetivos especÃ­ficos foram divididos em duas questÃµes de pesquisa. A primeira Ã©:
**QP1: Qual o impacto de diferentes tipos de algoritmos de** ***em-***
***bedding*** **de grafos na qualidade das explicaÃ§Ãµes geradas para**
**SsR?** A fim de responder a essa pergunta de pesquisa, implementamos um algoritmo agnÃ³stico a modelo (pÃ³s-hoc) de explicaÃ§Ã£o
utilizando trÃªs modelos de *embeddings* de grafos: um bilinear e
dois translacionais. Estas representaÃ§Ãµes vetoriais dos nÃ³s e arestas
dos grafos foram geradas por trÃªs diferentes estratÃ©gias consideradas estado-da-arte (i.e. TransE [ 18 ] e RotatE [ 29 ] translacionais
e ComplEx [ 32 ] bilinear). Os *embeddings* obtidos por esses algoritmos foram combinados para gerar representaÃ§Ãµes do usuÃ¡rio e dos
caminhos do grafo que conectam itens interagidos e recomendados, sendo que, o caminho com representaÃ§Ã£o em espaÃ§o latente
mais similar Ã  representaÃ§Ã£o do usuÃ¡rio Ã© escolhido como explicaÃ§Ã£o ao usuÃ¡rio. Nas anÃ¡lises experimentais, consideramos mÃ©tricas
que avaliam a qualidade da explicaÃ§Ã£o medindo a atualidade dos
itens interagidos e a popularidade e diversidade dos atributos que
conectam os itens interagidos ao item recomendado [2].
De forma complementar, comparamos as estratÃ©gias de *embed-*
*dings* de GCs com trÃªs abordagens sintÃ¡ticas (ExpLOD [ 19 ], ExpLOD


231


-----

WebMediaâ€™2024, Juiz de Fora, Brazil AndrÃ© Levi Zanon, Leonardo Rocha, and Marcelo Garcia Manzato


versÃ£o 2 (ExpLOD v2) [ 20 ] e o *Proposed Property-based Explana-*
*tion Model (PEM)* [ 10 ]). O objetivo dessa anÃ¡lise Ã© responder nossa
segunda pergunta de pesquisa: **QP2: As estratÃ©gias baseadas**
**em** ***embeddings*** **de grafos sÃ£o, de fato, capazes de gerar ex-**
**plicaÃ§Ãµes melhores em SsR em comparaÃ§Ã£o Ã s abordagens**
**sintÃ¡ticas?** .

Portanto, as principais contribuiÃ§Ãµes deste trabalho sÃ£o:

  - AnÃ¡lise comparativa entre estratÃ©gias de *embedding* de grafos e algoritmos sintÃ¡ticos na qualidade das explicaÃ§Ãµes geradas em SsR;

  - AnÃ¡lise comparativa do impacto de diferentes estratÃ©gias de
*embedding* de grafos na qualidade das explicaÃ§Ãµes geradas
para SsR;

  - CriaÃ§Ã£o de um arcabouÃ§o completo para avaliaÃ§Ã£o de estratÃ©gias de geraÃ§Ã£o de explicaÃ§Ãµes para SsR baseadas em grafos
de conhecimento.

Focando primeiramente na QP1, nossos resultados deixam claro
que modelos bilineares, capazes de representar relaÃ§Ãµes mais complexas entre nÃ³s e arestas, impactaram positivamente nas mÃ©tricas
de qualidade de explicaÃ§Ã£o. Com relaÃ§Ã£o Ã  QP2, observamos que
enquanto mÃ©todos sintÃ¡ticos priorizam a recÃªncia dos itens e popularidade de atributos escolhidos nas explicaÃ§Ãµes, estratÃ©gias de *embed-*
*dings* conseguem balancear o *trade-off* entre a popularidade e diversidade de atributos de itens nas explicaÃ§Ãµes mostradas aos usuÃ¡rios.
O artigo estÃ¡ estruturado da seguinte forma: A SeÃ§Ã£o 2 revisa
trabalhos relacionados a algoritmos de SsR explicÃ¡veis e baseados
em GCs. A SeÃ§Ã£o 3 detalha o arcabouÃ§o de avaliaÃ§Ã£o focado em
reprodutibilidade, incluindo a configuraÃ§Ã£o experimental, mÃ©tricas,
conjuntos de dados e algoritmos. A SeÃ§Ã£o 4 discute os resultados,
e a SeÃ§Ã£o 5 resume as descobertas.
### **2 TRABALHOS RELACIONADOS**

Uma vez que GC fornecem metadados estruturados sobre itens, eles
tÃªm sido utilizados para gerar recomendaÃ§Ãµes precisas e explicÃ¡veis
em diversas arquiteturas de recomendaÃ§Ã£o. ExplicaÃ§Ãµes em GC sÃ£o
geradas a partir da associaÃ§Ã£o entre itens interagidos e recomendados com atributos compartilhados. Na literatura existem duas
abordagens de algoritmos explicativos pÃ³s-hoc ou agnÃ³sticas ao
modelo com CG: uma em que as recomendaÃ§Ãµes sÃ£o reordenadas
com base nas melhores explicaÃ§Ãµes para um item recomendado e
outra em que somente as explicaÃ§Ãµes sÃ£o geradas [22].
Considerando algoritmos de reordenaÃ§Ã£o agnÃ³sticos ao modelo
utilizando GC, [ 2 ] utilizou trÃªs mÃ©tricas de otimizaÃ§Ã£o - atualidade de itens interagidos, popularidade e diversidade de atributos
extraÃ­dos de caminhos de explicaÃ§Ã£o do GC - para reordenar recomendaÃ§Ãµes. Por sua vez, [ 34 ] reordenou recomendaÃ§Ãµes avaliando
a relevÃ¢ncia dos atributos extraÃ­dos de caminhos de explicaÃ§Ã£o ao
comparar a frequÃªncia de associaÃ§Ãµes de atributos com itens interagidos e com o catÃ¡logo de itens. AlÃ©m disso, [ 14 ] gerou explicaÃ§Ãµes
por meio de extraÃ§Ã£o de aspectos e anÃ¡lise de sentimento, aumentando a precisÃ£o da recomendaÃ§Ã£o ao incorporar avaliaÃ§Ãµes textuais
como regularizador de algoritmo de recomendaÃ§Ã£o. No entanto, nesses trabalhos, as abordagens propostas avaliaram explicaÃ§Ãµes com
base exclusivamente em mÃ©tricas como precisÃ£o e diversidade.


Considerando arquiteturas GC pÃ³s-hoc para gerar explicaÃ§Ãµes,

[ 19 ] criou um algoritmo chamado ExpLOD, que alavanca explicaÃ§Ãµes de um GC com base em um grafo bipartido que conecta itens
interagidos com recomendados pelos atributos que compartilham.
As explicaÃ§Ãµes sÃ£o classificadas com base em uma adaptaÃ§Ã£o da
mÃ©trica *Term-Frequency Inverse Document Frequency* (TF-IDF), onde
os nÃ³s de item sÃ£o documentos e os nÃ³s de atributo sÃ£o termos. Este

trabalho foi avaliado comparando a explicaÃ§Ã£o proposta com informaÃ§Ãµes extraÃ­das do GC em um experimento online, onde o mÃ©todo
alcanÃ§ou percepÃ§Ã£o do usuÃ¡rio melhorada considerando objetivos
de explicaÃ§Ã£o. [ 20 ] estendeu o ExpLOD [ 19 ], adicionando atributos
mais amplos da hierarquia GC. O mesmo experimento online foi
conduzido, mas as explicaÃ§Ãµes do ExpLOD foram comparadas com
a nova versÃ£o proposta. Os usuÃ¡rios preferiram explicaÃ§Ãµes com
atributos mais amplos ao analisar sob a perspectiva de objetivos de
explicaÃ§Ã£o. Mais recentemente, [ 10 ] propÃ´s o Modelo de ExplicaÃ§Ã£o
Baseado em Propriedades (PEM), uma funÃ§Ã£o de pontuaÃ§Ã£o que classifica atributos com base em suas conexÃµes com itens interagidos
e o catÃ¡logo completo de itens. PEM superou a segunda versÃ£o do
ExpLOD em experimentos online, estabelecendo-se como o estadoda-arte para algoritmos explicativos de GC agnÃ³sticos ao modelo.
Entretanto, essas abordagens sÃ£o sintÃ¡ticas e nÃ£o consideram intrinsecamente a estrutura e o caminho do GC para gerar explicaÃ§Ãµes. Para suprir essa lacuna, em [ 35 ] foi criado um algoritmo de
explicaÃ§Ã£o agnÃ³stico ao sistema de recomendaÃ§Ã£o utilizando representaÃ§Ãµes vetoriais de GC e comparado com abordagens sintÃ¡ticas
utilizando mÃ©tricas offline de qualidade de explicaÃ§Ã£o. No entanto,
diferentes maneiras de gerar representaÃ§Ãµes vetoriais de grafos nÃ£o
foram exploradas visto que somente um modelo para a geraÃ§Ã£o dos
*embeddings* de grafos foi utilizado no algoritmo de explicaÃ§Ã£o.
A avaliaÃ§Ã£o de explicaÃ§Ãµes tambÃ©m tem recebido atenÃ§Ã£o, jÃ¡ que
as explicaÃ§Ãµes sÃ£o principalmente avaliadas com base em testes de
usuÃ¡rios online, que sÃ£o demorados e custosos para validar as estratÃ©gias. Em [ 6 ], mÃ©tricas offline foram implementadas para avaliar
recomendaÃ§Ãµes explicÃ¡veis, no entanto, avaliando a robustez dos
algoritmos explicativos medindo o nÃºmero de itens que podem ser
explicÃ¡veis para os usuÃ¡rios e o nÃºmero de interaÃ§Ãµes do usuÃ¡rio
relacionadas Ã s explicaÃ§Ãµes. Por outro lado, alguns trabalhos tambÃ©m consideram a diversidade e relevÃ¢ncia dos atributos exibidos

nas explicaÃ§Ãµes [ 2, 27 ] embora a relaÃ§Ã£o entre tais mÃ©tricas e testes
online seja definida. AlÃ©m disso, mÃ©tricas offline nÃ£o sÃ£o padronizadas, e trabalhos que avaliam com estudos de usuÃ¡rios carecem
de avaliaÃ§Ã£o quantitativa.
Assim, SsR explicÃ¡veis frequentemente nÃ£o avaliam as explicaÃ§Ãµes de forma quantitativa e qualitativa, jÃ¡ que modelos agnÃ³sticos
de reordenaÃ§Ã£o com GC contribuem com mÃ©tricas de precisÃ£o e
diversidade. Por outro lado, explicaÃ§Ãµes com GC agnÃ³sticas ao modelo sÃ£o avaliadas com testes de usuÃ¡rio online, que sÃ£o custosos e
limitados Ã  avaliaÃ§Ã£o do nÃºmero de participantes e, como resultado,
nÃ£o sÃ£o extensivamente avaliados de maneira offline.
### **3 MATERIAIS E MÃ‰TODOS** **3.1 VisÃ£o Geral**

A fim de responder a QP1 e analisar como diferentes algoritmos
de *embeddings* de grafos impactam na geraÃ§Ã£o de explicaÃ§Ãµes agnÃ³sticas a modelo em SsR, apresentamos um arcabouÃ§o que gera


232


-----

O Impacto de EstratÃ©gias de *Embeddings* de Grafos na Explicabilidade de Sistemas de RecomendaÃ§Ã£o WebMediaâ€™2024, Juiz de Fora, Brazil


explicaÃ§Ãµes para recomendaÃ§Ãµes a partir de *embeddings* de grafos
gerados pelos algoritmos TransE [ 18 ], ComplEx [ 32 ] e RotatE [ 29 ].
O caminho mostrado como a explicaÃ§Ã£o escolhida Ã© dado pela maior
similaridade entre dois *embeddings* : o do caminho e o do usuÃ¡rio. O
*embedding* do caminho Ã© composto pela soma dos *embeddings* dos
nÃ³s e arestas que conectam um ou mais nÃ³s de itens interagidos
pelo usuÃ¡rio com um nÃ³ de item recomendado. JÃ¡ o *embedding* do
usuÃ¡rio Ã© composto pela somatÃ³ria dos *embeddings* dos nÃ³s dos
itens interagidos. Na SeÃ§Ã£o 3.2 detalhamos as estratÃ©gias baseadas
em *embeddings* .
Para responder a QP2, comparamos as abordagens de *embedding*
de grafos com trÃªs algoritmos de estado-da-arte para explicaÃ§Ãµes sintÃ¡ticas em SsR. Nosso objetivo Ã© verificar se abordagens baseadas em
*embeddings* performam melhor que abordagens sintÃ¡ticas. Os algoritmos sintÃ¡ticos implementados foram: ExpLOD [ 19 ], ExpLOD versÃ£o 2 (ExpLOD v2) [ 20 ] e o *Proposed Property-based Explanation Mo-*
*del (PEM)* [ 10 ]. Os trÃªs utilizam estratÃ©gias para balancear a quantidade de referÃªncias que nÃ³s de atributos possuem entre itens interagidos e recomendados para escolher o caminho mais relevante para
uma explicaÃ§Ã£o. Na SeÃ§Ã£o 3.3 detalhamos essas abordagens. Na SeÃ§Ã£o 3.4 detalhamos as mÃ©tricas propostas por [ 2 ] que medem a diversidade de atributos, a popularidade dos mesmos e a recÃªncia de itens
dentro das explicaÃ§Ãµes para avaliar a qualidade das explicaÃ§Ãµes.
As estratÃ©gias avaliadas sÃ£o pÃ³s-hoc e, portanto, independem
dos SsR. Em nossa avaliaÃ§Ã£o consideramos sete algoritmos de recomendaÃ§Ã£o baseados em diferentes abordagens: Mais Popular [ 7 ]
para recomendaÃ§Ãµes nÃ£o personalizadas, o algoritmo PageRank
Personalizado [ 19 ] aumentado com o grafo Wikidata para recomendaÃ§Ãµes baseadas em grafo, User-KNN [ 24 ] para algoritmos
de vizinhanÃ§a, *Embarrassingly Shallow AutoEncoder* (EASE) [ 28 ] e
*Bayesian Personalized Ranking Matrix Factorization* (BPR-MF) [ 23 ]
para algoritmos nÃ£o neurais, e *Neural Collaborative Filtering* (NCF)

[ 16 ] para arquiteturas baseadas em redes neurais. Utilizamos a biblioteca CaseRecommender [ 8 ] para implementar os algoritmos
Mais Popular, User-KNN e BPR-MF. As implementaÃ§Ãµes dos outros
recomendadores, juntamente com os algoritmos de explicaÃ§Ã£o, mÃ©tricas e consultas para extrair as triplas para a construÃ§Ã£o do GC,
estÃ£o **disponÃ­veis em um repositÃ³rio de cÃ³digo aberto** [1] **, sendo**
**essa uma de nossas contribuiÃ§Ãµes nesse trabalho** .
Nas avaliaÃ§Ãµes, consideramos os conjuntos de dados MovieLens
100k [ 15 ] e da LastFM [ 4 ] para as explicaÃ§Ãµes das Top-5 recomendaÃ§Ãµes de seis algoritmos de SsR para todos os usuÃ¡rios. Assim, para
os itens mais bem ranqueados de cada algoritmo de recomendaÃ§Ã£o,
todos os sete (quatro de *embedding* e trÃªs sintÃ¡ticos) algoritmos de
explicaÃ§Ã£o agnÃ³sticos ao modelo foram executados a fim de obter as
mÃ©tricas de qualidade de explicaÃ§Ã£o. Considerando as orientaÃ§Ãµes
de reprodutibilidade em SsR propostas [ 12 ] e robustez da avaliaÃ§Ã£o de explicaÃ§Ã£o destacados [ 30 ], e para garantir uma avaliaÃ§Ã£o
rigorosa, aplicamos seis algoritmos de SsR de diferentes famÃ­lias,
utilizando 90% do conjunto de dados para treinamento e 10% para
teste para gerar as explicaÃ§Ãµes.
Utilizamos um GC da Wikidata *Linked Open Data* (LOD) para os
domÃ­nios de filmes e artistas musicais para implementar todos os algoritmos avaliados. Os dados processados permaneceram com 99%
das interaÃ§Ãµes originais para o conjunto de dados MovieLens 100k e

1 https://github.com/andlzanon/lod-personalized-recommender


89% para o conjunto de dados LastFM. Um resumo das estatÃ­sticas do
MovieLens 100k e do LastFM antes e depois do prÃ©-processamento
e as informaÃ§Ãµes do GC estÃ£o disponÃ­veis na Tabela 1.

|Col1|Col2|MovieLens|LastFM|
|---|---|---|---|
|Conjunto Original|usuÃ¡rios|610|1,892|
||itens|9,724|17,632|
||interaÃ§Ãµes|100,836|92,834|
|Conjunto Processado|usuÃ¡rios|610|1,875|
||itens|9,517|11,641|
||interaÃ§Ãµes|100,521|83,017|
|Wikidata GC|entidades|78,703|34,297|
||triplas|295,787|134,197|
||tipos de arestas|23|33|


*ğ‘–* âˆˆ *ğ¼*

*ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* ( *ğ‘ğ‘ğ‘¡â„* ) =

*ğ‘›* âˆˆ *ğ‘ƒ*

âˆ‘ï¸


*ğ‘’ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘”* ( *ğ‘›* ) (3)

*ğ‘›* âˆˆ *ğ‘ƒ*

âˆ‘ï¸




**Tabela 1: EstatÃ­sticas dos conjuntos de dados originais e pro-**
**cessados, e informaÃ§Ãµes do GC quanto ao nÃºmero de entida-**
**des, triplas e quantidade de arestas.**
### **3.2 Abordagens Baseadas em Embedding**

ExplicaÃ§Ãµes em GC agnÃ³sticas a modelo tem por objetivo descobrir
qual o caminho mais relevante que conecta um item interagido a
um recomendado. A equaÃ§Ã£o 1 define formalmente esse objetivo
em que para todos os caminhos *ğ‘* no conjunto de caminhos *ğ¶* que
conectam um item interagido a um recomendado, uma funÃ§Ã£o de
agregaÃ§Ã£o ( *ğ‘ğ‘”ğ‘”* ) - como mÃ©dia e soma - Ã© aplicada sob a relevÃ¢ncia
*ğ‘Ÿğ‘’ğ‘™* de cada nÃ³ *ğ‘›* em *ğ‘* .

*ğ‘ğ‘Ÿğ‘”ğ‘šğ‘ğ‘¥* (âˆ€ *ğ‘* âˆˆ *ğ¶* : *ğ‘ğ‘”ğ‘”* ( *ğ‘Ÿğ‘’ğ‘™* ( *ğ‘›* )âˆ€ *ğ‘›* âˆˆ *ğ‘* ) (1)

A Figura 1 ilustra a abordagem de *embeddings* de GC agnÃ³stica
ao modelo. Os nÃ³s interagidos pelo usuÃ¡rio no GC sÃ£o os azuis, os
nÃ³s de atributo sÃ£o representados em amarelo, e o nÃ³ em vermelho
Ã© o do item recomendado. As mesmas cores se aplicam aos vetores
que representam os *embeddings* desses nÃ³s. O vetor preto representa um *embedding* de relaÃ§Ãµes entre nÃ³s, representadas por uma
seta de mesma cor na Figura 1.
Dois *embeddings* sÃ£o necessÃ¡rios para calcular a relevÃ¢ncia *ğ‘Ÿğ‘’ğ‘™*
de um caminho de explicaÃ§Ã£o: o do usuÃ¡rio e o do caminho. O *em-*
*bedding* do usuÃ¡rio, que Ã© calculado por um *pooling* de soma dos
*embeddings* dos itens interagidos; e o *embedding* do caminho, que,
por sua vez, Ã© um *pooling* de soma de todos os *embeddings* de itens,
atributos e relaÃ§Ãµes do caminho que conecta um nÃ³ de item interagido pelo usuÃ¡rio a um nÃ³ de item recomendado no GC. As EquaÃ§Ãµes
2 e 3 exibem o cÃ¡lculo para cada um dos *embeddings* onde *ğ¼* Ã© o
conjunto de nÃ³s de itens interagidos pelo usuÃ¡rio, e *ğ‘ƒ* Ã© o conjunto
de nÃ³s de itens, relaÃ§Ãµes e atributos em um caminho. O mÃ©todo
*ğ‘’ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘”* retorna o *embedding* do nÃ³ passado como parÃ¢metro.
Os caminhos foram extraÃ­dos usando o algoritmo de Dijkstra [9].


*ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* ( *ğ‘¢ğ‘ ğ‘’ğ‘Ÿ* ) =

*ğ‘–* âˆˆ *ğ¼*

âˆ‘ï¸


*ğ‘’ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘”* ( *ğ‘–* ) (2)

*ğ‘–* âˆˆ *ğ¼*

âˆ‘ï¸


233


-----

WebMediaâ€™2024, Juiz de Fora, Brazil AndrÃ© Levi Zanon, Leonardo Rocha, and Marcelo Garcia Manzato


**Figura 1: Estrutura do modelo proposto. Os nÃ³s azuis**
**representam os itens interagidos pelo usuÃ¡rio, os nÃ³s**
**amarelos representam nÃ³s de atributo, e o nÃ³ vermelho Ã©**
**o nÃ³ do item recomendado. O mesmo esquema de cores se**
**aplica aos vetores gerados pelos algoritmos de** ***embeddings*** **.**
**Vetores pretos representam o** ***embeddings*** **de arestas. O**
**sÃ­mbolo** [ï¿½] **representa uma operaÃ§Ã£o de** ***pooling*** **de soma, e**
âˆ¼ **Ã© a similaridade de cosseno entre dois** ***embeddings*** **,** *ğ‘Ÿğ‘’ğ‘™* **Ã©**
**a saÃ­da da funÃ§Ã£o de similaridade de cosseno.**

O caminho de explicaÃ§Ã£o escolhido Ã© aquele com a maior similaridade com o *embedding* do usuÃ¡rio entre todos os caminhos que
conectam pelo menos um item interagido ao item recomendado.
Nesse sentido, a similaridade de cosseno do *embedding* do usuÃ¡rio
com os *embeddings* do caminho computa essa proximidade. O comprimento mÃ¡ximo do caminho foi definido como 5, e o nÃºmero de
itens interagidos por explicaÃ§Ã£o, de 3, seguindo a mesma configuraÃ§Ã£o dos *baselines* . O valor da similaridade Ã© representado na EquaÃ§Ã£o
4, onde *ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* ( *ğ‘¢ğ‘ ğ‘’ğ‘Ÿ* ) Ã© o *embedding* do usuÃ¡rio e *ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* ( *ğ‘ğ‘ğ‘¡â„* ) Ã© o
*embedding* do caminho.

*ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* ( *ğ‘¢ğ‘ ğ‘’ğ‘Ÿ* ) *.ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* ( *ğ‘* *ğ‘ğ‘¡â„* )
*ğ‘ ğ‘–ğ‘š* ( *ğ‘¢ğ‘ ğ‘’ğ‘Ÿ, ğ‘ğ‘ğ‘¡â„* ) = (4)
|| *ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* ( *ğ‘¢ğ‘ ğ‘’ğ‘Ÿ* )|| *.* || *ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* ( *ğ‘ğ‘ğ‘¡â„* )||

A seleÃ§Ã£o do caminho de explicaÃ§Ã£o respeita a EquaÃ§Ã£o 5, em que,
para todos os caminhos de explicaÃ§Ã£o dentro do conjunto *ğ‘ƒğ‘ğ‘¡â„ğ‘ *
que ligam um nÃ³ de item interagido a um nÃ³ de item recomendado
por atributos compartilhados entre eles, o *embedding* do caminho
com a maior similaridade de cosseno com o *embedding* do usuÃ¡rio
Ã© o escolhido.

*ğ‘ğ‘Ÿğ‘”ğ‘šğ‘ğ‘¥* (âˆ€ *ğ‘ğ‘ğ‘¡â„* âˆˆ *ğ‘ƒğ‘ğ‘¡â„ğ‘ ğ‘ ğ‘–ğ‘š* ( *ğ‘¢ğ‘ ğ‘’ğ‘Ÿ, ğ‘ğ‘ğ‘¡â„* )) (5)

O *Algorithm 1* Ã© o pseudocÃ³digo do algoritmo de explicaÃ§Ã£o
baseado em *embedding* e utiliza de trÃªs parÃ¢metros: os itens de
histÃ³rico do usuÃ¡rio ( *ğ‘ğ‘Ÿğ‘œğ‘“ğ‘–ğ‘™ğ‘’* _ *ğ‘–ğ‘¡ğ‘’ğ‘šğ‘ * ), o item recomendado a ser
explicado ( *ğ‘Ÿğ‘’ğ‘* _ *ğ‘–ğ‘¡ğ‘’ğ‘š* ) e o modelo de *embbedding* de grafos treinado
( *ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* _ *ğ‘šğ‘œğ‘‘ğ‘’ğ‘™* ). Na linha 2 o *embbedding* do usuÃ¡rio Ã© criado a
partir da soma dos *embbedding* dos nÃ³s dos itens interagidos e que
sÃ£o retornados pelo modelo de *embbedding* de grafos.
Em seguida, na linha 3, todos os caminhos de um item interagido
ao recomendado sÃ£o obtidos utilizando o algoritmo de Dijkstra [ 9 ].
Como no algoritmo proposto o *embbedding* do usuÃ¡rio Ã© comparado


aos *embbeddings* dos caminhos, as linhas 4 e 5 inicializam variÃ¡veis
que serÃ£o responsÃ¡veis por armazenar a similaridade mÃ¡xima atual
e o caminho de *embbedding* mais similar ao do usuÃ¡rio.
As linhas 6 a 14 representam a geraÃ§Ã£o dos *embbeddings* dos
caminhos e a comparaÃ§Ã£o com o *embbedding* do usuÃ¡rio. Dessa
forma, para cada caminho, o *embbedding* Ã© gerado somando os
embeddings dos nÃ³s que o compÃµem. Portanto, *ğ‘.ğ‘›ğ‘œğ‘ * () retorna
uma lista de nÃ³s do caminho *ğ‘* e *ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* _ *ğ‘šğ‘œğ‘‘ğ‘’ğ‘™* ( *ğ‘.ğ‘›ğ‘œğ‘ * ()) retorna os
*embbeddings* desses nÃ³s. Em seguida, a similaridade de cosseno
entre os *embbeddings* do usuÃ¡rio e do caminho Ã© realizada na linha
8. Quando esse valor Ã© maior que o mÃ¡ximo, tanto o valor mÃ¡ximo,
quanto o caminho que corresponde a essa similaridade mÃ¡xima, sÃ£o
atualizados nas linhas 10 e 11. Na linha 14 o algoritmo retorna o
caminho de *embbedding* com maior similaridade com o *embbedding*
do usuÃ¡rio.

**Al** **g** **orithm 1** GeraÃ§Ã£o de Ex p licaÃ§Ã£o com Embeddin g s

1: **function** Caminho_Embedding(profile_items, rec_item, embed_model)

2: *ğ‘¢ğ‘ ğ‘’ğ‘Ÿ* _ *ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* â† *ğ‘ ğ‘¢ğ‘š* ( *ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* _ *ğ‘šğ‘œğ‘‘ğ‘’ğ‘™* ( *ğ‘ğ‘Ÿğ‘œğ‘“ğ‘–ğ‘™ğ‘’* _ *ğ‘–ğ‘¡ğ‘’ğ‘šğ‘ * ))

3: *ğ‘ğ‘ğ‘šğ‘–ğ‘›â„ğ‘œğ‘ * â† *ğ‘‘ğ‘–ğ‘—ğ‘˜ğ‘ ğ‘¡ğ‘Ÿğ‘* ( *ğ‘ğ‘Ÿğ‘œğ‘“ğ‘–ğ‘™ğ‘’* _ *ğ‘–ğ‘¡ğ‘’ğ‘šğ‘ ,ğ‘Ÿğ‘’ğ‘* _ *ğ‘–ğ‘¡ğ‘’ğ‘š* )

4: *ğ‘šğ‘ğ‘¥* â†âˆ’1

5: *ğ‘ğ‘ğ‘š* _ *ğ‘šğ‘ğ‘¥* â†[]

6: **for** c in caminhos **do**

7: *ğ‘ğ‘ğ‘šğ‘–ğ‘›â„ğ‘œ* _ *ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* â† *ğ‘ ğ‘¢ğ‘š* ( *ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* _ *ğ‘šğ‘œğ‘‘ğ‘’ğ‘™* ( *ğ‘.ğ‘›ğ‘œğ‘ * ()))

8: *ğ‘ ğ‘–ğ‘š* â† *ğ‘ğ‘œğ‘ ğ‘ ğ‘’ğ‘›ğ‘œ* ( *ğ‘ğ‘ğ‘šğ‘–ğ‘›â„ğ‘œ* _ *ğ‘’ğ‘šğ‘ğ‘’ğ‘‘,ğ‘¢ğ‘ ğ‘’ğ‘Ÿ* _ *ğ‘’ğ‘šğ‘ğ‘’ğ‘‘* )

9: **if** *ğ‘ ğ‘–ğ‘š* *> ğ‘šğ‘ğ‘¥* **then**

10: *ğ‘šğ‘ğ‘¥* â† *ğ‘ ğ‘–ğ‘š*

11: *ğ‘ğ‘ğ‘š* _ *ğ‘šğ‘ğ‘¥* â† *ğ‘*

12: **end if**

13: **end for**

14: **return** *ğ‘ğ‘ğ‘š* _ *ğ‘šğ‘ğ‘¥*

15: **end function**

A proposta de *embedding* foi feita gerando *embeddings* dos GCs
extraÃ­dos da Wikidata LOD para os domÃ­nios de filmes e artÃ­sticos das bases de dados MovieLens e LastFM, respectivamente. A
escolha dos algoritmos de *embeddings* utilizados foi realizada considerando as diferentes famÃ­lias de algoritmos. Enquanto o TransE

[ 18 ] e RotatE [ 29 ] utilizam a abordagem translacional, o algoritmo
ComplEX [ 32 ], por sua vez, Ã© um algoritmo bilinear. O algoritmo
TransE foi comparado ao RotatE para verificar se a evoluÃ§Ã£o do
estado da arte na representaÃ§Ã£o de *embeddings* de grafos em uma
famÃ­lia de algoritmos, melhora mÃ©tricas de qualidade de explicaÃ§Ã£o.
Modelos translacionais se baseiam no conceito de coordenadas

cartesianas [ 5, 36 ] em que, considerando uma tripla ( *â„,ğ‘Ÿ,ğ‘¡* ), onde
*â„* e *ğ‘¡* sÃ£o nÃ³s no GC e *ğ‘Ÿ* Ã© a relaÃ§Ã£o que conecta os dois nÃ³s, uma
transformaÃ§Ã£o linear que representa a distÃ¢ncia entre esses elementos gera a funÃ§Ã£o de custo a ser minimizada, assim, *â„* + *ğ‘Ÿ* â‰ˆ *ğ‘¡* . O
RotatE usa a equaÃ§Ã£o de distÃ¢ncia *ğ‘‘* *ğ‘Ÿ* ( *â„,ğ‘¡* ) = || *â„* â—¦ *ğ‘Ÿ* âˆ’ *ğ‘¡* ||, jÃ¡ o TransE
utiliza a funÃ§Ã£o *ğ‘‘* *ğ‘Ÿ* ( *â„,ğ‘¡* ) = || *â„* + *ğ‘Ÿ* âˆ’ *ğ‘¡* || . O sÃ­mbolo â—¦ denota o produto
elemento a elemento. Modelos bilineares, por sua vez, medem a
similaridade de *â„*, *ğ‘Ÿ* e *ğ‘¡* utilizando produtos interno e operaÃ§Ãµes
multiplicativas, geralmente envolvendo formas bilineares [17].
Para o treinamento dos modelos de *embedding* de grafos foi realizada a otimizaÃ§Ã£o de parÃ¢metros em que a taxa de aprendizado ( *ğœ†* )


234


-----

O Impacto de EstratÃ©gias de *Embeddings* de Grafos na Explicabilidade de Sistemas de RecomendaÃ§Ã£o WebMediaâ€™2024, Juiz de Fora, Brazil


foi variada entre os valores 0.1 e 0.001, e o tamanho do *batch* ( *ğµ* ) para
atualizaÃ§Ã£o dos parÃ¢metros foi de 128 e 256. O tamanho do *embed-*
*ding* ( *ğ¾* ) tambÃ©m foi otimizado entre 200 e 400. A utilizaÃ§Ã£o ou nÃ£o
de amostragem negativa tambÃ©m foi variada. Quando existia a amostragem negativa, 10 exemplos negativos por amostra positiva foram
gerados para um *batch* . A quantidade de Ã©pocas para o treinamento
foi fixa de 40 para todos os modelos. Como o modelo ComplEX [ 32 ]
usa o algoritmo de *Stochastic Gradient Descent* com AdaGrad [ 11 ]
como otimizador, a taxa de aprendizado Ã© ajustada no treinamento.
As triplas do GC foram divididas em conjuntos de treinamento,
validaÃ§Ã£o e teste na proporÃ§Ã£o de 0.8, 0.1 e 0.1, respectivamente.
No GC extraÃ­do da Wikidata para os itens do conjunto de dados
MovieLens, 235,466 triplas foram utilizadas para treino, 29,434 para
validaÃ§Ã£o e 29,433 para teste. JÃ¡ para o GC extraÃ­do para o LastFM,
a separaÃ§Ã£o treino, validaÃ§Ã£o e teste foi de 101,516, 12,690 e 12,689,
respectivamente. A biblioteca Pykeen [ 1 ] foi utilizada para implementar os modelos de *embeddings* de grafo. A acurÃ¡cia do modelo
Ã© medido pela mÃ©trica de *Hit Rate* que mede o quÃ£o bem o modelo
encontra o nÃ³ que completa uma tripla. Assim, dado um *embedding*
de nÃ³ *â„* e um *embedding* de relaÃ§Ã£o *ğ‘Ÿ*, o modelo deve encontrar o *em-*
*bedding* de nÃ³ *ğ‘¡* correto correspondente a tripla ( *â„,ğ‘Ÿ,ğ‘¡* ) presente no
grafo. As mÃ©tricas de *Hit Rate* no conjunto de teste para os modelos
de melhores parÃ¢metros para os *embeddings* de GC extraÃ­do da Wikidata para o MovieLens e LastFM estÃ£o apresentadas na Tabela 2.
Os melhores modelos obtiveram os seguintes parÃ¢metros: Para
o conjunto de dados MovieLens 100k, no modelo TransE *ğ¾* foi de
200, *ğœ†* de 0.001, *ğµ* de 256 e sem a presenÃ§a de amostragem negativa;
para o modelo ComplEX *ğ¾* foi de 400, *ğµ* de 128 e com a presenÃ§a de
amostragem negativa; no modelo RotatE *ğ¾* foi de 200, *ğœ†* de 0.001, *ğµ*
de 128 e com a presenÃ§a de amostragem negativa. Para o conjunto
de dados LastFM, no modelo TransE *ğ¾* foi de 200, *ğœ†* de 0.001, *ğµ*
de 256 e sem a presenÃ§a de amostragem negativa; para o modelo
ComplEX *ğ¾* foi de 200, *ğµ* de 128 e sem a presenÃ§a de amostragem
negativa; no modelo RotatE *ğ¾* foi de 200, *ğœ†* de 0.001, *ğµ* de 128 e com
a presenÃ§a de amostragem negativa.

### **3.3 Abordagens SintÃ¡ticas**

TrÃªs algoritmos sintÃ¡ticos foram implementados para comparaÃ§Ã£o
com os quatro resultados obtidos por meio da aplicaÃ§Ã£o do mÃ©todo de *embedding* de grafos no arcabouÃ§o da descrito na SeÃ§Ã£o 3.2.
Diferentemente de mÃ©todos baseados em *embeddings*, abordagens
sintÃ¡ticas utilizam a ocorrÃªncia do nÃ³ do atributo relacionado ao

nÃ³ do item para determinar sua relevÃ¢ncia.
O mÃ©todo ExpLOD [ 19 ] classifica propriedades no Grafo de Conhecimento (GC) usando uma abordagem adaptada de TF-IDF. A
relevÃ¢ncia de um atributo Ã© determinada pela frequÃªncia de referÃªncias ao atributo tanto de itens interagidos quanto de itens
recomendados em relaÃ§Ã£o ao total de referÃªncias ao atributo entre
todos os itens. A EquaÃ§Ã£o 6 ilustra o cÃ¡lculo para o valor de relevÃ¢ncia de um atributo *ğ‘*, onde *ğ‘›* *ğ‘,ğ¼* *ğ‘¢* representa o nÃºmero de links
do conjunto de itens interagidos pelo usuÃ¡rio *ğ¼* *ğ‘¢* para o atributo *ğ‘* .
Da mesma forma, *ğ‘›* *ğ‘,ğ¼* *ğ‘Ÿ* denota o nÃºmero de links conectando o atributo *ğ‘* aos itens recomendados *ğ¼* *ğ‘Ÿ*, e *ğ¼ğ·ğ¹* ( *ğ‘* ) significa a FrequÃªncia
Inversa do Documento de *ğ‘*, calculada como log( *ğ‘›* [|] *ğ‘,ğ¼ğ¶* *[ğ¶]* [|] [)] [, onde] [ |] *[ğ¶]* [|]

representa o nÃºmero total de itens no catÃ¡logo e *ğ‘›* *ğ‘,ğ¼* *ğ¶* Ã© o nÃºmero
total de itens referenciando o atributo *ğ‘* . Os valores *ğ›¼* e *ğ›½* sÃ£o pesos
e foram definidos como 0.5 de acordo com [19].


*ğ‘›* *ğ‘* *,ğ¼* *ğ‘¢*
*ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’* _ *ğ‘’ğ‘¥ğ‘ğ‘™ğ‘œğ‘‘* ( *ğ‘, ğ¼* *ğ‘¢* *, ğ¼* *ğ‘Ÿ* ) = ( *ğ›¼*


*ğ‘* *,ğ¼* *ğ‘¢* *ğ‘›* *ğ‘* *,ğ¼* *ğ‘Ÿ*

| *ğ¼* *ğ‘¢* | [) + (] *[ğ›½]* | *ğ¼* *ğ‘Ÿ* |


*ğ‘Ÿ* (6)

| *ğ¼* *ğ‘Ÿ* | [) âˆ—] *[ğ¼ğ·ğ¹]* [(] *[ğ‘]* [)]


A EquaÃ§Ã£o 7 exibe o cÃ¡lculo para classificaÃ§Ã£o de atributos do
ExpLOD v2 [ 20 ], que Ã© muito similar Ã  sua versÃ£o anterior; mas
tambÃ©m abrange atributos mais amplos. Por exemplo, considere o
filme â€™La La Landâ€™ de 2016, classificado com o atributo â€™romanceâ€™
no GC do Wikidata. Essa classificaÃ§Ã£o implica que o filme tambÃ©m
estÃ¡ associado a atributos mais amplos como â€™relacionamento interpessoalâ€™ e â€™amorâ€™, jÃ¡ que â€™romanceâ€™ Ã© uma subclasse desses atributos.
Como resultado, para atributos do GC mais amplos *ğ‘* que tÃªm subclasses, a relevÃ¢ncia Ã© a soma da EquaÃ§Ã£o 6 para todos os atributos
*ğ‘* *ğ‘ğ‘–* no conjunto de *ğ‘ƒ* *ğ‘* ( *ğ‘* ) que sÃ£o filhos de *ğ‘*, multiplicado pelo IDF
da classe mais ampla ( *ğ¼ğ·ğ¹* ( *ğ‘* ) ). Portanto, os algoritmos ExpLOD
classificam atributos que sÃ£o populares entre o conjunto de itens
interagidos, mas raros no conjunto de itens do catÃ¡logo.




*ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’* _ *ğ‘’ğ‘¥ğ‘ğ‘™ğ‘œğ‘‘* ( *ğ‘, ğ¼* *ğ‘¢* *, ğ¼* *ğ‘Ÿ* ) =


| *ğ‘ƒ* *ğ‘* ( *ğ‘* ) |

*ğ‘–* =1

âˆ‘ï¸


*ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’* _ *ğ‘’ğ‘¥ğ‘ğ‘™ğ‘œğ‘‘* ( *ğ‘* *ğ‘ğ‘–* *, ğ¼* *ğ‘¢* *, ğ¼* *ğ‘Ÿ* ) âˆ— *ğ¼ğ·ğ¹* ( *ğ‘* )

*ğ‘–* =1

âˆ‘ï¸


|Col1|Col2|TransE|RotatE|ComplEX|
|---|---|---|---|---|
|MovieLens|H@1|0.0317|0.0982|0.0115|
||H@3|0.0956|0.1595|0.0209|
||H@5|0.1282|0.1927|0.0261|
||H@10|0.1727|0.2418|0.0362|
|LastFM|H@1|0.0570|0.1852|0.0029|
||H@3|0.1135|0.2725|0.0076|
||H@5|0.1481|0.3154|0.0118|
||H@10|0.1998|0.3735|0.0219|


**Tabela 2: MÃ©tricas do conjunto de teste para diferentes al-**
**goritmos de** ***embeddings*** **de grafos para o GC dos conjuntos**
**de dados MovieLens e LastFM.** *ğ»* @ *ğ‘›* **Ã© a mÃ©trica de Hit Rate**
**do modelo para completar corretamente uma tripla conside-**
**rando os** *ğ‘›* **nÃ³s mais prÃ³ximos.**


(7)
O mecanismo de pontuaÃ§Ã£o usado no Modelo de ExplicaÃ§Ã£o Baseado em Propriedades (PEM) Ã© representado pela EquaÃ§Ã£o 8 e,
diferentemente dos algoritmos ExpLOD, considera o nÃºmero de
itens interagidos que referenciam o atributo em vez do nÃºmero de
links. Para pontuar um atributo *ğ‘*, primeiramente, considera-se o
nÃºmero de itens interagidos que referenciam o atributo | *ğ¼* ( *ğ‘, ğ¼* *ğ‘¢* )|,
onde *ğ¼* *ğ‘¢* representa o conjunto de itens com os quais o usuÃ¡rio interagiu. Esse valor Ã© entÃ£o normalizado pelo nÃºmero total de itens
com os quais o usuÃ¡rio interagiu, denotado por | *ğ¼* *ğ‘¢* |.
AlÃ©m disso, a equaÃ§Ã£o considera o nÃºmero de itens no catÃ¡logo
*ğ¶* conectados ao atributo | *ğ¼* ( *ğ‘,ğ¶* )| . Semelhante ao termo anterior,
esse valor Ã© normalizado pelo nÃºmero total de itens no catÃ¡logo, denotado por | *ğ¶* | . Finalmente, o logaritmo do nÃºmero total de itens no


235


-----

WebMediaâ€™2024, Juiz de Fora, Brazil AndrÃ© Levi Zanon, Leonardo Rocha, and Marcelo Garcia Manzato


catÃ¡logo conectados ao atributo log(| *ğ¼* ( *ğ‘,ğ¶* )|) Ã© calculado para amplificar a importÃ¢ncia de atributos relativamente raros no catÃ¡logo.

*ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’* _ *ğ‘ğ‘’ğ‘š* ( *ğ‘, ğ¼* *ğ‘¢* *, ğ¼* *ğ‘Ÿ* *,ğ¶* ) = [|] *[ğ¼]* [(] *[ğ‘]* *[, ğ¼]* *[ğ‘¢]* [)|/|] *[ğ¼]* *[ğ‘¢]* [|] âˆ— log(| *ğ¼* ( *ğ‘,ğ¶* )|) (8)

| *ğ¼* ( *ğ‘,ğ¶* )|/| *ğ¶* |

Para os todos algoritmos o caminho com a maior mÃ©dia de relevÃ¢ncia de atributo Ã© escolhido como explicaÃ§Ã£o. AlÃ©m disso, o comprimento mÃ¡ximo do caminho foi definido como cinco, e o nÃºmero
mÃ¡ximo de itens interagidos para um item recomendado foi trÃªs.
### **3.4 MÃ©tricas**

A mÃ©trica de RecÃªncia da InteraÃ§Ã£o de ConexÃ£o ( *ğ¿ğ¼ğ‘…* ) mede a recÃªncia dos itens interagidos pelo usuÃ¡rio que formam uma explicaÃ§Ã£o;
a Popularidade da Entidade Compartilhada ( *ğ‘†ğ¸ğ‘ƒ* ) mede a popularidade dos atributos exibidos em explicaÃ§Ãµes para um Ãºnico usuÃ¡rio
e Diversidade do Tipo de ExplicaÃ§Ã£o ( *ğ¸ğ‘‡ğ·* ) o nÃºmero de atributos
diferentes nas explicaÃ§Ãµes. Assim, as mÃ©tricas propostas por [ 2 ]
para avaliar a qualidade de explicaÃ§Ã£o definem que explicaÃ§Ãµes de
qualidade encontram caminhos diferentes ( *ğ¸ğ‘‡ğ·* ), mas utilizando
atributos populares ( *ğ‘†ğ¸ğ‘ƒ* ) e conectando itens recomendados com
itens recÃ©m interagidos ( *ğ¿ğ¼ğ‘…* ). Todas as mÃ©tricas variam entre 0 e
1 em que 1 Ã© o valor Ã³timo, exceto por ETD pode ser maior que 1
caso o caminho tenha mais que um atributo.
As EquaÃ§Ãµes 9 e 10 representam as mÃ©tricas de *ğ¿ğ¼ğ‘…* e *ğ‘†ğ¸ğ‘ƒ*, respectivamente. Essas mÃ©tricas sÃ£o calculadas com base na mÃ©dia de
equaÃ§Ãµes de mÃ©dia mÃ³vel exponencialmente ponderada normalizada para cada item interagido e atributo dentro de uma explicaÃ§Ã£o.
Para *ğ¿ğ¼ğ‘…*, os valores dos itens interagidos ( *ğ‘* *[ğ‘–]* ) sÃ£o calculados
usando seus respectivos carimbos de data/hora ( *ğ‘¡* *[ğ‘–]* ), que sÃ£o normalizados pelo mÃ©todo min-max para variar entre 0 e 1. A natureza
recursiva da funÃ§Ã£o garante que o valor de uma propriedade *ğ‘–* depende de *ğ‘–* âˆ’ 1, com valores ordenados em ordem crescente de
carimbos de data/hora. Assim, *ğ¿ğ¼ğ‘…* ( *ğ‘* [1] *,ğ‘¡* [1] ) equivale a *ğ‘¡* 1 . O parÃ¢metro *ğ›½* Ã© tipicamente definido como 0,3, como sugerido em [ 2 ].
Consequentemente, *ğ¿ğ¼ğ‘…* atribui valores mais altos a explicaÃ§Ãµes
que conectam recomendaÃ§Ãµes com itens interagidos mais recentes.

*ğ¿ğ¼ğ‘…* ( *ğ‘* *[ğ‘–]* *,ğ‘¡* *[ğ‘–]* ) = (1 âˆ’ *ğ›½* ) âˆ— *ğ¿ğ¼ğ‘…* ( *ğ‘* *[ğ‘–]* [âˆ’][1] *,ğ‘¡* *[ğ‘–]* [âˆ’][1] ) + *ğ›½* âˆ— *ğ‘¡* *[ğ‘–]* (9)

Na EquaÃ§Ã£o 10, a mÃ©trica de Popularidade da Entidade Compartilhada ( *ğ‘†ğ¸ğ‘ƒ* ) quantifica a popularidade dos atributos considerando
o nÃºmero *ğ‘£* *[ğ‘–]* de nÃ³s de itens conectados ao atributo *ğ‘’* *[ğ‘–]* . A ordenaÃ§Ã£o
e a normalizaÃ§Ã£o min-max tambÃ©m sÃ£o aplicadas ao nÃºmero de
referÃªncias que um atributo tÃªm a outros nÃ³s. Consequentemente,
*ğ‘†ğ¸ğ‘ƒ* ( *ğ‘’* [1] *, ğ‘£* [1] ) corresponde a *ğ‘£* 1, representando o atributo com o menor nÃºmero de referÃªncias no GC. Valores altos de *ğ‘†ğ¸ğ‘ƒ* indicam

que os atributos em explicaÃ§Ãµes sÃ£o populares.

*ğ‘†ğ¸ğ‘ƒ* ( *ğ‘’* *[ğ‘–]* *, ğ‘£* *[ğ‘–]* ) = (1 âˆ’ *ğ›½* ) âˆ— *ğ‘†ğ¸ğ‘ƒ* ( *ğ‘’* *[ğ‘–]* [âˆ’][1] *, ğ‘£* *[ğ‘–]* [âˆ’][1] ) + *ğ›½* âˆ— *ğ‘£* *[ğ‘–]* (10)

Finalmente, a EquaÃ§Ã£o 11 define a mÃ©trica de Diversidade do
Tipo de ExplicaÃ§Ã£o ( *ğ¸ğ‘‡ğ·* ), que quantifica a diversidade de atributos
em explicaÃ§Ãµes associadas a recomendaÃ§Ãµes. Ela calcula a razÃ£o do
nÃºmero de propriedades na lista recomendada | *ğœ”* *ğ¿* *ğ‘¢* | para o mÃ­nimo
entre o comprimento da lista de recomendaÃ§Ã£o *ğ‘˜* e o nÃºmero total de
possÃ­veis atributos *ğœ”* *ğ¿* que poderiam formar uma explicaÃ§Ã£o. *ğ¸ğ‘‡ğ·*
fornece uma visÃ£o sobre a variedade de atributos apresentados em


explicaÃ§Ãµes e ajuda a avaliar se o algoritmo de explicaÃ§Ã£o tende a
favorecer atributos repetitivos. Valores mais altos de *ğ¸ğ‘‡ğ·* indicam
uma maior diversidade de atributos.

| *ğœ”* *ğ¿* *ğ‘¢* |
*ğ¸ğ‘‡ğ·* ( *ğ‘†* ) = (11)
*ğ‘šğ‘–ğ‘›* ( *ğ‘˜,* | *ğœ”* *ğ¿* |)
### **4 RESULTADOS**

Para responder Ã s questÃµes de pesquisa QP1 e QP2, executamos os
algoritmos sintÃ¡ticos ExpLOD, ExpLOD v2, PEM e a abordagem de
*embedding* com os algoritmos TransE, RotatE e ComplEX para todos
os usuÃ¡rios dos conjuntos de dados MovieLens 100k e LastFM para
os cinco principais itens recomendados dos algoritmos de recomendaÃ§Ã£o Mais Popular, BPR-MF, PageRank, UserKNN, EASE e NCF
considerando as mÃ©tricas LIR, ETD e SEP. Os resultados para outras
mÃ©tricas, tais como precisÃ£o e diversidade, e exemplos de explicaÃ§Ãµes gerados por cada um dos algoritmos estÃ£o disponÃ­veis online [2] .
A Tabela 3 e Tabela 4 correspondem Ã  mÃ©dia e o desvio padrÃ£o
das mÃ©tricas de qualidade de explicaÃ§Ã£o SEP, ETD e LIR para todos
os usuÃ¡rios considerando os conjuntos de dados MovieLens 100k
e LastFM, respectivamente, em relaÃ§Ã£o aos cinco principais itens
recomendados de cada algoritmo. As duas primeiras colunas sÃ£o
relativas ao algoritmo de recomendaÃ§Ã£o executado e a mÃ©trica de
qualidade, em seguida, os resultados do mÃ©todo proposto considerando trÃªs algoritmos de *embedding* diferentes estÃ£o nas trÃªs
primeiras colunas e os resultados dos trÃªs mÃ©todos sintÃ¡ticos estÃ£o
nas Ãºltimas trÃªs colunas. Os valores em negrito sÃ£o os mais altos
entre os algoritmos, e os valores sublinhados sÃ£o os mais baixos.
Distinguimos os valores mais altos e mais baixos, porque os objetivos de explicaÃ§Ã£o e os atributos de qualidade exibem um *trade-off* .
Os atributos dos itens sÃ£o distribuÃ­dos seguindo uma *long-tail* em
que alguns atributos sÃ£o muito comuns entre poucos itens [ 13 ] e,
assim, quanto maior a quantidade de atributos mostrados em explicaÃ§Ãµes aos usuÃ¡rios, maior tambÃ©m Ã© a probabilidade de um atributo
menos popular de ser escolhido em uma explicaÃ§Ã£o [2, 3, 31].
A fim de responder a QP1 e diferenciar o impacto de diferentes algoritmos de *embeddings* na geraÃ§Ã£o de explicaÃ§Ãµes, as trÃªs primeiras
colunas das tabelas se referem os resultados das qualidade de explicaÃ§Ãµes do mÃ©todo agnÃ³stico ao modelo utilizando os algoritmos
de *embedding* de grafos TransE [18], RotatE [29] e ComplEX [32].
Considerando os mÃ©todos TransE [ 18 ] e RotatE [ 29 ], que pertencem a famÃ­lia de algoritmos translacionais de *embedding* de grafos,
as mÃ©tricas de *HitRate* no conjunto de treinamento do modelo de
*embedding* de grafos na Tabela 2 evidenciam que o algoritmo RotatE

[ 29 ] Ã© uma evoluÃ§Ã£o no estado da arte para o modelo translacional
TransE [ 18 ]. Nesse sentido, no conjunto de dados LastFM esta evoluÃ§Ã£o do estado-da-arte refletiu na evoluÃ§Ã£o das mÃ©tricas de qualidade
de explicaÃ§Ã£o, em que tanto ETD quanto SEP obtiveram resultados
melhores para o mÃ©todo com o algoritmo RotatE em comparaÃ§Ã£o ao
TransE. No entanto, o mesmo nÃ£o ocorreu no dataset do MovieLens,
em que a melhoria das mÃ©tricas de *HitRate* de um mesmo tipo de
modelo nÃ£o necessariamente refletiu na evoluÃ§Ã£o de mÃ©tricas de
qualidade de explicaÃ§Ã£o. Assim, mesmo modelos mais simples de
*embedding* de grafos conseguem gerar representaÃ§Ãµes vetoriais que
refletem em explicaÃ§Ãµes de qualidade.

2 https://tinyurl.com/zfscfshv


236


-----

O Impacto de EstratÃ©gias de *Embeddings* de Grafos na Explicabilidade de Sistemas de RecomendaÃ§Ã£o WebMediaâ€™2024, Juiz de Fora, Brazil




|Col1|Col2|TransE|RotatE|ComplEX|ExpLOD|ExpLOD v2|PEM|
|---|---|---|---|---|---|---|---|
|Mais Popular|LIR|0.03147 Â± 0.12|0.0275 Â± 0.11|0.0234 Â± 0.09|0.0945 Â± 0.15|0.0834 Â± 0.14|0.0320 Â± 0.07|
||ETD|0.6718 Â± 0.21|0.6842 Â± 0.20|0.9537 Â± 0.31|0.5809 Â± 0.19|0.5947 Â± 0.19|0.9390 Â± 0.12|
||SEP|0.52104 Â± 0.18|0.6869 Â± 0.13|0.5625 Â± 0.15|0.6322 Â± 0.14|0.6107 Â± 0.12|0.1430 Â± 0.13|
|Page Rank|LIR|0.0310 Â± 0.11|0.0312 Â± 0.12|0.0241 Â± 0.10|0.0939 Â± 0.15|0.0872 Â± 0.15|0.0323 Â± 0.08|
||ETD|0.7335 Â± 0.21|0.6570 Â± 0.22|0.9305 Â± 0.31|0.5563 Â± 0.20|0.6043 Â± 0.19|0.9389 Â± 0.12|
||SEP|0.4662 Â± 0.20|0.7022 Â± 0.15|0.5557 Â± 0.16|0.6250 Â± 0.16|0.5606 Â± 0.15|0.1095 Â± 0.11|
|UserKNN|LIR|0.03327 Â± 0.12|0.0352 Â± 0.12|0.0234 Â± 0.10|0.1010 Â± 0.14|0.0914 Â± 0.13|0.0322 Â± 0.08|
||ETD|0.7055 Â± 0.24|0.6849 Â± 0.22|0.9859 Â± 0.33|0.6593 Â± 0.19|0.6409 Â± 0.19|0.9452 Â± 0.11|
||SEP|0.5202 Â± 0.23|0.2311 Â± 0.15|0.6103 Â± 0.16|0.5803 Â± 0.16|0.5275 Â± 0.14|0.131 Â± 0.12|
|BPR-MF|LIR|0.0408 Â± 0.16|0.0298 Â± 0.11|0.0244 Â± 0.09|0.1048 Â± 0.14|0.0945 Â± 0.13|0.0306 Â± 0.07|
||ETD|0.6826 Â± 0.26|0.6934 Â± 0.24|0.9855 Â± 0.32|0.6891 Â± 0.19|0.6937 Â± 0.19|0.9583 Â± 0.10|
||SEP|0.5755 Â± 0.23|0.2151 Â± 0.15|0.5013 Â± 0.16|0.6113 Â± 0.14|0.5428 Â± 0.14|0.1400 Â± 0.12|
|EASE|LIR|0.0312 Â± 0.12|0.0295 Â± 0.11|0.0209 Â± 0.09|0.1000 Â± 0.14|0.0912 Â± 0.14|0.03193 Â± 0.08|
||ETD|0.7345 Â± 0.24|0.6751 Â± 0.23|0.9724 Â± 0.31|0.6204 Â± 0.20|0.6328 Â± 0.19|0.9459 Â± 0.11|
||SEP|0.4952 Â± 0.49|0.6583 Â± 0.17|0.6089 Â± 0.16|0.5743 Â± 0.17|0.5274 Â± 0.15|0.1350 Â± 0.13|
|NCF|LIR|0.0320 Â± 0.13|0.0244 Â± 0.09|0.0199 Â± 0.08|0.1181 Â± 0.13|0.1035 Â± 0.12|0.0380 Â± 0.08|
||ETD|0.6966 Â± 0.29|0.8080 Â± 0.25|1.0100 Â± 0.32|0.8432 Â± 0.16|0.8161 Â± 0.16|0.9885 Â± 0.05|
||SEP|0.6122 Â± 0.22|0.2511 Â± 0.14|0.3955 Â± 0.14|0.5868 Â± 0.14|0.5350 Â± 0.13|0.1613 Â± 0.11|


**Tabela 3: Tabela das mÃ©tricas LIR, ETD e SEP para explicaÃ§Ãµes dos cinco principais itens recomendados no conjunto de**
**dados MovieLens 100k. Valores em negrito sÃ£o os mais altos e valores** **sublinhados** **sÃ£o os mais baixos entre os algoritmos de**
**recomendaÃ§Ã£o.**




|Col1|Col2|TransE|RotatE|ComplEX|ExpLOD|ExpLOD v2|PEM|
|---|---|---|---|---|---|---|---|
|Mais Popular|LIR|0.0104 Â± 0.06|0.0100 Â± 0.06|0.0123 Â± 0.08|0.0182 Â± 0.09|0.0189 Â± 0.11|0.0143 Â± 0.08|
||ETD|0.8247 Â± 0.27|0.9319 Â± 0.25|1.1394 Â± 0.28|0.7023 Â± 0.17|0.4927 Â± 0.22|0.9212 Â± 0.12|
||SEP|0.5084 Â± 0.22|0.6617 Â± 0.21|0.5181 Â± 0.16|0.7097 Â± 0.17|0.7537 Â± 0.23|0.1214 Â± 0.08|
|Page Rank|LIR|0.0108 Â± 0.07|0.008 Â± 0.06|0.0125 Â± 0.07|0.0191 Â± 0.10|0.0212 Â± 0.12|0.0134 Â± 0.07|
||ETD|0.7683 Â± 0.25|0.8704 Â± 0.30|1.0769 Â± 0.32|0.6100 Â± 0.20|0.5447 Â± 0.19|0.9440 Â± 0.10|
||SEP|0.4820 Â± 0.18|0.6359 Â± 0.17|0.5022 Â± 0.18|0.6501 Â± 0.21|0.7164 Â± 0.21|0.1209 Â± 0.09|
|UserKNN|LIR|0.0102 Â± 0.07|0.0090 Â± 0.05|0.0117 Â± 0.07|0.0183 Â± 0.10|0.0191 Â± 0.11|0.0158 Â± 0.08|
||ETD|0.7760 Â± 0.26|0.8688 Â± 0.31|1.0624 Â± 0.32|0.5335 Â± 0.20|0.5355 Â± 0.18|0.9106 Â± 0.14|
||SEP|0.5071 Â± 0.19|0.6088 Â± 0.18|0.4540 Â± 0.18|0.5288 Â± 0.26|0.2810 Â± 0.22|0.1417 Â± 0.10|
|BPR-MF|LIR|0.0110 Â± 0.06|0.0096 Â± 0.06|0.0113 Â± 0.07|0.0191 Â± 0.10|0.0204 Â± 0.11|0.0164 Â± 0.08|
||ETD|0.8403 Â± 0.26|0.9219 Â± 0.31|1.1021 Â± 0.31|0.6145 Â± 0.21|0.6196 Â± 0.19|0.9450 Â± 0.11|
||SEP|0.5312 Â± 0.18|0.6002 Â± 0.17|0.5984 Â± 0.18|0.5605 Â± 0.23|0.6302 Â± 0.19|0.1759 Â± 0.12|
|EASE|LIR|0.0102 Â± 0.07|0.0092 Â± 0.05|0.0111 Â± 0.07|0.0188 Â± 0.11|0.0194 Â± 0.11|0.0154 Â± 0.08|
||ETD|0.7934 Â± 0.25|0.8753 Â± 0.32|1.0707 Â± 0.32|0.5474 Â± 0.20|0.5585 Â± 0.18|0.9246 Â± 0.13|
||SEP|0.5026 Â± 0.19|0.5870 Â± 0.19|0.4639 Â± 0.18|0.5307 Â± 0.25|0.2861 Â± 0.21|0.1466 Â± 0.10|
|NCF|LIR|0.0098 Â± 0.06|0.0106 Â± 0.06|0.0131 Â± 0.07|0.0182 Â± 0.09|0.0162 Â± 0.08|0.0162 Â± 0.08|
||ETD|0.9409 Â± 0.27|1.0318 Â± 0.32|1.2057 Â± 0.29|0.7775 Â± 0.18|0.7867 Â± 0.18|0.9589 Â± 0.09|
||SEP|0.6302 Â± 0.17|0.6509 Â± 0.16|0.6153 Â± 0.17|0.5904 Â± 0.19|0.5514 Â± 0.20|0.2748 Â± 0.15|


**Tabela 4: Tabela das mÃ©tricas LIR, ETD e SEP para explicaÃ§Ãµes dos cinco principais itens recomendados no conjunto de dados**
**LastFM. Valores em negrito sÃ£o os mais altos entre os algoritmos de recomendaÃ§Ã£o e valores** **sublinhados** **sÃ£o os mais baixos.**


Nesse sentido, o algoritmo ComplEX [32], da famÃ­lia de algoritmos bilineares de *embedding* de grafos, obteve os resultados mais
consistentes para ambas as bases. Particularmente este algoritmo
obteve ETD acima de 0.65 e SEP acima de 0.45 para todas os conjuntos de dados e algoritmos. Isso acontece, pois esses modelos
utilizam formas bilineares para gerar as representaÃ§Ãµes vetoriais de


grafos, e isso possibilita a modelagem de padrÃµes mais complexos
entre nÃ³s e arestas. Diferentemente, modelos translacionais geram
*embeddings* por meio da aproximaÃ§Ã£o dos vetores realizando translaÃ§Ãµes, limitando sua expressividade. Dessa forma, respondendo a
QP1, a utilizaÃ§Ã£o de um tipo de modelo de *embedding* que captura


237


-----

WebMediaâ€™2024, Juiz de Fora, Brazil AndrÃ© Levi Zanon, Leonardo Rocha, and Marcelo Garcia Manzato


relaÃ§Ãµes mais complexas entre nÃ³s e arestas refletiu na melhora de
mÃ©tricas de qualidade de explicaÃ§Ã£o.
Para responder a QP2 e comparar as diferenÃ§as entre abordagens
sintÃ¡ticas e semÃ¢nticas, consideramos tambÃ©m os modelos ExpLOD

[ 19 ], ExpLOD v2 [ 20 ] e PEM [ 10 ] (nas trÃªs Ãºltimas colunas da Tabela
3 e Tabela 4). Neste contexto, Ã© possÃ­vel perceber que, para ambos
os conjuntos de dados, os algoritmos sintÃ¡ticos, especialmente os
algoritmos de ExpLOD e do ExpLOD v2, foram as melhores entre
todos os outros algoritmos para as mÃ©tricas LIR e SEP. Por outro
lado, as abordagens de *embeddings* foram superiores na mÃ©trica
ETD de diversidade.

No caso do algoritmo RotatE, por exemplo, para os algoritmos
de Mais Popular e PageRank no conjunto de dados MovieLens e
UserKNN, BPR-MF, EASE e NCF no LastFM, as mÃ©tricas de SEP e
ETD foram melhores quando comparadas Ã  algoritmos sintÃ¡ticos.
Isso indica a capacidade de mÃ©todos de *embedding* de fornecer caminhos de explicaÃ§Ã£o diversos para vÃ¡rias recomendaÃ§Ãµes e manter
um certo nÃ­vel de popularidade de atributos. No entanto, algoritmos
de *embeddings* tambÃ©m demonstraram menores nÃ­veis de LIR, o
que pode ser atribuÃ­do Ã  sua metodologia de treinamento. Embora
identifique caminhos diversos para explicaÃ§Ãµes de diferentes recomendaÃ§Ãµes, o algoritmo incorpora o item interagido apenas no
processo de soma de *pooling* para gerar os *embeddings* do caminho
de explicaÃ§Ã£o e do usuÃ¡rio. Em contraste, os trÃªs mÃ©todos sintÃ¡ticos priorizam a quantidade de nÃ³s de itens interagidos que estÃ£o
conectados a nÃ³s de atributos no GC para a escolha do caminho
mais relevante a ser mostrado como explicaÃ§Ã£o.
A exceÃ§Ã£o Ã© o algoritmo PEM, que reflete o comportamento de
*trade-off* entre diversidade e popularidade de atributos. Este algoritmo alcanÃ§a uma diversidade muito alta, mas, em contraste,
possui a menor SEP para todas as mÃ©tricas. Isso acontece porque, ao
contrÃ¡rio dos algoritmos ExpLOD, que sÃ£o baseados em TF-IDF, o
PEM normaliza o nÃºmero de itens que referenciam um atributo aos
itens interagidos pelo catÃ¡logo. Como o catÃ¡logo de itens Ã© extenso,
o PEM Ã© mais suscetÃ­vel a exibir mais itens diversos.
Portanto, algoritmos sintÃ¡ticos definem a relevÃ¢ncia do caminho
de explicaÃ§Ã£o como um *trade-off* entre o nÃºmero de conexÃµes dos
nÃ³s de atributos com nÃ³s de itens. Nesses algoritmos a explicaÃ§Ã£o escolhida contÃ©m nÃ³s de atributos que estÃ£o conectados a muitos nÃ³s
de itens interagidos pelo usuÃ¡rio, mas pouco conectados a nÃ³s do
conjunto inteiro de itens. Em particular, os algoritmos ExpLOD [ 19 ]
e ExpLOD v2 [ 20 ] priorizam a popularidade, enquanto o PEM [ 10 ]
prioriza a diversidade. JÃ¡ os modelos de *embeddings* sÃ£o treinados na
tarefa de completar triplas dos grafos. Assim, considerando um nÃ³
*â„* e uma relaÃ§Ã£o *ğ‘Ÿ*, algoritmos de *embedding* de grafos aprendem a
encontrar o nÃ³ correto *ğ‘¡* da tripla ( *â„*, *ğ‘Ÿ*, *ğ‘¡* ) do GC. Consequentemente,
algoritmos de explicaÃ§Ã£o que empregam representaÃ§Ãµes vetoriais
sÃ£o balanceados considerando as mÃ©tricas de SEP e ETD.

Respondendo a QP2, observamos que mÃ©todos sintÃ¡ticos estÃ£o
mais propensos a serem influenciados pela popularidade, porque
escolhem explicaÃ§Ãµes considerando o nÃºmero de ligaÃ§Ãµes de um
nÃ³ de atributo aos nÃ³s de itens. Por outro lado, os mÃ©todos baseados em *embeddings* escolhem caminhos de explicaÃ§Ã£o a partir da
similaridade da representaÃ§Ã£o vetorial de nÃ³s e arestas do grafo.
Logo, para estas estratÃ©gias, a popularidade de nÃ³s de atributos em
nÃ³s itens nÃ£o interfere decisivamente na escolha da explicaÃ§Ã£o a


um item recomendado, sendo, dessa maneira, mais equilibrados e,
consequentemente, melhores que mÃ©todos sintÃ¡ticos.
### **5 CONCLUSÃ•ES**

Neste trabalho foi desenvolvida uma abordagem comparativa e
reprodutÃ­vel, analisando o efeito de diferentes algoritmos de *em-*
*beddings* de grafos na geraÃ§Ã£o de explicaÃ§Ãµes de qualidade em algoritmos agnÃ³sticos a modelos em SsR, utilizando GC. Dessa maneira,
por meio de trÃªs mÃ©tricas de explicabilidade: a recÃªncia dos itens
e diversidade e popularidade de atributos, as explicaÃ§Ãµes de cada
algoritmo foi avaliada para duas bases de dados e seis SsR.
Foi verificado que abordagens baseadas em *embeddings* conseguem balancear melhor a popularidade e diversidade de atributos
comparando com abordagens sintÃ¡ticas. AlÃ©m disso, mÃ©tricas de
treinamento de diferentes mÃ©todos de *embedding* nÃ£o necessariamente refletem na melhoria nas mÃ©tricas de qualidade de explicaÃ§Ã£o.
Como trabalhos futuros, modelos geracionais podem ajudar na otimizaÃ§Ã£o multi-parÃ¢metro e considerar todas as trÃªs mÃ©tricas de
qualidade, visto que algoritmos sintÃ¡ticos de explicaÃ§Ã£o priorizam
popularidade ou diversidade de atributos e modelos de *embedding*
nÃ£o priorizam a recÃªncia dos itens.
### **AGRADECIMENTOS**

Os autores agradecem Ã  CAPES, CNPq, Fapesp, AWS e Fapemig
pelo financiamento e apoio a esta pesquisa.
### **REFERÃŠNCIAS**

[1] Ali, M., Berrendorf, M., Hoyt, C.T., Vermue, L., Sharifzadeh, S., Tresp, V., Lehmann,
J.: PyKEEN 1.0: A Python Library for Training and Evaluating Knowledge Graph
Embeddings. Journal of Machine Learning Research **22** (82), 1â€“6 (2021), http:
//jmlr.org/papers/v22/20-825.html

[2] Balloccu, G., Boratto, L., Fenu, G., Marras, M.: Post processing recommender
systems with knowledge graphs for recency, popularity, and diversity of explanations. In: Proceedings of the 45th International ACM SIGIR Conference on
Research and Development in Information Retrieval. pp. 646â€“656 (2022)

[3] Balog, K., Radlinski, F.: Measuring recommendation explanation quality: The
conflicting goals of explanations. In: Proceedings of the 43rd international ACM
SIGIR conference on research and development in information retrieval. pp.
329â€“338 (2020)

[4] Cantador, I., Brusilovsky, P., Kuflik, T.: 2nd workshop on information heterogeneity and fusion in recommender systems (hetrec 2011). In: Proceedings of the
5th ACM conference on Recommender systems. RecSys 2011, ACM, New York,
NY, USA (2011)

[5] Cao, J., Fang, J., Meng, Z., Liang, S.: Knowledge graph embedding: A survey from
the perspective of representation spaces. ACM Computing Surveys **56** (6), 1â€“42
(2024)

[6] Coba, L., Confalonieri, R., Zanker, M.: Recoxplainer: A library for development and offline evaluation of explainable recommender systems. IEEE Computational Intelligence Magazine **17** (1), 46â€“58 (2022).
https://doi.org/10.1109/mci.2021.3129958

[7] Cremonesi, P., Koren, Y., Turrin, R.: Performance of recommender algorithms
on top-n recommendation tasks. In: Proceedings of the Fourth ACM Conference
on Recommender Systems. p. 39â€“46. RecSys â€™10, Association for Computing
Machinery, New York, NY, USA (2010). https://doi.org/10.1145/1864708.1864721,
https://doi.org/10.1145/1864708.1864721

[8] Da Costa, A., Fressato, E., Neto, F., Manzato, M., Campello, R.: Case recommender: a flexible and extensible python framework for recommender systems. In:
Proceedings of the 12th ACM Conference on Recommender Systems. pp. 494â€“495
(2018)

[9] Dijkstra, E.W., et al.: A note on two problems in connexion with graphs. Numerische mathematik **1** (1), 269â€“271 (1959)

[10] Du, Y., Ranwez, S., Sutton-Charani, N., Ranwez, V.: Post-hoc recommendation
explanations through an efficient exploitation of the dbpedia category hierarchy.
Knowledge-Based Systems **245**, 108560 (2022)

[11] Duchi, J., Hazan, E., Singer, Y.: Adaptive subgradient methods for online learning
and stochastic optimization. Journal of machine learning research **12** (7) (2011)


238


-----

O Impacto de EstratÃ©gias de *Embeddings* de Grafos na Explicabilidade de Sistemas de RecomendaÃ§Ã£o WebMediaâ€™2024, Juiz de Fora, Brazil



[12] Ferrari Dacrema, M., Boglio, S., Cremonesi, P., Jannach, D.: A troubling analysis
of reproducibility and progress in recommender systems research. ACM Transactions on Information Systems (TOIS) **39** (2), 1â€“49 (2021)

[13] Ferraro, A.: Music cold-start and long-tail recommendation: bias in deep representations. In: Proceedings of the 13th ACM conference on recommender systems.
pp. 586â€“590 (2019)

[14] Hada, D.V., Shevade, S.K.: Rexplug: Explainable recommendation using plugand-play language model. In: Proceedings of the 44th International ACM SIGIR
Conference on Research and Development in Information Retrieval. pp. 81â€“91
(2021)

[15] Harper, F.M., Konstan, J.A.: The movielens datasets: History and context. Acm
transactions on interactive intelligent systems (tiis) **5** (4), 1â€“19 (2015)

[16] He, X., Liao, L., Zhang, H., Nie, L., Hu, X., Chua, T.S.: Neural collaborative filtering. In: Proceedings of the 26th International Conference on World
Wide Web. p. 173â€“182. WWW â€™17, International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE (2017).
https://doi.org/10.1145/3038912.3052569

[17] Li, J., Yang, Y.: Star: Knowledge graph embedding by scaling, translation and
rotation. In: International Conference on AI and Mobile Services. pp. 31â€“45.
Springer (2022)

[18] Lin, Y., Liu, Z., Sun, M., Liu, Y., Zhu, X.: Learning entity and relation embeddings
for knowledge graph completion. In: Proceedings of the AAAI conference on
artificial intelligence. vol. 29 (2015)

[19] Musto, C., Narducci, F., Lops, P., De Gemmis, M., Semeraro, G.: Explod: a framework for explaining recommendations based on the linked open data cloud. In:
Proceedings of the 10th ACM Conference on Recommender Systems. pp. 151â€“154
(2016)

[20] Musto, C., Narducci, F., Lops, P., de Gemmis, M., Semeraro, G.: Linked open
data-based explanations for transparent recommender systems. International
Journal of Human-Computer Studies **121**, 93â€“107 (2019)

[21] Peng, C., Xia, F., Naseriparsa, M., Osborne, F.: Knowledge graphs: Opportunities
and challenges. Artificial Intelligence Review pp. 1â€“32 (2023)

[22] Rana, A., Dâ€™Addio, R.M., Manzato, M.G., Bridge, D.: Extended recommendationby-explanation. User Modeling and User-Adapted Interaction **32** (1-2), 91â€“131
(2022)

[23] Rendle, S., Freudenthaler, C., Gantner, Z., Schmidt-Thieme, L.: Bpr: Bayesian
personalized ranking from implicit feedback. In: Proceedings of the Twenty-Fifth
Conference on Uncertainty in Artificial Intelligence. p. 452â€“461. UAI â€™09, AUAI
Press, Arlington, Virginia, USA (2009)

[24] Resnick, P., Iacovou, N., Suchak, M., Bergstrom, P., Riedl, J.: Grouplens: An
open architecture for collaborative filtering of netnews. In: Proceedings of the
1994 ACM Conference on Computer Supported Cooperative Work. p. 175â€“186.
CSCW â€™94, Association for Computing Machinery, New York, NY, USA (1994).
https://doi.org/10.1145/192844.192905, https://doi.org/10.1145/192844.192905

[25] Ricci, F., Rokach, L., Shapira, B.: Recommender systems: introduction and challenges. Recommender systems handbook pp. 1â€“34 (2015)

[26] Rudin, C.: Stop explaining black box machine learning models for high stakes
decisions and use interpretable models instead. Nature machine intelligence **1** (5),
206â€“215 (2019)

[27] Souza, L.S.d., Manzato, M.G.: Aspect-based summarization: an approach with
different levels of details to explain recommendations. In: Proceedings of the
Brazilian Symposium on Multimedia and the Web. pp. 202â€“210 (2022)

[28] Steck, H.: Embarrassingly shallow autoencoders for sparse data. In: The World
Wide Web Conference. p. 3251â€“3257. WWW â€™19, Association for Computing
Machinery, New York, NY, USA (2019). https://doi.org/10.1145/3308558.3313710,
https://doi.org/10.1145/3308558.3313710

[29] Sun, Z., Deng, Z.H., Nie, J.Y., Tang, J.: Rotate: Knowledge graph embedding by
relational rotation in complex space. arXiv preprint arXiv:1902.10197 (2019)

[30] Tchuente, D., Lonlac, J., Kamsu-Foguem, B.: A methodological and theoretical
framework for implementing explainable artificial intelligence (xai) in business
applications. Computers in Industry **155**, 104044 (2024)

[31] Tintarev, N., Masthoff, J.: Explaining recommendations: Design and evaluation.
In: Recommender systems handbook, pp. 353â€“382. Springer (2015)

[32] Trouillon, T., Welbl, J., Riedel, S., Gaussier, Ã‰., Bouchard, G.: Complex embeddings
for simple link prediction. In: International conference on machine learning. pp.
2071â€“2080. PMLR (2016)

[33] Xu, Z., Zeng, H., Tan, J., Fu, Z., Zhang, Y., Ai, Q.: A reusable model-agnostic
framework for faithfully explainable recommendation and system scrutability.
ACM Transactions on Information Systems (2023)

[34] Zanon, A.L., da Rocha, L.C.D., Manzato, M.G.: Balancing the trade-off between
accuracy and diversity in recommender systems with personalized explanations
based on linked open data. Knowledge-Based Systems **252**, 109333 (2022)

[35] Zanon, A.L., da Rocha, L.C.D., Manzato, M.G.: Model-agnostic knowledge graph
embedding explanations for recommender systems. In: World Conference on
Explainable Artificial Intelligence. pp. 3â€“27. Springer (2024)

[36] Zhang, S., Tay, Y., Yao, L., Liu, Q.: Quaternion knowledge graph embeddings.
Advances in neural information processing systems **32** (2019)



[37] Zhang, Y., Chen, X., et al.: Explainable recommendation: A survey and new
perspectives. Foundations and TrendsÂ® in Information Retrieval **14** (1), 1â€“101
(2020)


239


-----

