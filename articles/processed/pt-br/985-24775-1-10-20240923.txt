# **Únicos, mas não incomparáveis: abordagens para identificação de** **similaridades em respostas emocionais de diferentes indivíduos** **ao mesmo estímulo audiovisual**

## Guilherme O. Aguiar Juan P. D. Esteves
#### Instituto Federal de Mato Grosso Pontes e Lacerda, Brasil guilherme.aguiar@estudante.ifmt.edu.br dantas.esteves@estudante.ifmt.edu.br
### **ABSTRACT**

## Cleon X. Pereira Júnior Thamer H. Nascimento
#### Instituto Federal Goiano Iporá, Brasil cleon.junior@ifgoiano.edu.br thamer.nascimento@ifgoiano.edu.br

## Renan V. Aranha
#### Universidade Federal de Mato Grosso Cuiabá, Brasil renan.aranha@ufmt.br


Understanding human emotional behavior is a complex but essential task when aiming to offer a better user experience through the
incorporation of Affective Computing techniques. The integration
of these techniques can lead to more intuitive and emotionally
intelligent interactions between users and systems. In a society
characterized by ethnic and cultural diversity, it is also necessary
to understand how different individuals react to a given stimulus so
that adaptations and interventions in the software can be effective.
In this context, this study discusses two approaches to comparing
emotional responses of different individuals to the same emotional
stimulus. By leveraging advanced data analysis and machine learning methods, the research aims to provide deeper insights into
emotional patterns. In addition to highlighting the importance of
discussing the characteristics and particularities of each approach,
the study presents a validation of these approaches, identifying
similarities - and distinctions - in the emotional responses of 39
individuals. The results not only demonstrate the effectiveness of
the approaches but also suggest their complementarity.
### **KEYWORDS**

Computação Afetiva, Respostas Emocionais, Modelagem do Usuário
### **1 INTRODUÇÃO**

Num contexto em que as emoções humanas têm recebido cada vez
mais atenção no projeto e no uso de sistemas interativos, é imperativo compreender como as pessoas reagem emocionalmente aos
estímulos que lhes são apresentados [ 8 ]. Os benefícios inerentes
a esse conhecimento podem contemplar tanto aplicações voltadas
ao entretenimento, como plataformas de *streaming*, até sistemas
de educação à distância [ 16 ], em que a interação entre docentes e
estudantes usualmente envolve conteúdo audiovisual. Nessas situa
ções, entender como os indivíduos têm reagido aos conteúdos pode
fornecer informações interessantes, ao realçar pontos positivos das
produções audiovisuais e destacar aspectos a serem aprimorados
para que a finalidade do recurso seja alcançada, assim como indicar situações em que os estudantes apresentam dificuldades na
assimilação dos conteúdos [9].

In: Proceedings of the Brazilian Symposium on Multimedia and the Web (WebMe
dia’2024). Juiz de Fora, Brazil. Porto Alegre: Brazilian Computer Society, 2024.
© 2024 SBC – Brazilian Computing Society.
ISSN 2966-2753


Ainda que os avanços tecnológicos tenham favorecido o desenvolvimento de técnicas e algoritmos cada vez mais eficientes para o
reconhecimento de emoções, existem diversos desafios a serem superados para a interpretação dos dados emocionais, especialmente
quando associados a conteúdos audiovisuais. Como difundido na
área de Interação Humano-Computador [ 3 ], o processo de interação
é fortemente influenciado pelo contexto de uso. Diferentemente
de produtos como aplicativos de produtos ou serviços que desejam oferecer boa experiência aos usuários, produções audiovisuais
podem ter o intuito de provocar emoções consideradas negativas
em seus espectadores. Assim, emoções como raiva ou medo não
são indicadores de uma experiência ruim, como em boa parte das
aplicações computacionais, mas sim indicadores de que o usuário
está engajado com aquele conteúdo. Como exemplo desta categoria, pode-se citar filmes de drama, suspense e terror. No âmbito da
Educação, o estado emocional de confusão pode revelar o esforço
do estudante na aprendizagem, mas a longa duração desse estado
emocional pode levar o estudante à frustração [9].
Além dos aspectos contextuais, sabe-se também que as emoções
de um indivíduo são suscetíveis a aspectos demográficos [ 5, 10 ]
e suas diferenças individuais, como seus traços de personalidade

[ 13, 14, 17 ]. Portanto, um único estímulo pode provocar respostas
emocionais distintas em diferentes indivíduos. Também é possível
que este estímulo não evoque nenhuma emoção em um conjunto
de indivíduos. Logo, o simples fato de expor um indivíduo a um
estímulo não garante a evocação de determinados estados emocio
nais.

Na área de Computação Afetiva, é crescente o interesse de pesquisadores no desenvolvimento de aplicações que se adaptam aos
estados emocionais dos usuários [ 16 ]. Em geral, as soluções propostas envolvem o treinamento de algoritmos de Aprendizado de
Máquina em grandes conjuntos de dados, que nem sempre consideram as características contextuais do processo de interação,
bem como também podem não considerar semelhanças ou particularidades dos indivíduos que compõem os dados utilizados para
treinamento. Neste complexo contexto, compreender como pessoas
diferentes reagem emocionalmente a um estímulo é fundamental
para o aprimoramento das soluções de Computação Afetiva considerando princípios de explicabilidade.
Mais do que associar as reações emocionais de um usuário a categorias de experiência, como boa/ruim ou engajado/não engajado,
é crucial compreender por que algumas pessoas reagem emocionalmente a um estímulo enquanto outras não. É necessário, também,


336


-----

WebMedia’2024, Juiz de Fora, Brazil Aguiar, et al.


identificar quais pessoas reagem de maneira semelhante aos mesmos estímulos e quais reagem de forma diferente. Além disso, é
fundamental desenvolver métodos para comparar essas reações

emocionais.
Se, por um lado, o processo de identificação de similaridades
não é inédito e está embutido em diversas soluções que envolvem a
utilização de algoritmos de Aprendizado de Máquina, é também fato
que o processo nem sempre é tratado com transparência e enfoque
na explicabilidade. Assim, visando contribuir com este cenário, a
partir de práticas identificadas na literatura, este estudo apresenta
duas abordagens para a comparação de respostas emocionais de
diferentes indivíduos. Ao analisar as reações emocionais de 39 indivíduos a um estímulo audiovisual sob as duas abordagens, são
realçadas as particularidades de cada abordagem, bem como discutidas as contribuições decorrentes de uma análise conjunta, que
integra as duas abordagens propostas.
### **2 CONTEXTO TEÓRICO E CONTRIBUIÇÕES** **DESTE ESTUDO**

Estudos que discutem reações emocionais de indivíduos a estímulos
audiovisuais não são inéditos na literatura e podem ser classificados
quanto ao objetivo da investigação. Uma revisão exploratória da
literatura revela uma maior quantidade de estudos que visam à
**detecção de engajamento ou interesse** em conteúdo audiovisual
a partir das respostas emocionais dos usuários. Como exemplo dessa
prática, a recém-publicada pesquisa de Oakes, Peschel e Barraclough

[ 15 ] investiga a viabilidade de se utilizar dados de expressões faciais,
registrados de forma não invasiva, para avaliar o engajamento do
público em apresentações artísticas. Diferentemente de estudos que
analisam os dados de cada usuário separadamente, esta pesquisa
adota como premissa que a similaridade das respostas emocionais
do público é um indicativo de engajamento com a apresentação. Esta
premissa emerge de estudos anteriores, que observaram reações
similares de usuários enquanto estavam engajados ao ouvir músicas.
Ainda nesse contexto, uma pesquisa conduzida por de Sá et al .

[ 7 ] analisou as respostas emocionais de 10 usuários ao *trailer* de
um filme do gênero horror que, à época do estudo, ainda não havia
sido lançado. O intuito estava em predizer a intenção de assistir ao
filme. Foram observados sinais EEG e, com o uso de *eye tracking*, a
região do vídeo para a qual cada usuário estava olhando. Embora os
resultados indiquem padrões no reconhecimento das emoções, não
há informações quanto à similaridade de respostas emocionais de
diferentes indivíduos. Em trabalho similar, conduzido por Da Silva
et al . [ 6 ] também usando as técnicas de EEG e *eye tracking*, foram
observadas as reações emocionais de usuários a conteúdos audiovisuais, visando a favorecer a avaliação da percepção desses usuários
quanto ao conteúdo assistido.
No âmbito da **comparação similaridade em respostas emoci-**
**onais**, [ 2 ] descrevem uma pesquisa em que dois grupos de pessoas,
um formado por indivíduos com perfil político liberal e outro grupo
formado por indivíduos com perfil conservador, tiveram suas respostas emocionais a estímulos visuais registrados com o uso de eletromiografia facial. Indivíduos de ambos os grupos foram expostos
a um conjunto de imagens. Ao final do processo, os pesquisadores
aplicaram o teste t de Student para identificar se havia diferença
significativa entre os dados dos diferentes grupos. Os resultados,


relatados em [ 1 ], revelam que não houve diferença estatisticamente
significativa entre os dois grupos de usuários.
A literatura também revela **desafios** inerentes à análise emocional a partir de estímulos audiovisuais. Embora o uso de filmes
para elicitar emoções em usuários tenha se mostrado uma abordagem efetiva tanto para emoções positivas quanto negativas [ 11 ],
há casos em que os impactos emocionais são sutis. Como exemplo,
análises de [ 4 ] revelaram que, ao contrário do esperado, os vídeos
utilizados como estímulo não foram capazes de gerar respostas
emocionais equivalentes. Em alguns casos, os índices identificados
para determinadas expressões faciais associadas a emoções foram
muito baixos. Como possível justificativa, os autores explicaram
que os participantes haviam sido orientados a não olhar para a tela
em momentos desconfortáveis (possivelmente em cumprimento
aos procedimentos éticos). Como consequência, o *software* utilizado para o reconhecimento de expressões faciais pode não ter
identificado as expressões adequadamente nesses instantes.
A análise dos trabalhos supracitados revela o amplo conjunto
de oportunidades de contribuições no âmbito da comparação de
repostas emocionais de diferentes indivíduos aos mesmos estímulos
emocionais, evidenciando a relevância da presente investigação já
a partir da categorização de abordagens para comparação de dados
emocionais, que será apresentada na Seção 3. Em complemento, os
resultados da comparação de reações emocionais de 39 indivíduos,
cujo processo metodológico é descrito na Seção 4, contribuem para
a compreensão das características e particularidades de cada abordagem, bem como para o avanço na identificação de similaridades
em repostas emocionais.
### **3 ABORDAGENS PARA A COMPARAÇÃO DE** **DADOS EMOCIONAIS**

As técnicas de reconhecimento de emoções em tempo real (de caráter fisiológico ou não) coletam uma grande quantidade de dados
durante determinado período. Como consequência, o tratamento
e a interpretação desse grande conjunto de dados pode ser um
processo complexo, condutível de diferentes formas. A partir de
reflexão crítica em relação às práticas adotadas na literatura para a
interpretação de dados relacionados aos estados emocionais, são
propostas a seguir duas abordagens aplicáveis a esse contexto.
### **3.1 Análise de experiência emocional**

A primeira abordagem, neste estudo denominada de “Análise de
Experiência Emocional” (AEE), considera as emoções elicitadas por
um indivíduo durante um determinado período. Nesta perspectiva, o
enfoque está em compreender quais foram as respostas emocionais
dos usuários aos estímulos, bem como a frequência ou intensidade
em que essas emoções foram detectadas.
A Figura 1 ilustra de forma simplificada como a análise de experiência emocional se caracteriza. Nesta Figura, há a representação
visual de uma linha do tempo, com marcações que indicam diferentes trechos de um vídeo. Abaixo, há duas trilhas, cada uma
representando um usuário diferente. Na trilha de cada usuário, na
região equivalente a cada trecho de vídeo, existe a representação
visual da emoção que o usuário vivenciou durante aquele momento.
A Figura revela que dois indivíduos, denotados pelas alcunhas de


337


-----

Únicos, mas não incomparáveis: abordagens para identificação de similaridades em respostas emocionais WebMedia’2024, Juiz de Fora, Brazil

**Figura 1: Representação do processo de interpretação dos dados segundo a abordagem AEE, em que são comparadas as reações**
**emocionais de cada usuário a diferentes trechos de um mesmo estímulo audiovisual.**

**Figura 2: Representação do processo de interpretação dos dados segundo a abordagem ATE.**


"Pessoa A"e "Pessoa B", tiveram expressões faciais associadas a emoções reconhecidas em dois trechos do vídeo. Enquanto a Pessoa A
estava com a expressão facial associada à raiva no primeiro trecho,
a emoção identificada no segundo trecho era a de alegria. O processo inverso é observado para a Pessoa B, que inicia o vídeo com
a expressão facial associada à alegria e o conclui com a expressão
facial associada à raiva.

Ao aplicar-se uma análise de experiência emocional, as experiências dos usuários A e B serão consideradas equivalentes, pois, no
processo de análise, as duas emoções foram observadas em igual
intensidade. Nota-se, portanto, que nesta abordagem a ordem de
manifestação das emoções não é relevante, mas sim a frequência ou
intensidade com que se manifestaram. Seguindo esta abordagem,
a conclusão indicaria que o vídeo gerou reações emocionais de
alegria e raiva em ambos os usuários. Do conceito à implementação, podem ser aplicadas, neste contexto, as seguintes técnicas: i)
cálculo de média das emoções; ii) quantificação da expressão facial


mais intensa em um determinado período; iii) cálculo de distância
euclidiana; e iv) algoritmos de clusterização, como o *kNN* . Como
exemplo de pesquisas que adotam tal prática, têm-se os estudos de
González-Rodríguez et al. [12] e Boğa et al. [4].
### **3.2 Análise de trajetória emocional**

Diferentemente da abordagem anterior, que desconsidera a temporalidade no comportamento emocional, a análise de trajetória
emocional dedica-se a observar se, ao longo de um determinado
período, a intensidade com que uma emoção foi identificada cresceu ou decresceu ao longo do tempo. Nessa abordagem, valoriza-se
o impacto dos acontecimentos do vídeo no estado emocional dos
usuários. Novamente recorrendo à Figura 1 para a exemplificação
dessa abordagem, pode-se entender que, para a Pessoa A, o primeiro
trecho do vídeo elicitava a emoção de raiva, enquanto o segundo
trecho elicitava a emoção de alegria. Em contraponto, uma situação
inversa pode ser observada para a Pessoa B. Nota-se, neste ponto,


338


-----

WebMedia’2024, Juiz de Fora, Brazil Aguiar, et al.


uma questão importante: o mesmo conjunto de dados pode gerar diferentes interpretações a partir da abordagem de análise. Enquanto
a abordagem anterior possibilitava concluir que ambos os usuários
tiveram experiências equivalentes, a atual abordagem realça que
estes usuários tiveram experiências completamente distintas, como
evidência a Figura 2.
Em termos práticos, a análise de trajetória emocional pode ser
observada a partir da correlação. Neste contexto, um desafio está na
definição da janela de tempo em que será analisada a similaridade
entre dois usuários. Em [ 15 ], por exemplo, optou-se por analisar a
correlação dos estados emocionais de diferentes usuários em uma
janela de tempo de um minuto.
### **4 MATERIAIS E MÉTODOS**

Visando a comparar e validar abordagens para a identificação de
similaridades em respostas emocionais de diferentes usuários, serão
aplicadas as abordagens AEE e ATE, apresentadas na seção anterior.
Para nortear o percurso metodológico deste estudo, foram definidas
as questões de pesquisa apresentadas a seguir:

  - **QP1** : Há experiências emocionais similares de usuários que
assistiram aos mesmos estímulos audiovisuais?

  - **QP2** : Para um mesmo estímulo emocional, há usuários com
trajetórias emocionais similares?

  - **QP3** : Há casos de usuários que compartilham tanto experiências quanto trajetórias emocionais?

Para responder à **QP1**, serão analisadas as similaridades de experiências emocionais de diferentes usuários aos mesmos estímulos

audiovisuais, conforme abordagem AEE, descrita na Seção 3.1. Para
a redução da amostragem, será gerado um vetor de características
para cada indivíduo ( *𝑉* *𝑖* ), contendo a média da intensidade de cada
expressão facial associada à emoção. Foi estabelecida a seguinte
ordem: neutra ( *𝜇* 1 ), alegria ( *𝜇* 2 ), tristeza ( *𝜇* 3 ), raiva ( *𝜇* 4 ), medo ( *𝜇* 5 ),
nojo ( *𝜇* 6 ) e surpresa ( *𝜇* 7 ).

*𝑉* *𝑖* = [ *𝜇* 1 *, ..., 𝜇* *𝑛* ] (1)

Em seguida, os dados serão submetidos ao algoritmo kNN ( *k-*
*Nearest Neighbors* ), com parâmetro *𝑛* = 39, para possibilitar a comparação de todos os pares de indivíduos. Assim, para cada par, será
calculada a distância entre esses indivíduos. Para responder à **QP2**,
que trata da trajetória emocional (abordagem ATE, descrita na Seção 3.2), será calculada a correlação entre as trajetórias emocionais
dos usuários. Considerando a distribuição dos dados, o método de
cálculo de correlação utilizado será a correlação de Spearman. Uma
vez que a correlação compara a variação entre duas variáveis, será
calculada a correlação considerando a expressão facial neutra. Para
a discussão, serão consideradas apenas correlações estatisticamente
significativas ( *𝑝* *<* 0 *.* 05) e que possuam correlação, no mínimo,
moderada ( *𝜌* *𝑠* *>* = 0 *.* 5 ) . Finalmente, para a discussão da **QP3**, o
índice de correlação ( *𝜌* *𝑠* ) e o índice de similaridade do kNN serão
analisados em conjunto para os pares de usuários.
### **4.1 Seleção do conjunto de dados**

Embora existam diversos conjuntos de dados de expressões faciais
associadas a emoções, conjuntos de dados que contenham vídeos
ou fotografias de pessoas reagindo ao mesmo conjunto de estímulos
audiovisuais, com sincronização temporal, são escassos. Após uma


pesquisa exploratória, foram identificados dois conjuntos de dados
que continham tal característica: o *AM-FED*, mantido pela Affectiva,
e o Emognition Wearable Dataset 2020 [ 18 ]. Ambos os conjuntos
de dados são gratuitos para uso em pesquisas científicas, sendo
este outro critério de seleção. Com relação aos aspectos éticos, a
Resolução CNS 674/2022 habilita o desenvolvimento de pesquisas
que envolvam conjuntos de dados já coletados. Nesse sentido, as
pessoas autoras submeteram solicitação de acesso aos produtores
do conjunto de dados *Emognition* e também para o *AM-FED* . Até o
momento de elaboração deste trabalho, houve apenas resposta por
parte dos produtores do *dataset Emognition* .

*Emognition.* O conjunto de dados *Emognition* reúne dados de 39
1 participantes (18 do sexo masculino e 21 do feminino, com idade
de 21 ± 2 anos ). Cada voluntário assistiu a dez vídeos. Deles, um
foi considerado neutro, enquanto os outros nove evocavam uma
emoção específica. O protocolo utilizado para a coleta de dados
envolveu os seguintes procedimentos: ao início da coleta, durante
cinco minutos, os voluntários assistiram a um vídeo contendo linhas
e pontos dispostos em uma tela preta. Em seguida, responderam a
um questionário de autoavaliação. Então, para cada um dos dez vídeos utilizados como estímulo, adotou-se a realização das seguintes
etapas: i) 2 minutos de vídeo contendo linhas e pontos dispostos
em uma tela preta; ii) vídeo com a intencionalidade de se evocar
uma emoção específica (com duração 1 a 2 minutos); e iii) responder ao questionário de autoavaliação. Além dos vídeos gravados
com os voluntários, o conjunto de dados é composto por dados de
reconhecimento de expressões faciais, analisadas com o uso do *soft-*
*ware Quantum Sense*, que reconhece expressões faciais associadas
às seguintes emoções: raiva, nojo, alegria, tristeza e surpresa, além
da face neutra. Como os registros disponibilizados no *dataset* não
estavam associados ao *frame* do vídeo, visando à compatibilidade
das análises, os vídeos foram processados novamente pelas pessoas
autoras deste trabalho. No âmbito deste estudo, por limitação de
escopo, foram consideradas as reações emocionais de usuários ao
estímulo associado à emoção de nojo.
### **4.2 Processamento dos dados**

Os vídeos que integram o conjunto de dados *Emognition* estavam
organizados com a identificação do usuário e do estímulo utilizado
naquela coleta. Ao início da fase de processamento, para cada arquivo de vídeo, foram extraídas imagens estáticas, uma para cada
segundo de duração do vídeo. Assim, um vídeo com duração de 120
segundos resultou na geração de 120 imagens estáticas. Tal processo
foi realizado visando-se a reduzir a dimensionalidade dos dados.

As imagens foram, portanto, submetidas ao processamento pela biblioteca *Face-api.js*, cuja eficácia no reconhecimento de expressões
faciais associadas a emoções foi avaliada em estudo anterior. Para
cada imagem, a biblioteca retorna um vetor com a intensidade de
cada uma das sete expressões faciais: neutra, alegria, medo, nojo,
raiva, tristeza e surpresa. É importante mencionar que, diferentemente de algumas soluções que analisam a ocorrência de expressões
faciais associadas a emoções de forma independente, a *Face-api.js*
considera a ocorrência excludente. Se em determinada imagem for
detectada a expressão facial neutra com intensidade de 80%, os

1 O número de 39 participantes considera apenas indivíduos para os quais há registros
de imagens disponíveis.


339


-----

Únicos, mas não incomparáveis: abordagens para identificação de similaridades em respostas emocionais WebMedia’2024, Juiz de Fora, Brazil


índices relacionados às demais expressões faciais devem somar 20%.
Portanto, a expressão facial neutra é um indicativo de evocação
emocional em um determinado instante. Para cada usuário, em cada
estímulo, foi gerado um arquivo no formato CSV ( *comma-separated*
*values* ) contendo o vetor de intensidades emocionais em determinada imagem. Também foi anotado o número da imagem, visando
a favorecer a comparação das respostas emocionais de diferentes
usuários.
### **5 RESULTADOS** **5.1 Detecção de experiências emocionais** **similares**

Para identificar similaridades em experiências emocionais de diferentes indivíduos (QP1), foi calculada, para cada participante, a
média de intensidade de cada expressão facial. Obteve-se, portanto,
um vetor de sete características para cada indivíduo. A Figura 3 apresenta, nesse contexto, um gráfico de dispersão dos dados emocionais
desses indivíduos [2] . Para a geração da figura, dada a necessidade de
redução de dimensionalidade, de sete para duas, foi aplicado um
algoritmo PCA ( *Principal Component Analysis* ). A Figura 3 evidencia, a partir da proximidade dos pontos, que há uma quantidade
considerável de indivíduos que apresentaram experiências emocionais similares. Em contraponto, há indivíduos com experiências
emocionais distintas.


0.6

0.4

0.2

0

-0.2

-0.4

-0.6




















-0.5 -0.25 0 0.25 0.5 0.75 1

**Figura 3: Dispersão dos indivíduos quanto às expressões faci-**
**ais coletadas durante o estímulo audiovisual.**

Enriquecendo o processo de interpretação dos dados, foram selecionados de forma arbitrária, a partir da dispersão apresentada na
Figura 3, dois pares de indivíduos para uma análise mais detalhada:

2 Visando à reprodutibilidade, os indivíduos estão identificados com o código utilizado
pelos autores do conjunto de dados *Emognition* .


Indivíduo *𝜇* 1 *𝜇* 2 *𝜇* 3 *𝜇* 4 *𝜇* 5 *𝜇* 6 *𝜇* 7

36 0.89 0.09 0.02 0.00 0.00 0.00 0.00

64 0.92 0.08 0.00 0.00 0.00 0.00 0.00

28 0.85 0.00 0.07 0.00 0.01 0.00 0.06

63 0.07 0.82 0.10 0.00 0.00 0.01 0.00

**Tabela 1: Comparação dos vetores de características de duas**
**duplas de indivíduos.**

um par graficamente próximo (indivíduos 36 e 64) e outro par graficamente distante (indivíduos 28 e 63). Os dados, apresentados na
Tabela 1, evidenciam a similaridade dos vetores de características
dos indivíduos 36 e 64, assim como a diferença entre os vetores de
características dos indivíduos 28 e 63. Enquanto o primeiro par teve
alta incidência de expressão facial neutra, com a ocorrência também
da expressão facial associada à alegria em intensidade similar, o
segundo par apresentou experiências distintas. O indivíduo 28 teve
maior incidência de expressão facial neutra, enquanto o indivíduo
63 teve maior incidência de expressões faciais associadas à emoção
de alegria.
Em seguida, também aplicou-se o algoritmo *kNN*, que calcula
a distância entre indivíduos que compõem um par. Quanto mais
próximo de zero é o índice, maior é a similaridade identificada entre
dois usuários. Em decorrência do elevado número de combinações
(1482, tendo *𝑛* = 39), tem-se na Tabela 2 a apresentação dos cinco pares com maior similaridade, seguidos pelos cinco pares com menor
similaridade.

Indivíduo Vizinho Distância

31 39 0.00

25 24 0.00

47 50 0.01

43 24 0.01

43 23 0.01

24 63 1.24

63 24 1.24

63 25 1.24

23 63 1.23

43 63 1.23

**Tabela 2: Resultados provenientes do algoritmo kNN.**

Potencializando a análise e favorecendo uma compreensão de
todo o cenário, a Figura 4 apresenta um gráfico de distribuição dos
índices de distância calculados para cada par de usuários com o algoritmo *KNN* . Como pode-se observar, há uma expressiva quantidade
de ocorrências com alta similaridade entre os indivíduos.
### **5.2** **Identificação de trajetórias emocionais** **similares**

Considerando a QP2, que trata da identificação de similaridades de
trajetórias emocionais de diferentes indivíduos aos mesmos estímulos audiovisuais, calculou-se, para cada par de usuários, a correlação


340


-----

WebMedia’2024, Juiz de Fora, Brazil Aguiar, et al.


300

200

100

0

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

**Figura 4: Distribuição do índice de similaridade calculado**
**pelo algoritmo** ***KNN*** **.**

de Spearman. A operação foi realizada para os índices relacionados
à expressão facial neutra, considerando os motivos expostos anteriormente na Seção 4. Os resultados, descritos parcialmente na Tabela
3, revelam que foram encontradas 210 correlações estatisticamente
significativas ( *𝑝* *<* 0 *.* 05). Destas, 67 correlações são negativas e 143
positivas. Para auxiliar o processo de compreensão dos dados e de
validação dessa abordagem, optou-se pela utilização de recursos
gráficos.

Indivíduo 1 Indivíduo 2 *𝜌* *𝑠* *𝑝*

50 43 0.97 0.00

47 43 0.97 0.00

47 50 0.96 0.00

50 60 0.84 0.0

60 43 0.82 0.00

56 29 0.24 0.04

50 27 0.24 0.04

28 26 0.24 0.04

26 31 0.24 0.04

51 57 0.25 0.03

**Tabela 3: Índices de correlação entre pares de usuários.**

As Figuras 5, 6 e 7 apresentam gráficos de linhas que comparam, longitudinalmente, a variação da intensidade da expressão
facial neutra de dois usuários. No caso da Figura 5, tem-se uma
comparação entre os usuários identificados pelos números 38 e 48.
Embora a intensidade da expressão facial neutra de ambos os usuários tenha apresentado variação ao longo do tempo, há correlação
positiva moderada e significativa ( *𝜌* *𝑠* = 0 *.* 54, *𝑝* = 0 *.* 0), evidenciada
pela similaridade no comportamento longitudinal das linhas. Ao
analisar-se a Figura 6, que ilustra a comparação para os usuários
43 e 47 no mesmo intervalo de tempo contemplado pela Figura 5,
evidencia-se inicialmente que o comportamento facial do segundo
par de indivíduos apresentou pouca variação quando comparado ao
par anterior. Estes usuários não tiveram ativação emocional notável
em suas expressões faciais em considerável parte do vídeo, mas
apresentaram forte correlação ( *𝜌* *𝑠* = 0 *.* 97, *𝑝* = 0 *.* 0).
Ademais, embora a questão de pesquisa que fomenta essa discussão trate da identificação de trajetórias similares, a abordagem


também é capaz de revelar trajetórias emocionais opostas, a partir
da análise de correlações negativas. A Figura 7 apresenta uma situação em que houve moderada correlação negativa ( *𝜌* *𝑠* = − 0 *.* 65,
*𝑝* = 0 *.* 0) entre os usuários 43 e 63.
### **5.3 Comparação entre as abordagens**

Em vistas a discutir a **QP3**, que trata da ocorrência de experiências
e trajetórias emocionais similares, foi realizado o confronto dos
resultados do algoritmo *kNN* com a correlação de Spearman. A
Tabela 4 apresenta os dez primeiros registros após a ordenação por
correlação e similaridade.

Indivíduo Vizinho *𝜌* *𝑠* *𝑝* kNN

50 43 0.97 0.0 0.01

47 43 0.97 0.0 0.03

47 50 0.96 0.0 0.01

50 60 0.84 0.0 0.06

60 43 0.82 0.0 0.07

47 63 -0.76 0.00 8.07

50 63 -0.72 0.00 8.04

63 43 -0.65 0.00 7.99

27 26 -0.61 0.00 7.01

49 32 -0.57 0.00 6.10

**Tabela 4: Índices de correlação e distância entre pares de**
**indivíduos, contemplando as abordagens AEE e ATE.**

Para exemplificação dos resultados, serão discutidos de forma
detalhada dois pares de indivíduos: 43-50 e 47-63. O primeiro par,
formado pelos indivíduos identificados pelos números 43 e 50, é
caracterizado por grande similaridade nas duas abordagens de identificação de similaridade emocional. Uma consulta aos dados de
expressões faciais revela que, para ambos os indivíduos, o estímulo
audiovisual não provocou considerável manifestação de expressões
faciais associadas a emoções detectadas com o uso do *software*,
como revela a Tabela 5. A análise é corroborada pela Figura 8, que
evidencia comportamento fortemente similar.

Indivíduo *𝜇* 1 *𝜇* 2 *𝜇* 3 *𝜇* 4 *𝜇* 5 *𝜇* 6 *𝜇* 7

43 0.99 0 0.01 0 0 0 0

50 0.98 0 0.02 0 0 0 0

47 0.97 0 0.03 0 0 0 0

63 0.07 0.82 0.1 0 0 0.01 0

**Tabela 5: Comparação dos vetores de características de duas**
**duplas de indivíduos a partir da análise conjunta de AEE e**
**ATE.**

Em contraponto, a comparação entre as duas abordagens também
favorece a identificação de pares de indivíduos em que há grandes
distinções, tanto na abordagem AEE quanto na abordagem ATE,
caso do par formado pelos indivíduos 47 e 63. Como indicado na
Tabela 5, nota-se que enquanto para o indivíduo 47 predominou-se
a expressão facial neutra, para o indivíduo 63 observou-se maior


341


-----

Únicos, mas não incomparáveis: abordagens para identificação de similaridades em respostas emocionais WebMedia’2024, Juiz de Fora, Brazil

1

0

5 10 15 20 25 30 35 40 45 50 55 60 65 70

**Figura 5: Comparação gráfica da trajetória emocional dos indivíduos 38 e 48, com correlação moderada (** *𝜌* *𝑠* = 0 *.* 54 **,** *𝑝* = 0 *.* 0 **)**

1

0

5 10 15 20 25 30 35 40 45 50 55 60 65 70

43 47

**Figura 6: Comparação gráfica da trajetória emocional dos indivíduos 43 e 47, com correlação forte (** *𝜌* *𝑠* = 0 *.* 97 **,** *𝑝* = 0 *.* 0 **)**

1

0

5 10 15 20 25 30 35 40 45 50 55 60 65 70

**Figura 7: Comparação gráfica da trajetória emocional dos indivíduos 47 e 63, com correlação moderada e inversa (** *𝜌* *𝑠* = − 0 *.* 65 **,**
*𝑝* = 0 *.* 0 **)**


incidência da expressão facial associada à alegria. Similarmente, a
Figura 7 evidencia a comparação da ATE para esses dois indivíduos,
revelando a distinção entre suas reações ao longo do vídeo, como
já discutido anteriormente.
### **6 DISCUSSÕES** **6.1 Contribuições**

Os resultados apresentados na Seção 5 permitem concluir que as
abordagens AEE e ATE são, de fato, eficazes para a comparação
de similaridade de respostas emocionais evocadas por diferentes
indivíduos a partir de um mesmo estímulo audiovisual, tanto em


relação às experiências emocionais quanto em relação às trajetórias.
Os resultados também validam as particularidades das abordagens,
evidenciando que elas oferecem diferentes perspectivas de compreensão das respostas emocionais dos indivíduos e, portanto, devem
ser escolhidas sob um cauteloso processo de análise dos pesquisadores quanto ao objetivo do estudo. Enquanto a AEE oferece uma
perspectiva quanto às emoções vivenciadas, com suas respectivas
intensidades, a ATE evidencia as alterações emocionais ocorridas ao
longo do estímulo. Tais abordagens podem, inclusive, ser combinadas para a identificação de total similaridade entre dois indivíduos.
Podem, também, revelar comportamentos complemente opostos,
denotados por um índice representativo de grande distância (AEE)


342


-----

WebMedia’2024, Juiz de Fora, Brazil Aguiar, et al.

1

0

5 10 15 20 25 30 35 40 45 50 55 60 65 70

**Figura 8: Comparação gráfica da trajetória emocional dos indivíduos 43 e 50, com correlação forte e positiva. (** *𝜌* *𝑠* = 0 *.* 97 **,** *𝑝* = 0 *.* 0 **)**


e correlação inversa (ATE). A classificação de práticas relatadas na
literatura em duas abordagens, seguida pela sua validação, oferece
não apenas novas perspectivas para a análise emocional no âmbito
de sistemas interativos, mas também abre caminho para a prospecção de um conjunto de aplicações práticas. Nesse sentido, pode-se
mencionar desde a avaliação de conteúdo em plataformas de *strea-*
*ming* até adaptação de materiais de ensino às respostas emocionais
dos alunos.
### **6.2** **Desafios e oportunidades**

O desenvolvimento de uma investigação que visa a comparar repostas emocionais de diferentes indivíduos é desafiadora sob diversos
aspectos. Dentre eles, está na coleta sincronizável das respostas
emocionais. Uma alternativa nesse cenário envolve a construção
de *datasets* em um ambiente controlado, como ocorreu na base de
dados utilizada neste estudo. Todavia, a utilização de vídeos para
estimular emoções nos voluntários nem sempre é satisfatória, como
realçado na literatura e observado ao longo dos resultados. Como
discutido na seção de resultados, foram identificados vários casos
em que os voluntários permaneceram com a expressão facial neutra
durante o tempo em que assistiam ao vídeo utilizado como estímulo.
Apesar dessa limitação, destaca-se a efetividade das abordagens
avaliadas neste estudo, que conseguiram identificar indivíduos que
tiveram tal comportamento similar.
Ademais, no âmbito deste estudo, foram considerados estímulos
audiovisuais, caracterizados pelo mesmo tempo de duração. Em
aplicações interativas, como jogos eletrônicos, o processo de interação é marcado pelo protagonismo do usuário, que tem o poder
de decisão quanto aos eventos e ações da aplicação. Assim, pode
não haver sincronicidade nos estímulos apresentados. Neste cenário, a comparação de similaridades de respostas emocionais dos
usuários tende a ser ainda mais desafiadora, já que o percurso do
usuário na aplicação pode não ser equiparável a outro. Como alternativa, pode-se optar pela comparação de respostas emocionais em
intervalos de tempo menores, delimitados pelo acontecimento de
determinado evento, como a exibição de um diálogo ou a conclusão
de um objetivo. Técnicas como *Multi-Dimensional Dynamic Time*
*Warping* (MDDTW), por exemplo, podem ser aplicadas para essa
comparação.
Finalmente, visando a reprodutibilidade da análise, os dados processados durante o desenvolvimento deste estudo estão disponíveis


para acesso público a partir da seguinte URL https://shorturl.at/
mJV8y.
### **7 CONSIDERAÇÕES FINAIS**

Compreender as emoções humanas e o modo como diferentes indivíduos reagem aos mesmos estímulos é um desafio altamente
complexo, mesmo diante de avanços em áreas como neurologia,
psicologia e computação. Ao mesmo tempo que a compreensão dos
estados afetivos humanos é um campo com oportunidades a serem
exploradas, há também oportunidades para enriquecer a experiência de uso de sistemas computacionais a partir da adaptação desses
sistemas considerando as emoções vivenciadas pelos usuários durante o uso de determinada aplicação. Este processo, entretanto,
envolve o agrupamento de usuários com características similares,
que recebem tratamento equivalente.
Comparando os resultados provenientes de duas abordagens
para a identificação de similaridades em respostas emocionais, este
estudo provoca o estado da arte ao discutir as particularidades de
cada abordagem, bem como ao sugerir uma profunda reflexão crítica
quanto à abordagem de comparação de respostas emocionais em
estudos futuros.
É evidente, portanto, que os desafios relacionados a esse tema
não são esgotados no presente trabalho. Deste modo, investigações
futuras devem expandir o escopo de análise, contemplando respostas emocionais de indivíduos a um amplo conjunto de estímulos
audiovisuais. Há, ainda, possibilidades quanto à expansão da análise com a inclusão de fatores demográficos, como idade, gênero e
nacionalidade, além de características individuais, como traços de
personalidade. Espera-se que a condução de novas investigações
nesse sentido enriqueça o arcabouço conceitual da área de Computação Afetiva, favorecendo o desenvolvimento de aplicações que
disponham de adaptações afetivas com efetividade.
### **AGRADECIMENTOS**

Os autores expressam gratidão ao Freepik pelas imagens utilizadas
na criação de algumas figuras deste artigo.
### **REFERÊNCIAS**

[1] Bert Bakker, Gijs Schumacher, Kevin Arceneaux, and Claire Gothreau. 2022.
Conservatives and Liberals have Similar Physiological Responses to Threats.
(2022). https://doi.org/10.17605/OSF.IO/D5G72


343


-----

Únicos, mas não incomparáveis: abordagens para identificação de similaridades em respostas emocionais WebMedia’2024, Juiz de Fora, Brazil



[2] Bert N. Bakker, Gijs Schumacher, Claire Gothreau, and Kevin Arceneaux. 2020.
Conservatives and liberals have similar physiological responses to threats. *Nature*
*Human Behaviour* 4, 6 (Feb. 2020), 613–621. https://doi.org/10.1038/s41562-0200823-z

[3] Simone Diniz Junqueira Barbosa, Bruno Santana da Silva, Milene Selbach Silveira,
Isabela Gasparini, Ticianne Darin, and Gabriel Diniz Junqueira Barbosa. 2021.
*Interação Humano-Computador e Experiência do Usuário* . Autopublicação.

[4] Merve Boğa, Mehmet Koyuncu, Gülin Kaça, and Turan Onur Bayazıt. 2022. Comparison of emotion elicitation methods: 3 methods, 3 emotions, 3 measures. *Cur-*
*rent Psychology* 42, 22 (April 2022), 18670–18685. https://doi.org/10.1007/s12144022-02984-5

[5] Alan S. Cowen, Dacher Keltner, Florian Schroff, Brendan Jou, Hartwig Adam,
and Gautam Prasad. 2020. Sixteen facial expressions occur in similar contexts
worldwide. *Nature* 589, 7841 (Dec. 2020), 251–257. https://doi.org/10.1038/s41586020-3037-7

[6] Thiago Henrique Coelho Tavares Da Silva, Matheus Dantas Cavalcanti, Felipe
Melo Feliciano De Sá, Isaac Nóbrega Marinho, Daniel De Queiroz Cavalcanti, and
Valdecir Becker. 2022. Visualization of brainwaves using EEG to map emotions
with eye tracking to identify attention in audiovisual workpieces. In *Proceedings of*
*the Brazilian Symposium on Multimedia and the Web* (Curitiba, Brazil) *(WebMedia*
*’22)* . Association for Computing Machinery, New York, NY, USA, 381–389. https:
//doi.org/10.1145/3539637.3557055

[7] Felipe de Sá, Daniel Cavalcanti, and Valdecir Becker. 2023. Testes com usuários
para análise de emoções em conteúdos audiovisuais utilizando EEG e eye tracking.
In *Anais Estendidos do XXIX Simpósio Brasileiro de Sistemas Multimídia e Web*
(Ribeirão Preto/SP). SBC, Porto Alegre, RS, Brasil, 63–66. https://doi.org/10.5753/
webmedia_estendido.2023.235663

[8] Tomás A. D’Amelio, Nicolás M. Bruno, Leandro A. Bugnon, Federico Zamberlan,
and Enzo Tagliazucchi. 2023. Affective Computing as a Tool for Understanding
Emotion Dynamics from Physiology: A Predictive Modeling Study of Arousal
and Valence. In *2023 11th International Conference on Affective Computing and*
*Intelligent Interaction Workshops and Demos (ACIIW)* . 1–7. https://doi.org/10.
1109/ACIIW59127.2023.10388155



[9] Diógines D’Avila Goldoni, Helena M. Reis, and Patrícia A. Jaques. 2023. Emoções
na Aprendizagem: Estimando a Duração da Confusão e Aprimorando Intervenções Pedagógicas. *Revista Brasileira de Informática na Educação* 31 (dez. 2023),
1225–1247. https://doi.org/10.5753/rbie.2023.3433

[10] Yingruo Fan, Jacqueline C. K. Lam, and Victor O. K. Li. 2021. Demographic
effects on facial emotion expression: an interdisciplinary investigation of the
facial action units of happiness. *Scientific Reports* 11, 1 (March 2021). https:
//doi.org/10.1038/s41598-021-84632-9

[11] Luz Fernández-Aguilar, Beatriz Navarro-Bravo, Jorge Ricarte, Laura Ros, and
Jose Miguel Latorre. 2019. How effective are films in inducing positive and negative emotional states? A meta-analysis. *PLOS ONE* 14, 11 (Nov. 2019), e0225040.
https://doi.org/10.1371/journal.pone.0225040

[12] M.Rosario González-Rodríguez, M.Carmen Díaz-Fernández, and Carmen Pacheco Gómez. 2020. Facial-expression recognition: An emergent approach to the
measurement of tourist satisfaction through emotions. *Telematics and Informatics*
51 (Aug. 2020), 101404. https://doi.org/10.1016/j.tele.2020.101404

[13] Timothy A Judge and Stephen P Robbins. 2017. *Organizational behavior* . Pearson.

[14] Krzysztof Kutt, Dominika Drążyk, Szymon Bobek, and Grzegorz J. Nalepa. 2020.
Personality-Based Affective Adaptation Methods for Intelligent Systems. *Sensors*
21, 1 (Dec. 2020), 163. https://doi.org/10.3390/s21010163

[15] Richard A. Oakes, Lisa Peschel, and Nick E. Barraclough. 2024. Inter-subject
correlation of audience facial expressions predicts audience engagement during
theatrical performances. *iScience* (April 2024), 109843. https://doi.org/10.1016/j.
isci.2024.109843

[16] Guanxiong Pei, Haiying Li, Yandi Lu, Yanlei Wang, Shizhen Hua, and Taihao Li.
2024. Affective Computing: Recent Advances, Challenges, and Future Trends.
*Intelligent Computing* 3 (Jan. 2024). https://doi.org/10.34133/icomputing.0076

[17] Rainer Reisenzein, Andrea Hildebrandt, and Hannelore Weber. 2020. *Personality*
*and Emotion* (2 ed.). Cambridge University Press, 81–100. https://doi.org/10.
1017/9781108264822.009

[18] Stanisław Saganowski, Joanna Komoszyńska, Maciej Behnke, Bartosz Perz, Łukasz D. Kaczmarek, and Przemysław Kazienko. 2021. Emognition Wearable
Dataset 2020. https://doi.org/10.7910/DVN/R9WAF4


344


-----

