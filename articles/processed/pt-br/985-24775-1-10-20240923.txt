# **√önicos, mas n√£o incompar√°veis: abordagens para identifica√ß√£o de** **similaridades em respostas emocionais de diferentes indiv√≠duos** **ao mesmo est√≠mulo audiovisual**

## Guilherme O. Aguiar Juan P. D. Esteves
#### Instituto Federal de Mato Grosso Pontes e Lacerda, Brasil guilherme.aguiar@estudante.ifmt.edu.br dantas.esteves@estudante.ifmt.edu.br
### **ABSTRACT**

## Cleon X. Pereira J√∫nior Thamer H. Nascimento
#### Instituto Federal Goiano Ipor√°, Brasil cleon.junior@ifgoiano.edu.br thamer.nascimento@ifgoiano.edu.br

## Renan V. Aranha
#### Universidade Federal de Mato Grosso Cuiab√°, Brasil renan.aranha@ufmt.br


Understanding human emotional behavior is a complex but essential task when aiming to offer a better user experience through the
incorporation of Affective Computing techniques. The integration
of these techniques can lead to more intuitive and emotionally
intelligent interactions between users and systems. In a society
characterized by ethnic and cultural diversity, it is also necessary
to understand how different individuals react to a given stimulus so
that adaptations and interventions in the software can be effective.
In this context, this study discusses two approaches to comparing
emotional responses of different individuals to the same emotional
stimulus. By leveraging advanced data analysis and machine learning methods, the research aims to provide deeper insights into
emotional patterns. In addition to highlighting the importance of
discussing the characteristics and particularities of each approach,
the study presents a validation of these approaches, identifying
similarities - and distinctions - in the emotional responses of 39
individuals. The results not only demonstrate the effectiveness of
the approaches but also suggest their complementarity.
### **KEYWORDS**

Computa√ß√£o Afetiva, Respostas Emocionais, Modelagem do Usu√°rio
### **1 INTRODU√á√ÉO**

Num contexto em que as emo√ß√µes humanas t√™m recebido cada vez
mais aten√ß√£o no projeto e no uso de sistemas interativos, √© imperativo compreender como as pessoas reagem emocionalmente aos
est√≠mulos que lhes s√£o apresentados [ 8 ]. Os benef√≠cios inerentes
a esse conhecimento podem contemplar tanto aplica√ß√µes voltadas
ao entretenimento, como plataformas de *streaming*, at√© sistemas
de educa√ß√£o √† dist√¢ncia [ 16 ], em que a intera√ß√£o entre docentes e
estudantes usualmente envolve conte√∫do audiovisual. Nessas situa
√ß√µes, entender como os indiv√≠duos t√™m reagido aos conte√∫dos pode
fornecer informa√ß√µes interessantes, ao real√ßar pontos positivos das
produ√ß√µes audiovisuais e destacar aspectos a serem aprimorados
para que a finalidade do recurso seja alcan√ßada, assim como indicar situa√ß√µes em que os estudantes apresentam dificuldades na
assimila√ß√£o dos conte√∫dos [9].

In: Proceedings of the Brazilian Symposium on Multimedia and the Web (WebMe
dia‚Äô2024). Juiz de Fora, Brazil. Porto Alegre: Brazilian Computer Society, 2024.
¬© 2024 SBC ‚Äì Brazilian Computing Society.
ISSN 2966-2753


Ainda que os avan√ßos tecnol√≥gicos tenham favorecido o desenvolvimento de t√©cnicas e algoritmos cada vez mais eficientes para o
reconhecimento de emo√ß√µes, existem diversos desafios a serem superados para a interpreta√ß√£o dos dados emocionais, especialmente
quando associados a conte√∫dos audiovisuais. Como difundido na
√°rea de Intera√ß√£o Humano-Computador [ 3 ], o processo de intera√ß√£o
√© fortemente influenciado pelo contexto de uso. Diferentemente
de produtos como aplicativos de produtos ou servi√ßos que desejam oferecer boa experi√™ncia aos usu√°rios, produ√ß√µes audiovisuais
podem ter o intuito de provocar emo√ß√µes consideradas negativas
em seus espectadores. Assim, emo√ß√µes como raiva ou medo n√£o
s√£o indicadores de uma experi√™ncia ruim, como em boa parte das
aplica√ß√µes computacionais, mas sim indicadores de que o usu√°rio
est√° engajado com aquele conte√∫do. Como exemplo desta categoria, pode-se citar filmes de drama, suspense e terror. No √¢mbito da
Educa√ß√£o, o estado emocional de confus√£o pode revelar o esfor√ßo
do estudante na aprendizagem, mas a longa dura√ß√£o desse estado
emocional pode levar o estudante √† frustra√ß√£o [9].
Al√©m dos aspectos contextuais, sabe-se tamb√©m que as emo√ß√µes
de um indiv√≠duo s√£o suscet√≠veis a aspectos demogr√°ficos [ 5, 10 ]
e suas diferen√ßas individuais, como seus tra√ßos de personalidade

[ 13, 14, 17 ]. Portanto, um √∫nico est√≠mulo pode provocar respostas
emocionais distintas em diferentes indiv√≠duos. Tamb√©m √© poss√≠vel
que este est√≠mulo n√£o evoque nenhuma emo√ß√£o em um conjunto
de indiv√≠duos. Logo, o simples fato de expor um indiv√≠duo a um
est√≠mulo n√£o garante a evoca√ß√£o de determinados estados emocio
nais.

Na √°rea de Computa√ß√£o Afetiva, √© crescente o interesse de pesquisadores no desenvolvimento de aplica√ß√µes que se adaptam aos
estados emocionais dos usu√°rios [ 16 ]. Em geral, as solu√ß√µes propostas envolvem o treinamento de algoritmos de Aprendizado de
M√°quina em grandes conjuntos de dados, que nem sempre consideram as caracter√≠sticas contextuais do processo de intera√ß√£o,
bem como tamb√©m podem n√£o considerar semelhan√ßas ou particularidades dos indiv√≠duos que comp√µem os dados utilizados para
treinamento. Neste complexo contexto, compreender como pessoas
diferentes reagem emocionalmente a um est√≠mulo √© fundamental
para o aprimoramento das solu√ß√µes de Computa√ß√£o Afetiva considerando princ√≠pios de explicabilidade.
Mais do que associar as rea√ß√µes emocionais de um usu√°rio a categorias de experi√™ncia, como boa/ruim ou engajado/n√£o engajado,
√© crucial compreender por que algumas pessoas reagem emocionalmente a um est√≠mulo enquanto outras n√£o. √â necess√°rio, tamb√©m,


336


-----

WebMedia‚Äô2024, Juiz de Fora, Brazil Aguiar, et al.


identificar quais pessoas reagem de maneira semelhante aos mesmos est√≠mulos e quais reagem de forma diferente. Al√©m disso, √©
fundamental desenvolver m√©todos para comparar essas rea√ß√µes

emocionais.
Se, por um lado, o processo de identifica√ß√£o de similaridades
n√£o √© in√©dito e est√° embutido em diversas solu√ß√µes que envolvem a
utiliza√ß√£o de algoritmos de Aprendizado de M√°quina, √© tamb√©m fato
que o processo nem sempre √© tratado com transpar√™ncia e enfoque
na explicabilidade. Assim, visando contribuir com este cen√°rio, a
partir de pr√°ticas identificadas na literatura, este estudo apresenta
duas abordagens para a compara√ß√£o de respostas emocionais de
diferentes indiv√≠duos. Ao analisar as rea√ß√µes emocionais de 39 indiv√≠duos a um est√≠mulo audiovisual sob as duas abordagens, s√£o
real√ßadas as particularidades de cada abordagem, bem como discutidas as contribui√ß√µes decorrentes de uma an√°lise conjunta, que
integra as duas abordagens propostas.
### **2 CONTEXTO TE√ìRICO E CONTRIBUI√á√ïES** **DESTE ESTUDO**

Estudos que discutem rea√ß√µes emocionais de indiv√≠duos a est√≠mulos
audiovisuais n√£o s√£o in√©ditos na literatura e podem ser classificados
quanto ao objetivo da investiga√ß√£o. Uma revis√£o explorat√≥ria da
literatura revela uma maior quantidade de estudos que visam √†
**detec√ß√£o de engajamento ou interesse** em conte√∫do audiovisual
a partir das respostas emocionais dos usu√°rios. Como exemplo dessa
pr√°tica, a rec√©m-publicada pesquisa de Oakes, Peschel e Barraclough

[ 15 ] investiga a viabilidade de se utilizar dados de express√µes faciais,
registrados de forma n√£o invasiva, para avaliar o engajamento do
p√∫blico em apresenta√ß√µes art√≠sticas. Diferentemente de estudos que
analisam os dados de cada usu√°rio separadamente, esta pesquisa
adota como premissa que a similaridade das respostas emocionais
do p√∫blico √© um indicativo de engajamento com a apresenta√ß√£o. Esta
premissa emerge de estudos anteriores, que observaram rea√ß√µes
similares de usu√°rios enquanto estavam engajados ao ouvir m√∫sicas.
Ainda nesse contexto, uma pesquisa conduzida por de S√° et al .

[ 7 ] analisou as respostas emocionais de 10 usu√°rios ao *trailer* de
um filme do g√™nero horror que, √† √©poca do estudo, ainda n√£o havia
sido lan√ßado. O intuito estava em predizer a inten√ß√£o de assistir ao
filme. Foram observados sinais EEG e, com o uso de *eye tracking*, a
regi√£o do v√≠deo para a qual cada usu√°rio estava olhando. Embora os
resultados indiquem padr√µes no reconhecimento das emo√ß√µes, n√£o
h√° informa√ß√µes quanto √† similaridade de respostas emocionais de
diferentes indiv√≠duos. Em trabalho similar, conduzido por Da Silva
et al . [ 6 ] tamb√©m usando as t√©cnicas de EEG e *eye tracking*, foram
observadas as rea√ß√µes emocionais de usu√°rios a conte√∫dos audiovisuais, visando a favorecer a avalia√ß√£o da percep√ß√£o desses usu√°rios
quanto ao conte√∫do assistido.
No √¢mbito da **compara√ß√£o similaridade em respostas emoci-**
**onais**, [ 2 ] descrevem uma pesquisa em que dois grupos de pessoas,
um formado por indiv√≠duos com perfil pol√≠tico liberal e outro grupo
formado por indiv√≠duos com perfil conservador, tiveram suas respostas emocionais a est√≠mulos visuais registrados com o uso de eletromiografia facial. Indiv√≠duos de ambos os grupos foram expostos
a um conjunto de imagens. Ao final do processo, os pesquisadores
aplicaram o teste t de Student para identificar se havia diferen√ßa
significativa entre os dados dos diferentes grupos. Os resultados,


relatados em [ 1 ], revelam que n√£o houve diferen√ßa estatisticamente
significativa entre os dois grupos de usu√°rios.
A literatura tamb√©m revela **desafios** inerentes √† an√°lise emocional a partir de est√≠mulos audiovisuais. Embora o uso de filmes
para elicitar emo√ß√µes em usu√°rios tenha se mostrado uma abordagem efetiva tanto para emo√ß√µes positivas quanto negativas [ 11 ],
h√° casos em que os impactos emocionais s√£o sutis. Como exemplo,
an√°lises de [ 4 ] revelaram que, ao contr√°rio do esperado, os v√≠deos
utilizados como est√≠mulo n√£o foram capazes de gerar respostas
emocionais equivalentes. Em alguns casos, os √≠ndices identificados
para determinadas express√µes faciais associadas a emo√ß√µes foram
muito baixos. Como poss√≠vel justificativa, os autores explicaram
que os participantes haviam sido orientados a n√£o olhar para a tela
em momentos desconfort√°veis (possivelmente em cumprimento
aos procedimentos √©ticos). Como consequ√™ncia, o *software* utilizado para o reconhecimento de express√µes faciais pode n√£o ter
identificado as express√µes adequadamente nesses instantes.
A an√°lise dos trabalhos supracitados revela o amplo conjunto
de oportunidades de contribui√ß√µes no √¢mbito da compara√ß√£o de
repostas emocionais de diferentes indiv√≠duos aos mesmos est√≠mulos
emocionais, evidenciando a relev√¢ncia da presente investiga√ß√£o j√°
a partir da categoriza√ß√£o de abordagens para compara√ß√£o de dados
emocionais, que ser√° apresentada na Se√ß√£o 3. Em complemento, os
resultados da compara√ß√£o de rea√ß√µes emocionais de 39 indiv√≠duos,
cujo processo metodol√≥gico √© descrito na Se√ß√£o 4, contribuem para
a compreens√£o das caracter√≠sticas e particularidades de cada abordagem, bem como para o avan√ßo na identifica√ß√£o de similaridades
em repostas emocionais.
### **3 ABORDAGENS PARA A COMPARA√á√ÉO DE** **DADOS EMOCIONAIS**

As t√©cnicas de reconhecimento de emo√ß√µes em tempo real (de car√°ter fisiol√≥gico ou n√£o) coletam uma grande quantidade de dados
durante determinado per√≠odo. Como consequ√™ncia, o tratamento
e a interpreta√ß√£o desse grande conjunto de dados pode ser um
processo complexo, condut√≠vel de diferentes formas. A partir de
reflex√£o cr√≠tica em rela√ß√£o √†s pr√°ticas adotadas na literatura para a
interpreta√ß√£o de dados relacionados aos estados emocionais, s√£o
propostas a seguir duas abordagens aplic√°veis a esse contexto.
### **3.1 An√°lise de experi√™ncia emocional**

A primeira abordagem, neste estudo denominada de ‚ÄúAn√°lise de
Experi√™ncia Emocional‚Äù (AEE), considera as emo√ß√µes elicitadas por
um indiv√≠duo durante um determinado per√≠odo. Nesta perspectiva, o
enfoque est√° em compreender quais foram as respostas emocionais
dos usu√°rios aos est√≠mulos, bem como a frequ√™ncia ou intensidade
em que essas emo√ß√µes foram detectadas.
A Figura 1 ilustra de forma simplificada como a an√°lise de experi√™ncia emocional se caracteriza. Nesta Figura, h√° a representa√ß√£o
visual de uma linha do tempo, com marca√ß√µes que indicam diferentes trechos de um v√≠deo. Abaixo, h√° duas trilhas, cada uma
representando um usu√°rio diferente. Na trilha de cada usu√°rio, na
regi√£o equivalente a cada trecho de v√≠deo, existe a representa√ß√£o
visual da emo√ß√£o que o usu√°rio vivenciou durante aquele momento.
A Figura revela que dois indiv√≠duos, denotados pelas alcunhas de


337


-----

√önicos, mas n√£o incompar√°veis: abordagens para identifica√ß√£o de similaridades em respostas emocionais WebMedia‚Äô2024, Juiz de Fora, Brazil

**Figura 1: Representa√ß√£o do processo de interpreta√ß√£o dos dados segundo a abordagem AEE, em que s√£o comparadas as rea√ß√µes**
**emocionais de cada usu√°rio a diferentes trechos de um mesmo est√≠mulo audiovisual.**

**Figura 2: Representa√ß√£o do processo de interpreta√ß√£o dos dados segundo a abordagem ATE.**


"Pessoa A"e "Pessoa B", tiveram express√µes faciais associadas a emo√ß√µes reconhecidas em dois trechos do v√≠deo. Enquanto a Pessoa A
estava com a express√£o facial associada √† raiva no primeiro trecho,
a emo√ß√£o identificada no segundo trecho era a de alegria. O processo inverso √© observado para a Pessoa B, que inicia o v√≠deo com
a express√£o facial associada √† alegria e o conclui com a express√£o
facial associada √† raiva.

Ao aplicar-se uma an√°lise de experi√™ncia emocional, as experi√™ncias dos usu√°rios A e B ser√£o consideradas equivalentes, pois, no
processo de an√°lise, as duas emo√ß√µes foram observadas em igual
intensidade. Nota-se, portanto, que nesta abordagem a ordem de
manifesta√ß√£o das emo√ß√µes n√£o √© relevante, mas sim a frequ√™ncia ou
intensidade com que se manifestaram. Seguindo esta abordagem,
a conclus√£o indicaria que o v√≠deo gerou rea√ß√µes emocionais de
alegria e raiva em ambos os usu√°rios. Do conceito √† implementa√ß√£o, podem ser aplicadas, neste contexto, as seguintes t√©cnicas: i)
c√°lculo de m√©dia das emo√ß√µes; ii) quantifica√ß√£o da express√£o facial


mais intensa em um determinado per√≠odo; iii) c√°lculo de dist√¢ncia
euclidiana; e iv) algoritmos de clusteriza√ß√£o, como o *kNN* . Como
exemplo de pesquisas que adotam tal pr√°tica, t√™m-se os estudos de
Gonz√°lez-Rodr√≠guez et al. [12] e Boƒüa et al. [4].
### **3.2 An√°lise de trajet√≥ria emocional**

Diferentemente da abordagem anterior, que desconsidera a temporalidade no comportamento emocional, a an√°lise de trajet√≥ria
emocional dedica-se a observar se, ao longo de um determinado
per√≠odo, a intensidade com que uma emo√ß√£o foi identificada cresceu ou decresceu ao longo do tempo. Nessa abordagem, valoriza-se
o impacto dos acontecimentos do v√≠deo no estado emocional dos
usu√°rios. Novamente recorrendo √† Figura 1 para a exemplifica√ß√£o
dessa abordagem, pode-se entender que, para a Pessoa A, o primeiro
trecho do v√≠deo elicitava a emo√ß√£o de raiva, enquanto o segundo
trecho elicitava a emo√ß√£o de alegria. Em contraponto, uma situa√ß√£o
inversa pode ser observada para a Pessoa B. Nota-se, neste ponto,


338


-----

WebMedia‚Äô2024, Juiz de Fora, Brazil Aguiar, et al.


uma quest√£o importante: o mesmo conjunto de dados pode gerar diferentes interpreta√ß√µes a partir da abordagem de an√°lise. Enquanto
a abordagem anterior possibilitava concluir que ambos os usu√°rios
tiveram experi√™ncias equivalentes, a atual abordagem real√ßa que
estes usu√°rios tiveram experi√™ncias completamente distintas, como
evid√™ncia a Figura 2.
Em termos pr√°ticos, a an√°lise de trajet√≥ria emocional pode ser
observada a partir da correla√ß√£o. Neste contexto, um desafio est√° na
defini√ß√£o da janela de tempo em que ser√° analisada a similaridade
entre dois usu√°rios. Em [ 15 ], por exemplo, optou-se por analisar a
correla√ß√£o dos estados emocionais de diferentes usu√°rios em uma
janela de tempo de um minuto.
### **4 MATERIAIS E M√âTODOS**

Visando a comparar e validar abordagens para a identifica√ß√£o de
similaridades em respostas emocionais de diferentes usu√°rios, ser√£o
aplicadas as abordagens AEE e ATE, apresentadas na se√ß√£o anterior.
Para nortear o percurso metodol√≥gico deste estudo, foram definidas
as quest√µes de pesquisa apresentadas a seguir:

  - **QP1** : H√° experi√™ncias emocionais similares de usu√°rios que
assistiram aos mesmos est√≠mulos audiovisuais?

  - **QP2** : Para um mesmo est√≠mulo emocional, h√° usu√°rios com
trajet√≥rias emocionais similares?

  - **QP3** : H√° casos de usu√°rios que compartilham tanto experi√™ncias quanto trajet√≥rias emocionais?

Para responder √† **QP1**, ser√£o analisadas as similaridades de experi√™ncias emocionais de diferentes usu√°rios aos mesmos est√≠mulos

audiovisuais, conforme abordagem AEE, descrita na Se√ß√£o 3.1. Para
a redu√ß√£o da amostragem, ser√° gerado um vetor de caracter√≠sticas
para cada indiv√≠duo ( *ùëâ* *ùëñ* ), contendo a m√©dia da intensidade de cada
express√£o facial associada √† emo√ß√£o. Foi estabelecida a seguinte
ordem: neutra ( *ùúá* 1 ), alegria ( *ùúá* 2 ), tristeza ( *ùúá* 3 ), raiva ( *ùúá* 4 ), medo ( *ùúá* 5 ),
nojo ( *ùúá* 6 ) e surpresa ( *ùúá* 7 ).

*ùëâ* *ùëñ* = [ *ùúá* 1 *, ..., ùúá* *ùëõ* ] (1)

Em seguida, os dados ser√£o submetidos ao algoritmo kNN ( *k-*
*Nearest Neighbors* ), com par√¢metro *ùëõ* = 39, para possibilitar a compara√ß√£o de todos os pares de indiv√≠duos. Assim, para cada par, ser√°
calculada a dist√¢ncia entre esses indiv√≠duos. Para responder √† **QP2**,
que trata da trajet√≥ria emocional (abordagem ATE, descrita na Se√ß√£o 3.2), ser√° calculada a correla√ß√£o entre as trajet√≥rias emocionais
dos usu√°rios. Considerando a distribui√ß√£o dos dados, o m√©todo de
c√°lculo de correla√ß√£o utilizado ser√° a correla√ß√£o de Spearman. Uma
vez que a correla√ß√£o compara a varia√ß√£o entre duas vari√°veis, ser√°
calculada a correla√ß√£o considerando a express√£o facial neutra. Para
a discuss√£o, ser√£o consideradas apenas correla√ß√µes estatisticamente
significativas ( *ùëù* *<* 0 *.* 05) e que possuam correla√ß√£o, no m√≠nimo,
moderada ( *ùúå* *ùë†* *>* = 0 *.* 5 ) . Finalmente, para a discuss√£o da **QP3**, o
√≠ndice de correla√ß√£o ( *ùúå* *ùë†* ) e o √≠ndice de similaridade do kNN ser√£o
analisados em conjunto para os pares de usu√°rios.
### **4.1 Sele√ß√£o do conjunto de dados**

Embora existam diversos conjuntos de dados de express√µes faciais
associadas a emo√ß√µes, conjuntos de dados que contenham v√≠deos
ou fotografias de pessoas reagindo ao mesmo conjunto de est√≠mulos
audiovisuais, com sincroniza√ß√£o temporal, s√£o escassos. Ap√≥s uma


pesquisa explorat√≥ria, foram identificados dois conjuntos de dados
que continham tal caracter√≠stica: o *AM-FED*, mantido pela Affectiva,
e o Emognition Wearable Dataset 2020 [ 18 ]. Ambos os conjuntos
de dados s√£o gratuitos para uso em pesquisas cient√≠ficas, sendo
este outro crit√©rio de sele√ß√£o. Com rela√ß√£o aos aspectos √©ticos, a
Resolu√ß√£o CNS 674/2022 habilita o desenvolvimento de pesquisas
que envolvam conjuntos de dados j√° coletados. Nesse sentido, as
pessoas autoras submeteram solicita√ß√£o de acesso aos produtores
do conjunto de dados *Emognition* e tamb√©m para o *AM-FED* . At√© o
momento de elabora√ß√£o deste trabalho, houve apenas resposta por
parte dos produtores do *dataset Emognition* .

*Emognition.* O conjunto de dados *Emognition* re√∫ne dados de 39
1 participantes (18 do sexo masculino e 21 do feminino, com idade
de 21 ¬± 2 anos ). Cada volunt√°rio assistiu a dez v√≠deos. Deles, um
foi considerado neutro, enquanto os outros nove evocavam uma
emo√ß√£o espec√≠fica. O protocolo utilizado para a coleta de dados
envolveu os seguintes procedimentos: ao in√≠cio da coleta, durante
cinco minutos, os volunt√°rios assistiram a um v√≠deo contendo linhas
e pontos dispostos em uma tela preta. Em seguida, responderam a
um question√°rio de autoavalia√ß√£o. Ent√£o, para cada um dos dez v√≠deos utilizados como est√≠mulo, adotou-se a realiza√ß√£o das seguintes
etapas: i) 2 minutos de v√≠deo contendo linhas e pontos dispostos
em uma tela preta; ii) v√≠deo com a intencionalidade de se evocar
uma emo√ß√£o espec√≠fica (com dura√ß√£o 1 a 2 minutos); e iii) responder ao question√°rio de autoavalia√ß√£o. Al√©m dos v√≠deos gravados
com os volunt√°rios, o conjunto de dados √© composto por dados de
reconhecimento de express√µes faciais, analisadas com o uso do *soft-*
*ware Quantum Sense*, que reconhece express√µes faciais associadas
√†s seguintes emo√ß√µes: raiva, nojo, alegria, tristeza e surpresa, al√©m
da face neutra. Como os registros disponibilizados no *dataset* n√£o
estavam associados ao *frame* do v√≠deo, visando √† compatibilidade
das an√°lises, os v√≠deos foram processados novamente pelas pessoas
autoras deste trabalho. No √¢mbito deste estudo, por limita√ß√£o de
escopo, foram consideradas as rea√ß√µes emocionais de usu√°rios ao
est√≠mulo associado √† emo√ß√£o de nojo.
### **4.2 Processamento dos dados**

Os v√≠deos que integram o conjunto de dados *Emognition* estavam
organizados com a identifica√ß√£o do usu√°rio e do est√≠mulo utilizado
naquela coleta. Ao in√≠cio da fase de processamento, para cada arquivo de v√≠deo, foram extra√≠das imagens est√°ticas, uma para cada
segundo de dura√ß√£o do v√≠deo. Assim, um v√≠deo com dura√ß√£o de 120
segundos resultou na gera√ß√£o de 120 imagens est√°ticas. Tal processo
foi realizado visando-se a reduzir a dimensionalidade dos dados.

As imagens foram, portanto, submetidas ao processamento pela biblioteca *Face-api.js*, cuja efic√°cia no reconhecimento de express√µes
faciais associadas a emo√ß√µes foi avaliada em estudo anterior. Para
cada imagem, a biblioteca retorna um vetor com a intensidade de
cada uma das sete express√µes faciais: neutra, alegria, medo, nojo,
raiva, tristeza e surpresa. √â importante mencionar que, diferentemente de algumas solu√ß√µes que analisam a ocorr√™ncia de express√µes
faciais associadas a emo√ß√µes de forma independente, a *Face-api.js*
considera a ocorr√™ncia excludente. Se em determinada imagem for
detectada a express√£o facial neutra com intensidade de 80%, os

1 O n√∫mero de 39 participantes considera apenas indiv√≠duos para os quais h√° registros
de imagens dispon√≠veis.


339


-----

√önicos, mas n√£o incompar√°veis: abordagens para identifica√ß√£o de similaridades em respostas emocionais WebMedia‚Äô2024, Juiz de Fora, Brazil


√≠ndices relacionados √†s demais express√µes faciais devem somar 20%.
Portanto, a express√£o facial neutra √© um indicativo de evoca√ß√£o
emocional em um determinado instante. Para cada usu√°rio, em cada
est√≠mulo, foi gerado um arquivo no formato CSV ( *comma-separated*
*values* ) contendo o vetor de intensidades emocionais em determinada imagem. Tamb√©m foi anotado o n√∫mero da imagem, visando
a favorecer a compara√ß√£o das respostas emocionais de diferentes
usu√°rios.
### **5 RESULTADOS** **5.1 Detec√ß√£o de experi√™ncias emocionais** **similares**

Para identificar similaridades em experi√™ncias emocionais de diferentes indiv√≠duos (QP1), foi calculada, para cada participante, a
m√©dia de intensidade de cada express√£o facial. Obteve-se, portanto,
um vetor de sete caracter√≠sticas para cada indiv√≠duo. A Figura 3 apresenta, nesse contexto, um gr√°fico de dispers√£o dos dados emocionais
desses indiv√≠duos [2] . Para a gera√ß√£o da figura, dada a necessidade de
redu√ß√£o de dimensionalidade, de sete para duas, foi aplicado um
algoritmo PCA ( *Principal Component Analysis* ). A Figura 3 evidencia, a partir da proximidade dos pontos, que h√° uma quantidade
consider√°vel de indiv√≠duos que apresentaram experi√™ncias emocionais similares. Em contraponto, h√° indiv√≠duos com experi√™ncias
emocionais distintas.


0.6

0.4

0.2

0

-0.2

-0.4

-0.6




















-0.5 -0.25 0 0.25 0.5 0.75 1

**Figura 3: Dispers√£o dos indiv√≠duos quanto √†s express√µes faci-**
**ais coletadas durante o est√≠mulo audiovisual.**

Enriquecendo o processo de interpreta√ß√£o dos dados, foram selecionados de forma arbitr√°ria, a partir da dispers√£o apresentada na
Figura 3, dois pares de indiv√≠duos para uma an√°lise mais detalhada:

2 Visando √† reprodutibilidade, os indiv√≠duos est√£o identificados com o c√≥digo utilizado
pelos autores do conjunto de dados *Emognition* .


Indiv√≠duo *ùúá* 1 *ùúá* 2 *ùúá* 3 *ùúá* 4 *ùúá* 5 *ùúá* 6 *ùúá* 7

36 0.89 0.09 0.02 0.00 0.00 0.00 0.00

64 0.92 0.08 0.00 0.00 0.00 0.00 0.00

28 0.85 0.00 0.07 0.00 0.01 0.00 0.06

63 0.07 0.82 0.10 0.00 0.00 0.01 0.00

**Tabela 1: Compara√ß√£o dos vetores de caracter√≠sticas de duas**
**duplas de indiv√≠duos.**

um par graficamente pr√≥ximo (indiv√≠duos 36 e 64) e outro par graficamente distante (indiv√≠duos 28 e 63). Os dados, apresentados na
Tabela 1, evidenciam a similaridade dos vetores de caracter√≠sticas
dos indiv√≠duos 36 e 64, assim como a diferen√ßa entre os vetores de
caracter√≠sticas dos indiv√≠duos 28 e 63. Enquanto o primeiro par teve
alta incid√™ncia de express√£o facial neutra, com a ocorr√™ncia tamb√©m
da express√£o facial associada √† alegria em intensidade similar, o
segundo par apresentou experi√™ncias distintas. O indiv√≠duo 28 teve
maior incid√™ncia de express√£o facial neutra, enquanto o indiv√≠duo
63 teve maior incid√™ncia de express√µes faciais associadas √† emo√ß√£o
de alegria.
Em seguida, tamb√©m aplicou-se o algoritmo *kNN*, que calcula
a dist√¢ncia entre indiv√≠duos que comp√µem um par. Quanto mais
pr√≥ximo de zero √© o √≠ndice, maior √© a similaridade identificada entre
dois usu√°rios. Em decorr√™ncia do elevado n√∫mero de combina√ß√µes
(1482, tendo *ùëõ* = 39), tem-se na Tabela 2 a apresenta√ß√£o dos cinco pares com maior similaridade, seguidos pelos cinco pares com menor
similaridade.

Indiv√≠duo Vizinho Dist√¢ncia

31 39 0.00

25 24 0.00

47 50 0.01

43 24 0.01

43 23 0.01

24 63 1.24

63 24 1.24

63 25 1.24

23 63 1.23

43 63 1.23

**Tabela 2: Resultados provenientes do algoritmo kNN.**

Potencializando a an√°lise e favorecendo uma compreens√£o de
todo o cen√°rio, a Figura 4 apresenta um gr√°fico de distribui√ß√£o dos
√≠ndices de dist√¢ncia calculados para cada par de usu√°rios com o algoritmo *KNN* . Como pode-se observar, h√° uma expressiva quantidade
de ocorr√™ncias com alta similaridade entre os indiv√≠duos.
### **5.2** **Identifica√ß√£o de trajet√≥rias emocionais** **similares**

Considerando a QP2, que trata da identifica√ß√£o de similaridades de
trajet√≥rias emocionais de diferentes indiv√≠duos aos mesmos est√≠mulos audiovisuais, calculou-se, para cada par de usu√°rios, a correla√ß√£o


340


-----

WebMedia‚Äô2024, Juiz de Fora, Brazil Aguiar, et al.


300

200

100

0

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

**Figura 4: Distribui√ß√£o do √≠ndice de similaridade calculado**
**pelo algoritmo** ***KNN*** **.**

de Spearman. A opera√ß√£o foi realizada para os √≠ndices relacionados
√† express√£o facial neutra, considerando os motivos expostos anteriormente na Se√ß√£o 4. Os resultados, descritos parcialmente na Tabela
3, revelam que foram encontradas 210 correla√ß√µes estatisticamente
significativas ( *ùëù* *<* 0 *.* 05). Destas, 67 correla√ß√µes s√£o negativas e 143
positivas. Para auxiliar o processo de compreens√£o dos dados e de
valida√ß√£o dessa abordagem, optou-se pela utiliza√ß√£o de recursos
gr√°ficos.

Indiv√≠duo 1 Indiv√≠duo 2 *ùúå* *ùë†* *ùëù*

50 43 0.97 0.00

47 43 0.97 0.00

47 50 0.96 0.00

50 60 0.84 0.0

60 43 0.82 0.00

56 29 0.24 0.04

50 27 0.24 0.04

28 26 0.24 0.04

26 31 0.24 0.04

51 57 0.25 0.03

**Tabela 3: √çndices de correla√ß√£o entre pares de usu√°rios.**

As Figuras 5, 6 e 7 apresentam gr√°ficos de linhas que comparam, longitudinalmente, a varia√ß√£o da intensidade da express√£o
facial neutra de dois usu√°rios. No caso da Figura 5, tem-se uma
compara√ß√£o entre os usu√°rios identificados pelos n√∫meros 38 e 48.
Embora a intensidade da express√£o facial neutra de ambos os usu√°rios tenha apresentado varia√ß√£o ao longo do tempo, h√° correla√ß√£o
positiva moderada e significativa ( *ùúå* *ùë†* = 0 *.* 54, *ùëù* = 0 *.* 0), evidenciada
pela similaridade no comportamento longitudinal das linhas. Ao
analisar-se a Figura 6, que ilustra a compara√ß√£o para os usu√°rios
43 e 47 no mesmo intervalo de tempo contemplado pela Figura 5,
evidencia-se inicialmente que o comportamento facial do segundo
par de indiv√≠duos apresentou pouca varia√ß√£o quando comparado ao
par anterior. Estes usu√°rios n√£o tiveram ativa√ß√£o emocional not√°vel
em suas express√µes faciais em consider√°vel parte do v√≠deo, mas
apresentaram forte correla√ß√£o ( *ùúå* *ùë†* = 0 *.* 97, *ùëù* = 0 *.* 0).
Ademais, embora a quest√£o de pesquisa que fomenta essa discuss√£o trate da identifica√ß√£o de trajet√≥rias similares, a abordagem


tamb√©m √© capaz de revelar trajet√≥rias emocionais opostas, a partir
da an√°lise de correla√ß√µes negativas. A Figura 7 apresenta uma situa√ß√£o em que houve moderada correla√ß√£o negativa ( *ùúå* *ùë†* = ‚àí 0 *.* 65,
*ùëù* = 0 *.* 0) entre os usu√°rios 43 e 63.
### **5.3 Compara√ß√£o entre as abordagens**

Em vistas a discutir a **QP3**, que trata da ocorr√™ncia de experi√™ncias
e trajet√≥rias emocionais similares, foi realizado o confronto dos
resultados do algoritmo *kNN* com a correla√ß√£o de Spearman. A
Tabela 4 apresenta os dez primeiros registros ap√≥s a ordena√ß√£o por
correla√ß√£o e similaridade.

Indiv√≠duo Vizinho *ùúå* *ùë†* *ùëù* kNN

50 43 0.97 0.0 0.01

47 43 0.97 0.0 0.03

47 50 0.96 0.0 0.01

50 60 0.84 0.0 0.06

60 43 0.82 0.0 0.07

47 63 -0.76 0.00 8.07

50 63 -0.72 0.00 8.04

63 43 -0.65 0.00 7.99

27 26 -0.61 0.00 7.01

49 32 -0.57 0.00 6.10

**Tabela 4: √çndices de correla√ß√£o e dist√¢ncia entre pares de**
**indiv√≠duos, contemplando as abordagens AEE e ATE.**

Para exemplifica√ß√£o dos resultados, ser√£o discutidos de forma
detalhada dois pares de indiv√≠duos: 43-50 e 47-63. O primeiro par,
formado pelos indiv√≠duos identificados pelos n√∫meros 43 e 50, √©
caracterizado por grande similaridade nas duas abordagens de identifica√ß√£o de similaridade emocional. Uma consulta aos dados de
express√µes faciais revela que, para ambos os indiv√≠duos, o est√≠mulo
audiovisual n√£o provocou consider√°vel manifesta√ß√£o de express√µes
faciais associadas a emo√ß√µes detectadas com o uso do *software*,
como revela a Tabela 5. A an√°lise √© corroborada pela Figura 8, que
evidencia comportamento fortemente similar.

Indiv√≠duo *ùúá* 1 *ùúá* 2 *ùúá* 3 *ùúá* 4 *ùúá* 5 *ùúá* 6 *ùúá* 7

43 0.99 0 0.01 0 0 0 0

50 0.98 0 0.02 0 0 0 0

47 0.97 0 0.03 0 0 0 0

63 0.07 0.82 0.1 0 0 0.01 0

**Tabela 5: Compara√ß√£o dos vetores de caracter√≠sticas de duas**
**duplas de indiv√≠duos a partir da an√°lise conjunta de AEE e**
**ATE.**

Em contraponto, a compara√ß√£o entre as duas abordagens tamb√©m
favorece a identifica√ß√£o de pares de indiv√≠duos em que h√° grandes
distin√ß√µes, tanto na abordagem AEE quanto na abordagem ATE,
caso do par formado pelos indiv√≠duos 47 e 63. Como indicado na
Tabela 5, nota-se que enquanto para o indiv√≠duo 47 predominou-se
a express√£o facial neutra, para o indiv√≠duo 63 observou-se maior


341


-----

√önicos, mas n√£o incompar√°veis: abordagens para identifica√ß√£o de similaridades em respostas emocionais WebMedia‚Äô2024, Juiz de Fora, Brazil

1

0

5 10 15 20 25 30 35 40 45 50 55 60 65 70

**Figura 5: Compara√ß√£o gr√°fica da trajet√≥ria emocional dos indiv√≠duos 38 e 48, com correla√ß√£o moderada (** *ùúå* *ùë†* = 0 *.* 54 **,** *ùëù* = 0 *.* 0 **)**

1

0

5 10 15 20 25 30 35 40 45 50 55 60 65 70

43 47

**Figura 6: Compara√ß√£o gr√°fica da trajet√≥ria emocional dos indiv√≠duos 43 e 47, com correla√ß√£o forte (** *ùúå* *ùë†* = 0 *.* 97 **,** *ùëù* = 0 *.* 0 **)**

1

0

5 10 15 20 25 30 35 40 45 50 55 60 65 70

**Figura 7: Compara√ß√£o gr√°fica da trajet√≥ria emocional dos indiv√≠duos 47 e 63, com correla√ß√£o moderada e inversa (** *ùúå* *ùë†* = ‚àí 0 *.* 65 **,**
*ùëù* = 0 *.* 0 **)**


incid√™ncia da express√£o facial associada √† alegria. Similarmente, a
Figura 7 evidencia a compara√ß√£o da ATE para esses dois indiv√≠duos,
revelando a distin√ß√£o entre suas rea√ß√µes ao longo do v√≠deo, como
j√° discutido anteriormente.
### **6 DISCUSS√ïES** **6.1 Contribui√ß√µes**

Os resultados apresentados na Se√ß√£o 5 permitem concluir que as
abordagens AEE e ATE s√£o, de fato, eficazes para a compara√ß√£o
de similaridade de respostas emocionais evocadas por diferentes
indiv√≠duos a partir de um mesmo est√≠mulo audiovisual, tanto em


rela√ß√£o √†s experi√™ncias emocionais quanto em rela√ß√£o √†s trajet√≥rias.
Os resultados tamb√©m validam as particularidades das abordagens,
evidenciando que elas oferecem diferentes perspectivas de compreens√£o das respostas emocionais dos indiv√≠duos e, portanto, devem
ser escolhidas sob um cauteloso processo de an√°lise dos pesquisadores quanto ao objetivo do estudo. Enquanto a AEE oferece uma
perspectiva quanto √†s emo√ß√µes vivenciadas, com suas respectivas
intensidades, a ATE evidencia as altera√ß√µes emocionais ocorridas ao
longo do est√≠mulo. Tais abordagens podem, inclusive, ser combinadas para a identifica√ß√£o de total similaridade entre dois indiv√≠duos.
Podem, tamb√©m, revelar comportamentos complemente opostos,
denotados por um √≠ndice representativo de grande dist√¢ncia (AEE)


342


-----

WebMedia‚Äô2024, Juiz de Fora, Brazil Aguiar, et al.

1

0

5 10 15 20 25 30 35 40 45 50 55 60 65 70

**Figura 8: Compara√ß√£o gr√°fica da trajet√≥ria emocional dos indiv√≠duos 43 e 50, com correla√ß√£o forte e positiva. (** *ùúå* *ùë†* = 0 *.* 97 **,** *ùëù* = 0 *.* 0 **)**


e correla√ß√£o inversa (ATE). A classifica√ß√£o de pr√°ticas relatadas na
literatura em duas abordagens, seguida pela sua valida√ß√£o, oferece
n√£o apenas novas perspectivas para a an√°lise emocional no √¢mbito
de sistemas interativos, mas tamb√©m abre caminho para a prospec√ß√£o de um conjunto de aplica√ß√µes pr√°ticas. Nesse sentido, pode-se
mencionar desde a avalia√ß√£o de conte√∫do em plataformas de *strea-*
*ming* at√© adapta√ß√£o de materiais de ensino √†s respostas emocionais
dos alunos.
### **6.2** **Desafios e oportunidades**

O desenvolvimento de uma investiga√ß√£o que visa a comparar repostas emocionais de diferentes indiv√≠duos √© desafiadora sob diversos
aspectos. Dentre eles, est√° na coleta sincroniz√°vel das respostas
emocionais. Uma alternativa nesse cen√°rio envolve a constru√ß√£o
de *datasets* em um ambiente controlado, como ocorreu na base de
dados utilizada neste estudo. Todavia, a utiliza√ß√£o de v√≠deos para
estimular emo√ß√µes nos volunt√°rios nem sempre √© satisfat√≥ria, como
real√ßado na literatura e observado ao longo dos resultados. Como
discutido na se√ß√£o de resultados, foram identificados v√°rios casos
em que os volunt√°rios permaneceram com a express√£o facial neutra
durante o tempo em que assistiam ao v√≠deo utilizado como est√≠mulo.
Apesar dessa limita√ß√£o, destaca-se a efetividade das abordagens
avaliadas neste estudo, que conseguiram identificar indiv√≠duos que
tiveram tal comportamento similar.
Ademais, no √¢mbito deste estudo, foram considerados est√≠mulos
audiovisuais, caracterizados pelo mesmo tempo de dura√ß√£o. Em
aplica√ß√µes interativas, como jogos eletr√¥nicos, o processo de intera√ß√£o √© marcado pelo protagonismo do usu√°rio, que tem o poder
de decis√£o quanto aos eventos e a√ß√µes da aplica√ß√£o. Assim, pode
n√£o haver sincronicidade nos est√≠mulos apresentados. Neste cen√°rio, a compara√ß√£o de similaridades de respostas emocionais dos
usu√°rios tende a ser ainda mais desafiadora, j√° que o percurso do
usu√°rio na aplica√ß√£o pode n√£o ser equipar√°vel a outro. Como alternativa, pode-se optar pela compara√ß√£o de respostas emocionais em
intervalos de tempo menores, delimitados pelo acontecimento de
determinado evento, como a exibi√ß√£o de um di√°logo ou a conclus√£o
de um objetivo. T√©cnicas como *Multi-Dimensional Dynamic Time*
*Warping* (MDDTW), por exemplo, podem ser aplicadas para essa
compara√ß√£o.
Finalmente, visando a reprodutibilidade da an√°lise, os dados processados durante o desenvolvimento deste estudo est√£o dispon√≠veis


para acesso p√∫blico a partir da seguinte URL https://shorturl.at/
mJV8y.
### **7 CONSIDERA√á√ïES FINAIS**

Compreender as emo√ß√µes humanas e o modo como diferentes indiv√≠duos reagem aos mesmos est√≠mulos √© um desafio altamente
complexo, mesmo diante de avan√ßos em √°reas como neurologia,
psicologia e computa√ß√£o. Ao mesmo tempo que a compreens√£o dos
estados afetivos humanos √© um campo com oportunidades a serem
exploradas, h√° tamb√©m oportunidades para enriquecer a experi√™ncia de uso de sistemas computacionais a partir da adapta√ß√£o desses
sistemas considerando as emo√ß√µes vivenciadas pelos usu√°rios durante o uso de determinada aplica√ß√£o. Este processo, entretanto,
envolve o agrupamento de usu√°rios com caracter√≠sticas similares,
que recebem tratamento equivalente.
Comparando os resultados provenientes de duas abordagens
para a identifica√ß√£o de similaridades em respostas emocionais, este
estudo provoca o estado da arte ao discutir as particularidades de
cada abordagem, bem como ao sugerir uma profunda reflex√£o cr√≠tica
quanto √† abordagem de compara√ß√£o de respostas emocionais em
estudos futuros.
√â evidente, portanto, que os desafios relacionados a esse tema
n√£o s√£o esgotados no presente trabalho. Deste modo, investiga√ß√µes
futuras devem expandir o escopo de an√°lise, contemplando respostas emocionais de indiv√≠duos a um amplo conjunto de est√≠mulos
audiovisuais. H√°, ainda, possibilidades quanto √† expans√£o da an√°lise com a inclus√£o de fatores demogr√°ficos, como idade, g√™nero e
nacionalidade, al√©m de caracter√≠sticas individuais, como tra√ßos de
personalidade. Espera-se que a condu√ß√£o de novas investiga√ß√µes
nesse sentido enrique√ßa o arcabou√ßo conceitual da √°rea de Computa√ß√£o Afetiva, favorecendo o desenvolvimento de aplica√ß√µes que
disponham de adapta√ß√µes afetivas com efetividade.
### **AGRADECIMENTOS**

Os autores expressam gratid√£o ao Freepik pelas imagens utilizadas
na cria√ß√£o de algumas figuras deste artigo.
### **REFER√äNCIAS**

[1] Bert Bakker, Gijs Schumacher, Kevin Arceneaux, and Claire Gothreau. 2022.
Conservatives and Liberals have Similar Physiological Responses to Threats.
(2022). https://doi.org/10.17605/OSF.IO/D5G72


343


-----

√önicos, mas n√£o incompar√°veis: abordagens para identifica√ß√£o de similaridades em respostas emocionais WebMedia‚Äô2024, Juiz de Fora, Brazil



[2] Bert N. Bakker, Gijs Schumacher, Claire Gothreau, and Kevin Arceneaux. 2020.
Conservatives and liberals have similar physiological responses to threats. *Nature*
*Human Behaviour* 4, 6 (Feb. 2020), 613‚Äì621. https://doi.org/10.1038/s41562-0200823-z

[3] Simone Diniz Junqueira Barbosa, Bruno Santana da Silva, Milene Selbach Silveira,
Isabela Gasparini, Ticianne Darin, and Gabriel Diniz Junqueira Barbosa. 2021.
*Intera√ß√£o Humano-Computador e Experi√™ncia do Usu√°rio* . Autopublica√ß√£o.

[4] Merve Boƒüa, Mehmet Koyuncu, G√ºlin Ka√ßa, and Turan Onur Bayazƒ±t. 2022. Comparison of emotion elicitation methods: 3 methods, 3 emotions, 3 measures. *Cur-*
*rent Psychology* 42, 22 (April 2022), 18670‚Äì18685. https://doi.org/10.1007/s12144022-02984-5

[5] Alan S. Cowen, Dacher Keltner, Florian Schroff, Brendan Jou, Hartwig Adam,
and Gautam Prasad. 2020. Sixteen facial expressions occur in similar contexts
worldwide. *Nature* 589, 7841 (Dec. 2020), 251‚Äì257. https://doi.org/10.1038/s41586020-3037-7

[6] Thiago Henrique Coelho Tavares Da Silva, Matheus Dantas Cavalcanti, Felipe
Melo Feliciano De S√°, Isaac N√≥brega Marinho, Daniel De Queiroz Cavalcanti, and
Valdecir Becker. 2022. Visualization of brainwaves using EEG to map emotions
with eye tracking to identify attention in audiovisual workpieces. In *Proceedings of*
*the Brazilian Symposium on Multimedia and the Web* (Curitiba, Brazil) *(WebMedia*
*‚Äô22)* . Association for Computing Machinery, New York, NY, USA, 381‚Äì389. https:
//doi.org/10.1145/3539637.3557055

[7] Felipe de S√°, Daniel Cavalcanti, and Valdecir Becker. 2023. Testes com usu√°rios
para an√°lise de emo√ß√µes em conte√∫dos audiovisuais utilizando EEG e eye tracking.
In *Anais Estendidos do XXIX Simp√≥sio Brasileiro de Sistemas Multim√≠dia e Web*
(Ribeir√£o Preto/SP). SBC, Porto Alegre, RS, Brasil, 63‚Äì66. https://doi.org/10.5753/
webmedia_estendido.2023.235663

[8] Tom√°s A. D‚ÄôAmelio, Nicol√°s M. Bruno, Leandro A. Bugnon, Federico Zamberlan,
and Enzo Tagliazucchi. 2023. Affective Computing as a Tool for Understanding
Emotion Dynamics from Physiology: A Predictive Modeling Study of Arousal
and Valence. In *2023 11th International Conference on Affective Computing and*
*Intelligent Interaction Workshops and Demos (ACIIW)* . 1‚Äì7. https://doi.org/10.
1109/ACIIW59127.2023.10388155



[9] Di√≥gines D‚ÄôAvila Goldoni, Helena M. Reis, and Patr√≠cia A. Jaques. 2023. Emo√ß√µes
na Aprendizagem: Estimando a Dura√ß√£o da Confus√£o e Aprimorando Interven√ß√µes Pedag√≥gicas. *Revista Brasileira de Inform√°tica na Educa√ß√£o* 31 (dez. 2023),
1225‚Äì1247. https://doi.org/10.5753/rbie.2023.3433

[10] Yingruo Fan, Jacqueline C. K. Lam, and Victor O. K. Li. 2021. Demographic
effects on facial emotion expression: an interdisciplinary investigation of the
facial action units of happiness. *Scientific Reports* 11, 1 (March 2021). https:
//doi.org/10.1038/s41598-021-84632-9

[11] Luz Fern√°ndez-Aguilar, Beatriz Navarro-Bravo, Jorge Ricarte, Laura Ros, and
Jose Miguel Latorre. 2019. How effective are films in inducing positive and negative emotional states? A meta-analysis. *PLOS ONE* 14, 11 (Nov. 2019), e0225040.
https://doi.org/10.1371/journal.pone.0225040

[12] M.Rosario Gonz√°lez-Rodr√≠guez, M.Carmen D√≠az-Fern√°ndez, and Carmen Pacheco G√≥mez. 2020. Facial-expression recognition: An emergent approach to the
measurement of tourist satisfaction through emotions. *Telematics and Informatics*
51 (Aug. 2020), 101404. https://doi.org/10.1016/j.tele.2020.101404

[13] Timothy A Judge and Stephen P Robbins. 2017. *Organizational behavior* . Pearson.

[14] Krzysztof Kutt, Dominika DrƒÖ≈ºyk, Szymon Bobek, and Grzegorz J. Nalepa. 2020.
Personality-Based Affective Adaptation Methods for Intelligent Systems. *Sensors*
21, 1 (Dec. 2020), 163. https://doi.org/10.3390/s21010163

[15] Richard A. Oakes, Lisa Peschel, and Nick E. Barraclough. 2024. Inter-subject
correlation of audience facial expressions predicts audience engagement during
theatrical performances. *iScience* (April 2024), 109843. https://doi.org/10.1016/j.
isci.2024.109843

[16] Guanxiong Pei, Haiying Li, Yandi Lu, Yanlei Wang, Shizhen Hua, and Taihao Li.
2024. Affective Computing: Recent Advances, Challenges, and Future Trends.
*Intelligent Computing* 3 (Jan. 2024). https://doi.org/10.34133/icomputing.0076

[17] Rainer Reisenzein, Andrea Hildebrandt, and Hannelore Weber. 2020. *Personality*
*and Emotion* (2 ed.). Cambridge University Press, 81‚Äì100. https://doi.org/10.
1017/9781108264822.009

[18] Stanis≈Çaw Saganowski, Joanna Komoszy≈Ñska, Maciej Behnke, Bartosz Perz, ≈Åukasz D. Kaczmarek, and Przemys≈Çaw Kazienko. 2021. Emognition Wearable
Dataset 2020. https://doi.org/10.7910/DVN/R9WAF4


344


-----

